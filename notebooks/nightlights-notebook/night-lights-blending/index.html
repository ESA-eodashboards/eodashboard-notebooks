<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Monitoring socio-economic activities with nighttime light maps - EO Dashboard Notebooks</title><meta property="og:title" content="Monitoring socio-economic activities with nighttime light maps - EO Dashboard Notebooks"/><meta name="generator" content="mystmd"/><meta name="description" content="Collection of examples relevant to the EO Dashboard project"/><meta property="og:description" content="Collection of examples relevant to the EO Dashboard project"/><meta name="keywords" content=""/><meta name="image" content="/eodashboard-notebooks/build/nighttime_northeaste-21f472805eb19cbae2eff3b0562af016.jpg"/><meta property="og:image" content="/eodashboard-notebooks/build/nighttime_northeaste-21f472805eb19cbae2eff3b0562af016.jpg"/><link rel="stylesheet" href="/eodashboard-notebooks/build/_assets/app-IZWEOBHI.css"/><link rel="stylesheet" href="/eodashboard-notebooks/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/eodashboard-notebooks/favicon.ico"/><link rel="stylesheet" href="/eodashboard-notebooks/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block lg:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/eodashboard-notebooks/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R74op:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] lg:hidden hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center mb-5 h-6 text-sm font-light"><div class="flex-none pr-2 smallcaps">Notebook examples</div><div class="flex-grow"></div><a href="https://github.com/ESA-eodashboards/eodashboard-notebooks" title="GitHub Repository: ESA-eodashboards/eodashboard-notebooks" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><a href="https://github.com/ESA-eodashboards/eodashboard-notebooks/edit/main/notebooks/nightlights_notebook/Night_Lights_Blending.ipynb" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8top:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">Monitoring socio-economic activities with nighttime light maps</h1></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="s4v4U8Kp2O" class="relative group/block"><h2 id="case-study-creating-nighttime-light-maps-with-color-blending" class="relative group"><span class="heading-text">Case study: Creating nighttime light maps with color blending</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#case-study-creating-nighttime-light-maps-with-color-blending" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="lrQ35enTDL" class="relative group/block"><p>This notebook demonstrates how to create nighttime light variation maps over a time interval (from 2019 to 2022) with additive color blending for studying the distribution of artificial lighting in urban and rural regions, offering insights into urbanization, infrastructure development, and socio-economic activity.
The Nighttime Light Levels indicator can be explored on the EO Dashboard by selecting the EXPLORE DATASETS mode and choosing <a target="_blank" rel="noreferrer" href="https://eodashboard.org/explore?indicator=NTLU&amp;x=12142837.23019&amp;y=4137471.98879&amp;z=5.69238" class="">Night lights indicators</a>.</p><p>The study has been carried out by <strong>Bumpei Tojo PhD (Associate Professor), School of International and Area Studies, Tokyo University of Foreign Studies, Japan</strong>.</p><p>The <strong>PLES Engineering team</strong> (supporting <em>ESA Green Solutions Division</em>, EOP-SG) developed the blending algorithm with the current Notebook implementation and data ingestion on the dashboard (contacts: <strong>Federico Rondoni</strong>, <a target="_blank" rel="noreferrer" href="mailto:f.rondoni@stariongroup.eu" class="">f<wbr/>.rondoni@stariongroup<wbr/>.eu</a>, <strong>Diego Moglioni</strong>, <a target="_blank" rel="noreferrer" href="mailto:d.moglioni@stariongroup.eu" class="">d<wbr/>.moglioni@stariongroup<wbr/>.eu</a>).</p></div><div id="I9Yqc3oplZ" class="relative group/block"><p><img id="s5rCEUM7g8" style="margin:0 auto" src="/eodashboard-notebooks/build/nighttime_northeaste-21f472805eb19cbae2eff3b0562af016.jpg" alt="title" data-canonical-url="data/Nightlights/img/nighttime_northeastern-US.jpg" class=""/>
Example of a nighttime light map covering Northeastern United States during 2019-2022, representing areas where a decrease in nighttime light level occurred (indicating a presumed reduction in social activity) in red, and areas where an increase occurred (indicating a presumed increase in social activity) in blue.</p></div><div id="MNJnXnBzxd" class="relative group/block"><h2 id="input-data" class="relative group"><span class="heading-text">Input data:</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#input-data" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><ul><li><p>This product was developed by JAXA by aggregating the data from the Visible Infrared Imaging Radiometer Suite (VIIRS, onboard the Suomi NPP satellite) on a semi-annual basis (using median image generation) with 10-degree lat/lon (geographic) grid h-v tile as Geo Tiff files.</p></li><li><p>The tiles are 2400 x 2400 pixels, with pixel size of 0.004166 degrees (~464 m at the equator).</p></li><li><p>Metric: nighttime radiance (measured in watts per square centimeter per steradian, [W/cm²/sr]), which represents the brightness of artificial lighting.</p></li></ul></div><div id="QpVLnr4UPn" class="relative group/block"><p><strong>VIIRS 10-degree tile scheme</strong></p><img id="IqzHQr37Ss" style="margin:0 auto" src="/eodashboard-notebooks/build/VIIRS_tiling_scheme-21b55def631a5744fccaf4b7985c2e4f.jpg" alt="VIIRS tiling scheme.JPG" data-canonical-url="data/Nightlights/img/VIIRS_tiling_scheme.jpg" class=""/></div><div id="eIdSCOYNeY" class="relative group/block"><h2 id="running-environment" class="relative group"><span class="heading-text">Running environment:</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#running-environment" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><ul><li><p>This notebook can be run by installing the provided Anaconda Python environment (data/Nightlights/<strong>nightlights-env.yml</strong>).</p></li></ul></div><div id="EhRtM84pvE" class="relative group/block"><h2 id="importing-python-libraries" class="relative group"><span class="heading-text">Importing Python libraries</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#importing-python-libraries" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="nMRfYfoY4c" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">#Import libraries
import os
import sys
import re
import numpy as np
import rasterio
import rioxarray as rxr
import subprocess
from subprocess import Popen, PIPE
import tempfile
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from PIL import Image
import json
from ipyleaflet import Map, ImageOverlay, basemaps</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="V34lCn1KbUkKhoVCAEbXp" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="qO8M9YR6Hz" class="relative group/block"><h2 id="defining-working-folders" class="relative group"><span class="heading-text">Defining working folders</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#defining-working-folders" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="X5PbeEzcQJ" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">input_dir = &quot;input&quot;
input_path = os.path.join(os.getcwd(), &quot;data&quot;, &quot;Nightlights&quot;, input_dir)

output_urban = &quot;output&quot;
urban_path = os.path.join(os.getcwd(), &quot;data&quot;, &quot;Nightlights&quot;, output_urban)

# Create output dir
os.makedirs(urban_path, exist_ok=True)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="DNDpLJDVTwApHlBGTJ2Xi" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="FhhFj7rkp8" class="relative group/block"><h2 id="visualizing-input-data" class="relative group"><span class="heading-text">Visualizing input data</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#visualizing-input-data" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="OZDwnbVJ7e" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">pattern = re.compile(r&quot;h(\d+)v(\d+)_(\d{4})_(\d)H_median\.tif&quot;)

for root, _, files in os.walk(input_path):
    grouped_files = {}
    
    # Grouping files by h and v
    for file in files:
        match = pattern.match(file)
        if match:
            h, v, year, H = match.groups()
            key = (h, v)
            if key not in grouped_files:
                grouped_files[key] = []
            grouped_files[key].append((year, H, os.path.join(root, file))) 
    
    # Process files for plotting
    for (h, v), file_group in grouped_files.items():
        file_group

tuplelist2dict = {c:{&#x27;year&#x27;:a,&#x27;half&#x27;:b} for a,b,c in file_group}
sorted_dict = {}

grid_tile = None
for item in sorted(tuplelist2dict, key = lambda k: (tuplelist2dict[k][&#x27;year&#x27;], tuplelist2dict[k][&#x27;half&#x27;])):
    sorted_dict.update({item:tuplelist2dict[item]})
    grid_tile = item.split(&#x27;/&#x27;)[-1].split(&#x27;_&#x27;)[0]
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="nac9h_l50zoiANVgQFv8t" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="XhylNmo9ZT" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def plot_figures(figures, nrows = 1, ncols=1, factor = 1., clip_range = None, **kwargs):
    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, figsize=(15, 15))
    for idx,file_name in enumerate(figures):
        title = file_name.split(&#x27;/&#x27;)[-1]
        title = title.replace(&quot;_median.tif&quot;, &quot;&quot;)
        axeslist.ravel()[idx].imshow(np.clip(mpimg.imread(file_name)*factor, *clip_range), **kwargs) # cmap=plt.gray(), cmap=&#x27;Greys&#x27;
        axeslist.ravel()[idx].set_title(title)
        axeslist.ravel()[idx].set_axis_off()
    fig.suptitle(r&#x27;Median nighttime light level [$Wcm^{-2}sr^{-1}$]&#x27;, fontsize=20)
    #plt.tight_layout() 

    </code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="0_8QiCnwkcSeRnUp9wog0" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="vsOv2tuoqw" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">plot_figures(sorted_dict, 4, 2, clip_range=(0,1), factor=100./255.)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="haqD4rgv8gENOtSyHwcKt" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/eodashboard-notebooks/build/e28ff140cf45c79316a9514d2838d56a.png" alt="&lt;Figure size 1500x1500 with 8 Axes&gt;"/></div></div><div id="RthL86cCLx" class="relative group/block"><h2 id="applying-color-blending" class="relative group"><span class="heading-text">Applying color blending</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#applying-color-blending" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="lAfyZAPMY3" class="relative group/block"><p>Additive color blending involves mixing the primary colors of light, red (R), green (G), and blue (B), while adjusting their luminance levels. By manipulating the luminance of these colors, a wide range of hues can be achieved, with the key characteristic being that combining all three colors results in white.</p></div><div id="xJyiELSHjI" class="relative group/block"><p>Technique</p><ul><li><p>maximum pixel value of images for 2019 (brightest pixel values) is assigned to red (R)</p></li><li><p>minimum pixel value of images for 2020-2021 (darkest pixel values) is assigned to green (G)</p></li><li><p>maximum pixel value of images for 2022 (brightest pixel values) is assigned to blue (B)</p></li></ul></div><div id="VnvRY81AdY" class="relative group/block"><p>Output</p><ul><li><p>regions where a decrease in nighttime light level occurred are displayed in red</p></li><li><p>areas that experienced an increase (presumed to indicate an increase in social activity) are shown in blue</p></li><li><p>regions where there was no significant change throughout the pandemic are displayed in a gradient from gray to white.</p></li></ul></div><div id="jKxt5yERat" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">pattern = re.compile(r&quot;h(\d+)v(\d+)_(\d{4})_(\d)H_median\.tif&quot;)


def read_and_preprocess(file):
    with rasterio.open(file) as src:
        img = src.read(1)
        img = np.nan_to_num(img, nan=0)  # Replace NaNs with zeros
        return img, src.profile

    
def additive_blending(grouped_files):
    # Process each group of files for blending
    for (h, v), file_group in grouped_files.items():
        # Initialize arrays to store the maximum and minimum values for each year
        max_2019 = None
        min_2020_2021 = None
        max_2022 = None
        
        for year, H, file in file_group:
            img, profile = read_and_preprocess(file)
            
            if year == &#x27;2019&#x27;:
                if max_2019 is None:
                    max_2019 = img
                else:
                    max_2019 = np.maximum(max_2019, img)
            elif year in [&#x27;2020&#x27;, &#x27;2021&#x27;]:
                if min_2020_2021 is None:
                    min_2020_2021 = img
                else:
                    min_2020_2021 = np.minimum(min_2020_2021, img)
            elif year == &#x27;2022&#x27;:
                if max_2022 is None:
                    max_2022 = img
                else:
                    max_2022 = np.maximum(max_2022, img)
                                  
    # Create the blended image using the specified blending technique
    blended_img = np.zeros((max_2019.shape[0], max_2019.shape[1], 3), dtype=np.float32)
    blended_img[:, :, 0] = max_2019.astype(np.float32)  # Red band: maximum of 2019
    blended_img[:, :, 1] = min_2020_2021.astype(np.float32)  # Green band: minimum of 2020-2021 compared
    blended_img[:, :, 2] = max_2022.astype(np.float32)  # Blue band: maximum of 2022
    
    return blended_img, profile        </code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="-GD9s376Y7bIIbh1Df8kJ" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="gBIRWpPviJ" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Grouping files per (h,v) tiles and years span
grouped_files = {}
for root, _, files in os.walk(input_path):
    
    
    # Group files by h and v
    for file in files:
        match = pattern.match(file)
        if match:
            h, v, year, H = match.groups()
            key = (h, v)
            if key not in grouped_files:
                grouped_files[key] = []
            grouped_files[key].append((year, H, os.path.join(root, file)))


# blending           
blended_img, profile = additive_blending(grouped_files)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="WhZXbRTJQ6ry2X3T2Ap-V" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="Vy4byuYekD" class="relative group/block"><h2 id="employing-urban-stretch-processing" class="relative group"><span class="heading-text">Employing “urban” stretch processing</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#employing-urban-stretch-processing" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="wCn5R69rSb" class="relative group/block"><p>The purpose of the stretch processing is to emphasize the nighttime light level of each band (corresponding to 2019, 2020-21, and 2022), focusing on:</p><ul><li><p>“urban” nighttime light levels: the display range of each band is adjusted to 25-1000 [watts·cm-2·sr-1], emphasizing brighter areas</p></li></ul></div><div id="uTtCrNUM3v" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Urban stretch processing: Emphasize brighter areas
def urban_stretch_processing(band):
    min_val = 25
    max_val = 1000
    band = np.clip(band, min_val, max_val)
    band = (band - min_val) / (max_val - min_val) * 255
    return band.astype(np.uint8)

# Apply urban stretch processing to each band
blended_img[:, :, 0] = urban_stretch_processing(blended_img[:, :, 0])
blended_img[:, :, 1] = urban_stretch_processing(blended_img[:, :, 1])
blended_img[:, :, 2] = urban_stretch_processing(blended_img[:, :, 2])
        
# Update the profile for a 3-band image and set nodata value to None
profile.update(count=3, dtype=rasterio.uint8, nodata=None)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="jtpJMigVF9fSMjkH46iK0" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="kjTh1oYMT6" class="relative group/block"><h2 id="plotting-blended-image" class="relative group"><span class="heading-text">Plotting blended image</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#plotting-blended-image" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="o76z9PnLZW" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def plot_image(image, factor=1.0, clip_range = None, **kwargs):
    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))
    if clip_range is not None:
        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)
    else:
        ax.imshow(image * factor, **kwargs)
    ax.set_xticks([])
    ax.set_yticks([])


plot_image(blended_img, factor=1.5/255., clip_range=(0,1))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="1srNv3pYswN7XJSRnv68C" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><img src="/eodashboard-notebooks/build/0049010c11ccd43435e422180285ddb2.png" alt="&lt;Figure size 1500x1500 with 1 Axes&gt;"/></div></div><div id="an0LMDrTYn" class="relative group/block"><h2 id="overlaying-with-an-interactive-map" class="relative group"><span class="heading-text">Overlaying with an interactive map</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#overlaying-with-an-interactive-map" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="bGufaKWk9T" class="relative group/block"><p>Saving blended image as Cloud Optimized GeoTIFF</p></div><div id="NC6PJtRmrE" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Exporting output as COG file 
res_name = f&quot;Nighttimelevel_Urban_{grid_tile}_2019-2022.tif&quot;
output_cog = os.path.join(urban_path, res_name)


# Write the blended image directly to a temporary file
with tempfile.NamedTemporaryFile(suffix=&quot;.tif&quot;) as temp_file:
    with rasterio.open(temp_file.name, &quot;w&quot;, **profile) as dst:
        dst.write(blended_img[:, :, 0], 1)
        dst.write(blended_img[:, :, 1], 2)
        dst.write(blended_img[:, :, 2], 3)

    subprocess.run([
        &quot;gdal_translate&quot;, &quot;-of&quot;, &quot;COG&quot;,
        &quot;-co&quot;, &quot;COMPRESS=DEFLATE&quot;,
        &quot;-co&quot;, &quot;BLOCKSIZE=512&quot;,
        &quot;-co&quot;, &quot;RESAMPLING=NEAREST&quot;,
        &quot;-co&quot;, &quot;OVERVIEWS=IGNORE_EXISTING&quot;,
        temp_file.name,
        output_cog
    ])

print(f&quot;COG file saved as {output_cog}&quot;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="wdSa6YsIUDpapwihuPcCT" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Input file size is 2400, 2400
0...10...20...30...40...50...60...70...80...90...100 - done.
COG file saved as out_urban/Nighttimelevel_Urban_h10v04_2019-2022.tif
</span></code></pre></div></div></div><div id="wzDN2ODyVh" class="relative group/block"><p>Extracting bounding-box coordinates</p></div><div id="wIODWq8PDN" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">p1 = Popen([&quot;gdalinfo&quot;, &quot;-json&quot;, output_cog, &quot;-mm&quot;], stdout=PIPE)
output = p1.communicate()[0]
dec_out = output.decode(&#x27;utf-8&#x27;)
j_str = json.loads(dec_out)
bbox = j_str[&#x27;cornerCoordinates&#x27;]
ll = bbox[&#x27;lowerLeft&#x27;]  # SW coo
ur = bbox[&#x27;upperRight&#x27;] # NE coo
center = bbox[&#x27;center&#x27;]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="bnQBc__LoX6fT7ihDuq68" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="U7fzNdb9vC" class="relative group/block"><p>Adding alpha channel to the blended image</p></div><div id="nSlBLDzhyg" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def almostEquals(a,b,thres=50):
    return all(abs(a[i]-b[i])&lt;thres for i in range(len(a)))


image = Image.open(output_cog).convert(&#x27;RGBA&#x27;)
pixeldata = list(image.getdata())


for i,pixel in enumerate(pixeldata):
    if almostEquals(pixel[:3], (0,0,0)):
        pixeldata[i] = (0,0,0,0)


image.putdata(pixeldata)
png_path = os.path.join(urban_path, res_name.replace(&quot;.tif&quot;,&quot;.png&quot;))
res = image.save(png_path)
#os.path.abspath(res)
abs_path = os.path.abspath(png_path)
work_dir = os.getcwd()
id_ = work_dir.split(&#x27;/&#x27;)[2]
base_url = os.path.join(&#x27;https://hub-otc-sc.eox.at/user&#x27;,id_,&#x27;files&#x27;)
#base_url
abs_path = &#x27;/&#x27;.join(abs_path.split(&#x27;/&#x27;)[3:])
#abs_path
#os.path.join(base_url,abs_path)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="OF8rDzc4Eer8HYPbGPsU3" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="r07baZEpDG" class="relative group/block"><p>Overlay with OpenStreetMap</p></div><div id="sKroBpk0Xn" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">m = Map(basemap=basemaps.CartoDB.DarkMatter, center=(center[1], center[0]), zoom=6)
image = ImageOverlay(
        url=os.path.join(base_url,abs_path), #url=&quot;https://hub-otc-sc.eox.at/user/&lt;id&gt;/files/&lt;path_to_png&gt;
        bounds=((ll[1], ll[0]), (ur[1], ur[0])) # SW and NE corners
                    )
m.add_layer(image);
m</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="QS9TI7r9Ptj6fSv51Jhja" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="qWplQFWWpL" class="relative group/block"><p>Using additive color blending images to focus on urban areas in the northeastern United States, particularly the southern part of the Boston-Washington Corridor comprising major cities like New York, Philadelphia, Baltimore, and Washington, D.C., revealed relatively little variation in nighttime lights before and after the COVID-19 pandemic, as indicated by the images appearing white. However, significant reductions in nighttime lights during the COVID-19 pandemic (subsequently recovering to pre-pandemic levels) were evident in other medium to large cities, including Boston and Toronto, among others, as indicated by the images appearing pink to reddish.</p></div><div id="M5NWKEKwor" class="relative group/block"><h2 id="alternative-stretch-processing-approaches" class="relative group"><span class="heading-text">Alternative stretch processing approaches</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#alternative-stretch-processing-approaches" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="xNPCCArIUK" class="relative group/block"><ul><li><p>“Rural” nighttime light levels: setting each band’s display range to 0-50 [Watts·cm-2·sr-1] to emphasize darker areas</p></li><li><p>For a broader focus (from rural to urban areas): applying a log10 transformation to the values of each band with a display range set to 0-3.6 (equivalent to 0-3981 [Watts·cm-2·sr-1])</p></li></ul></div><div id="kKjIC351nj" class="relative group/block"><h2 id="final-remarks" class="relative group"><span class="heading-text">Final remarks</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#final-remarks" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="U77VPCBF8D" class="relative group/block"><p>This product has been specifically designed for utilization by researchers in applied scientific fields.
Potential applications are being explored in environmental and social issue studies, such as disaster recovery, energy, urban land use changes, conflicts, migration, and monitoring of illegal, unreported activities.</p></div><div id="JzlzxfapK0" class="relative group/block"><h2 id="to-learn-more" class="relative group"><span class="heading-text">To learn more</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#to-learn-more" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="rOPmtpyxHj" class="relative group/block"><p>The presented approach is often referenced in scientific and public health research. For example, Bunpei Tojo (2021) used Nightlights data in the study “Application of Earth observation satellite data to public health: Comparison of night light (VIIRS) and solar radiation (SGLI) and domestic COVID-19 epidemic,” presented at the 12th Federation of Science and Technology conference, to analyze the relationship between nighttime light intensity and public health factors.
<cite class="" data-state="closed"><a href="https://doi.org/10.11487/oukan.2021.0_B-4-4" target="_blank" rel="noreferrer" class="hover-link">東城 (2021)</a></cite>.</p></div><div></div><section id="references" class="article-grid subgrid-gap col-screen"><div><header class="text-lg font-semibold text-stone-900 dark:text-white group">References<a class="no-underline text-inherit hover:text-inherit ml-2 select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#references" title="Link to References" aria-label="Link to References">¶</a></header></div><div class="pl-3 mb-8 text-xs text-stone-500 dark:text-stone-300"><ol><li class="break-words" id="cite-2021">東城文柄. (2021). 地球観測衛星データの公衆衛生学への応用. In <i>横幹連合コンファレンス予稿集</i> (No. 0; Vol. 2021). 特定非営利活動法人　横断型基幹科学技術研究団体連合. <a target="_blank" rel="noreferrer" href="https://doi.org/10.11487/oukan.2021.0_B-4-4">10.11487/oukan.2021.0_B-4-4</a></li></ol></div></section></article></main><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/eodashboard-notebooks/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/eodashboard-notebooks/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/eodashboard-notebooks/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/eodashboard-notebooks/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/eodashboard-notebooks/build/_shared/chunk-F7G67JTZ.js"/><link rel="modulepreload" href="/eodashboard-notebooks/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/eodashboard-notebooks/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/eodashboard-notebooks/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/eodashboard-notebooks/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/eodashboard-notebooks/build/_shared/chunk-CPTH56EW.js"/><link rel="modulepreload" href="/eodashboard-notebooks/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/eodashboard-notebooks/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/eodashboard-notebooks/build/_shared/chunk-S4SWV34C.js"/><link rel="modulepreload" href="/eodashboard-notebooks/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/eodashboard-notebooks/build/root-7TUVC4ZT.js"/><link rel="modulepreload" href="/eodashboard-notebooks/build/_shared/chunk-INOWNUZ6.js"/><link rel="modulepreload" href="/eodashboard-notebooks/build/routes/$-P6PGXPYX.js"/><script>window.__remixContext = {"url":"/notebooks/nightlights-notebook/night-lights-blending","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.6.4","options":{"hide_toc":true,"hide_footer_links":true,"folders":true,"style":"/eodashboard-notebooks/build/custom-ce935da4963069cf292848ffc2c29675.css"},"nav":[],"actions":[],"projects":[{"subject":"Notebook examples","title":"EO Dashboard Notebooks","description":"Collection of examples relevant to the EO Dashboard project","github":"https://github.com/ESA-eodashboards/eodashboard-notebooks","id":"5aa0318b-5bc1-41e2-b1d4-053e8b61961b","exports":[],"bibliography":[],"index":"readme","pages":[{"title":"External Notebooks","level":1},{"title":"Group1","level":2},{"title":"2025 Bi DS EO Dashboard","level":3},{"slug":"external-notebooks.group1.2025-bids-eodashboard.readme","title":"2025-BiDS-EODashboard","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":4},{"title":"Notebook","level":4},{"slug":"external-notebooks.group1.2025-bids-eodashboard.notebook.urban-health-and-megacities","title":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/header-91647aee0f45b9db42b78b9ec04730b6.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":5},{"title":"Notebooks","level":1},{"slug":"notebooks.fire-impact-analysis","title":"Evaluation of Fire Impact on Populated Areas on a European Site","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/22a5ee1ff975cb9c3eb3b1e899bb858e.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.inland-water-with-edc","title":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.oceanographic-patterns-clustering","title":"\u003ca name=\"toc\"\u003e\u003c/a\u003e\u003cspan style='color:DarkCyan'\u003e Table of Contents \u003c/center\u003e \u003c/span\u003e","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/a737ae6d2b7cf4511053168c9e99be3b.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.openchallangenotebook-team-5-challenge-3-timeserie","title":"Earth System Science Hub Challenge 3: Time series interpolation techniques for remote sensing - Fran, Denise, Mae","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/a737ae6d2b7cf4511053168c9e99be3b.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.openchallengenotebook-c1-jessel-hezzi-roussel","title":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/49e045ccedfe842015ba44cc25ccb377.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.veda-api-bids-2023","title":"Using the NASA VEDA EOAPI","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/5d71b8fb32fb3d611031d0ea697e5422.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"Eodashboard STAC Access","level":2},{"slug":"notebooks.eodashboard-stac-access.eodashboard-stac-access","title":"EODashboard STAC access examples","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/ff5b0d0faa9a9d99644d137afe5bbd92.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"title":"Nightlights Notebook","level":2},{"slug":"notebooks.nightlights-notebook.night-lights-blending","title":"Monitoring socio-economic activities with nighttime light maps","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/nighttime_northeaste-21f472805eb19cbae2eff3b0562af016.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static","BASE_URL":"/eodashboard-notebooks"},"routes/$":{"config":{"version":2,"myst":"1.6.4","options":{"hide_toc":true,"hide_footer_links":true,"folders":true,"style":"/eodashboard-notebooks/build/custom-ce935da4963069cf292848ffc2c29675.css"},"nav":[],"actions":[],"projects":[{"subject":"Notebook examples","title":"EO Dashboard Notebooks","description":"Collection of examples relevant to the EO Dashboard project","github":"https://github.com/ESA-eodashboards/eodashboard-notebooks","id":"5aa0318b-5bc1-41e2-b1d4-053e8b61961b","exports":[],"bibliography":[],"index":"readme","pages":[{"title":"External Notebooks","level":1},{"title":"Group1","level":2},{"title":"2025 Bi DS EO Dashboard","level":3},{"slug":"external-notebooks.group1.2025-bids-eodashboard.readme","title":"2025-BiDS-EODashboard","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":4},{"title":"Notebook","level":4},{"slug":"external-notebooks.group1.2025-bids-eodashboard.notebook.urban-health-and-megacities","title":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/header-91647aee0f45b9db42b78b9ec04730b6.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":5},{"title":"Notebooks","level":1},{"slug":"notebooks.fire-impact-analysis","title":"Evaluation of Fire Impact on Populated Areas on a European Site","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/22a5ee1ff975cb9c3eb3b1e899bb858e.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.inland-water-with-edc","title":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.oceanographic-patterns-clustering","title":"\u003ca name=\"toc\"\u003e\u003c/a\u003e\u003cspan style='color:DarkCyan'\u003e Table of Contents \u003c/center\u003e \u003c/span\u003e","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/a737ae6d2b7cf4511053168c9e99be3b.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.openchallangenotebook-team-5-challenge-3-timeserie","title":"Earth System Science Hub Challenge 3: Time series interpolation techniques for remote sensing - Fran, Denise, Mae","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/a737ae6d2b7cf4511053168c9e99be3b.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.openchallengenotebook-c1-jessel-hezzi-roussel","title":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/49e045ccedfe842015ba44cc25ccb377.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.veda-api-bids-2023","title":"Using the NASA VEDA EOAPI","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/5d71b8fb32fb3d611031d0ea697e5422.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"Eodashboard STAC Access","level":2},{"slug":"notebooks.eodashboard-stac-access.eodashboard-stac-access","title":"EODashboard STAC access examples","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/ff5b0d0faa9a9d99644d137afe5bbd92.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"title":"Nightlights Notebook","level":2},{"slug":"notebooks.nightlights-notebook.night-lights-blending","title":"Monitoring socio-economic activities with nighttime light maps","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/nighttime_northeaste-21f472805eb19cbae2eff3b0562af016.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3}]}]},"page":{"version":2,"kind":"Notebook","sha256":"24228ddf9fee84a1f8cccfb2548317498e579622e4710b6761511b95ece1eeee","slug":"notebooks.nightlights-notebook.night-lights-blending","location":"/notebooks/nightlights_notebook/Night_Lights_Blending.ipynb","dependencies":[],"frontmatter":{"title":"Monitoring socio-economic activities with nighttime light maps","content_includes_title":false,"kernelspec":{"name":"eodashboardlps25-lps25-tutorial-dashboards","display_name":"lps25-tutorial-dashboards","language":"python"},"github":"https://github.com/ESA-eodashboards/eodashboard-notebooks","subject":"Notebook examples","numbering":{"title":{"offset":2}},"source_url":"https://github.com/ESA-eodashboards/eodashboard-notebooks/blob/main/notebooks/nightlights_notebook/Night_Lights_Blending.ipynb","edit_url":"https://github.com/ESA-eodashboards/eodashboard-notebooks/edit/main/notebooks/nightlights_notebook/Night_Lights_Blending.ipynb","thumbnail":"/eodashboard-notebooks/build/nighttime_northeaste-21f472805eb19cbae2eff3b0562af016.jpg","exports":[{"format":"ipynb","filename":"Night_Lights_Blending.ipynb","url":"/eodashboard-notebooks/build/Night_Lights_Blendin-49ecddf966b287651102c283ea570707.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Case study: Creating nighttime light maps with color blending","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"IGEtDgd2c4"}],"identifier":"case-study-creating-nighttime-light-maps-with-color-blending","label":"Case study: Creating nighttime light maps with color blending","html_id":"case-study-creating-nighttime-light-maps-with-color-blending","implicit":true,"key":"T3AoFvlyLv"}],"key":"s4v4U8Kp2O"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"This notebook demonstrates how to create nighttime light variation maps over a time interval (from 2019 to 2022) with additive color blending for studying the distribution of artificial lighting in urban and rural regions, offering insights into urbanization, infrastructure development, and socio-economic activity.\nThe Nighttime Light Levels indicator can be explored on the EO Dashboard by selecting the EXPLORE DATASETS mode and choosing ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cC4EQqtMK9"},{"type":"link","url":"https://eodashboard.org/explore?indicator=NTLU\u0026x=12142837.23019\u0026y=4137471.98879\u0026z=5.69238","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Night lights indicators","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"d5MDNmFVYe"}],"urlSource":"https://eodashboard.org/explore?indicator=NTLU\u0026x=12142837.23019\u0026y=4137471.98879\u0026z=5.69238","key":"B0gfc8oEGr"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cDgU2wpox3"}],"key":"RYKO8iTROm"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"The study has been carried out by ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"vgKee9DkR8"},{"type":"strong","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Bumpei Tojo PhD (Associate Professor), School of International and Area Studies, Tokyo University of Foreign Studies, Japan","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"zMg7kjLBxN"}],"key":"aHTH8NB1tT"},{"type":"text","value":".","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"DpUToU7zdk"}],"key":"V3obl5VpWK"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"Mt2JHrYdJn"},{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"PLES Engineering team","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"AOROaD2xza"}],"key":"ImgzzZ0Y2C"},{"type":"text","value":" (supporting ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"TFIQEO1tp2"},{"type":"emphasis","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"ESA Green Solutions Division","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"hbnwO9qAr5"}],"key":"NKzFPLN7VE"},{"type":"text","value":", EOP-SG) developed the blending algorithm with the current Notebook implementation and data ingestion on the dashboard (contacts: ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"yehagvXaAG"},{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Federico Rondoni","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"K3kj2JcLQK"}],"key":"QeV3rX9l0a"},{"type":"text","value":", ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"xvKJnK99vY"},{"type":"link","url":"mailto:f.rondoni@stariongroup.eu","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"f​.rondoni@stariongroup​.eu","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"wUADTJqgel"}],"urlSource":"mailto:f.rondoni@stariongroup.eu","key":"T4RR19aPGi"},{"type":"text","value":", ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"YW7r1yjXFi"},{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Diego Moglioni","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"B8SiWhE7of"}],"key":"koYQ35DFMz"},{"type":"text","value":", ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"aAUzeTBO7Z"},{"type":"link","url":"mailto:d.moglioni@stariongroup.eu","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"d​.moglioni@stariongroup​.eu","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"CUrefqoiXL"}],"urlSource":"mailto:d.moglioni@stariongroup.eu","key":"rkApepqtN0"},{"type":"text","value":").","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"KknK6qYszz"}],"key":"zgihrxm8G5"}],"key":"lrQ35enTDL"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"image","url":"/eodashboard-notebooks/build/nighttime_northeaste-21f472805eb19cbae2eff3b0562af016.jpg","alt":"title","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"s5rCEUM7g8","urlSource":"data/Nightlights/img/nighttime_northeastern-US.jpg"},{"type":"text","value":"\nExample of a nighttime light map covering Northeastern United States during 2019-2022, representing areas where a decrease in nighttime light level occurred (indicating a presumed reduction in social activity) in red, and areas where an increase occurred (indicating a presumed increase in social activity) in blue.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vJor4KFSof"}],"key":"y9ifwXPzje"}],"key":"I9Yqc3oplZ"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Input data:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dQ5TSKwNUR"}],"identifier":"input-data","label":"Input data:","html_id":"input-data","implicit":true,"key":"hJpvqKnaDb"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"This product was developed by JAXA by aggregating the data from the Visible Infrared Imaging Radiometer Suite (VIIRS, onboard the Suomi NPP satellite) on a semi-annual basis (using median image generation) with 10-degree lat/lon (geographic) grid h-v tile as Geo Tiff files.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"omU06KgeOS"}],"key":"b8maS4iqYw"}],"key":"aP2t10ZpM5"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The tiles are 2400 x 2400 pixels, with pixel size of 0.004166 degrees (~464 m at the equator).","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"DurXEbS1GD"}],"key":"nmJz9nijQ6"}],"key":"dBP3cARYUc"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Metric: nighttime radiance (measured in watts per square centimeter per steradian, [W/cm²/sr]), which represents the brightness of artificial lighting.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"dBcIohfnq8"}],"key":"khmrbV2k50"}],"key":"hCK4hpoQco"}],"key":"fbOtCVIY4s"}],"key":"MNJnXnBzxd"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"VIIRS 10-degree tile scheme","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"AM2lugiFS6"}],"key":"DdFxrrkvPY"}],"key":"bysoeknnaY"},{"type":"image","url":"/eodashboard-notebooks/build/VIIRS_tiling_scheme-21b55def631a5744fccaf4b7985c2e4f.jpg","alt":"VIIRS tiling scheme.JPG","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"IqzHQr37Ss","urlSource":"data/Nightlights/img/VIIRS_tiling_scheme.jpg"}],"key":"QpVLnr4UPn"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Running environment:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"m2a7aOEydZ"}],"identifier":"running-environment","label":"Running environment:","html_id":"running-environment","implicit":true,"key":"XXPxyBPUFI"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"This notebook can be run by installing the provided Anaconda Python environment (data/Nightlights/","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Tmqp7GKrfk"},{"type":"strong","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"nightlights-env.yml","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"EPE9RBSg8H"}],"key":"rvtb8o9pZp"},{"type":"text","value":").","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"gWi3KZf4JC"}],"key":"QR9O7Yh2wN"}],"key":"w3d5LSlYxt"}],"key":"aKgCJq0N0s"}],"key":"eIdSCOYNeY"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Importing Python libraries","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SdQPfRHYHn"}],"identifier":"importing-python-libraries","label":"Importing Python libraries","html_id":"importing-python-libraries","implicit":true,"key":"sJpjT9aJVD"}],"key":"EhRtM84pvE"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#Import libraries\nimport os\nimport sys\nimport re\nimport numpy as np\nimport rasterio\nimport rioxarray as rxr\nimport subprocess\nfrom subprocess import Popen, PIPE\nimport tempfile\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom PIL import Image\nimport json\nfrom ipyleaflet import Map, ImageOverlay, basemaps","key":"VAwjD7VAR7"},{"type":"output","id":"V34lCn1KbUkKhoVCAEbXp","data":[],"key":"Vl70rJuEmO"}],"key":"nMRfYfoY4c"},{"type":"block","kind":"notebook-content","data":{"tags":[]},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Defining working folders","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KCerfDCpzE"}],"identifier":"defining-working-folders","label":"Defining working folders","html_id":"defining-working-folders","implicit":true,"key":"n2ROqrSRC5"}],"visibility":"show","key":"qO8M9YR6Hz"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"input_dir = \"input\"\ninput_path = os.path.join(os.getcwd(), \"data\", \"Nightlights\", input_dir)\n\noutput_urban = \"output\"\nurban_path = os.path.join(os.getcwd(), \"data\", \"Nightlights\", output_urban)\n\n# Create output dir\nos.makedirs(urban_path, exist_ok=True)","visibility":"show","key":"b1bwJeKLr4"},{"type":"output","id":"DNDpLJDVTwApHlBGTJ2Xi","data":[],"visibility":"show","key":"WaZqcJUh5n"}],"visibility":"show","key":"X5PbeEzcQJ"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Visualizing input data","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NrxczVnpq5"}],"identifier":"visualizing-input-data","label":"Visualizing input data","html_id":"visualizing-input-data","implicit":true,"key":"CPLEN8w7m1"}],"key":"FhhFj7rkp8"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"pattern = re.compile(r\"h(\\d+)v(\\d+)_(\\d{4})_(\\d)H_median\\.tif\")\n\nfor root, _, files in os.walk(input_path):\n    grouped_files = {}\n    \n    # Grouping files by h and v\n    for file in files:\n        match = pattern.match(file)\n        if match:\n            h, v, year, H = match.groups()\n            key = (h, v)\n            if key not in grouped_files:\n                grouped_files[key] = []\n            grouped_files[key].append((year, H, os.path.join(root, file))) \n    \n    # Process files for plotting\n    for (h, v), file_group in grouped_files.items():\n        file_group\n\ntuplelist2dict = {c:{'year':a,'half':b} for a,b,c in file_group}\nsorted_dict = {}\n\ngrid_tile = None\nfor item in sorted(tuplelist2dict, key = lambda k: (tuplelist2dict[k]['year'], tuplelist2dict[k]['half'])):\n    sorted_dict.update({item:tuplelist2dict[item]})\n    grid_tile = item.split('/')[-1].split('_')[0]\n","visibility":"show","key":"q1QTNCLvv1"},{"type":"output","id":"nac9h_l50zoiANVgQFv8t","data":[],"visibility":"show","key":"vKf8kXeqAN"}],"visibility":"show","key":"OZDwnbVJ7e"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"def plot_figures(figures, nrows = 1, ncols=1, factor = 1., clip_range = None, **kwargs):\n    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, figsize=(15, 15))\n    for idx,file_name in enumerate(figures):\n        title = file_name.split('/')[-1]\n        title = title.replace(\"_median.tif\", \"\")\n        axeslist.ravel()[idx].imshow(np.clip(mpimg.imread(file_name)*factor, *clip_range), **kwargs) # cmap=plt.gray(), cmap='Greys'\n        axeslist.ravel()[idx].set_title(title)\n        axeslist.ravel()[idx].set_axis_off()\n    fig.suptitle(r'Median nighttime light level [$Wcm^{-2}sr^{-1}$]', fontsize=20)\n    #plt.tight_layout() \n\n    ","visibility":"show","key":"SXA2GRgIOm"},{"type":"output","id":"0_8QiCnwkcSeRnUp9wog0","data":[],"visibility":"show","key":"wyCH2iHpAz"}],"visibility":"show","key":"XhylNmo9ZT"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"plot_figures(sorted_dict, 4, 2, clip_range=(0,1), factor=100./255.)","visibility":"show","key":"deCDzNnPK1"},{"type":"output","id":"haqD4rgv8gENOtSyHwcKt","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"e28ff140cf45c79316a9514d2838d56a","path":"/eodashboard-notebooks/build/e28ff140cf45c79316a9514d2838d56a.png"},"text/plain":{"content":"\u003cFigure size 1500x1500 with 8 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"NXrNJtMSGG"}],"visibility":"show","key":"vsOv2tuoqw"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Applying color blending","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pWbehGlfIw"}],"identifier":"applying-color-blending","label":"Applying color blending","html_id":"applying-color-blending","implicit":true,"key":"oohSzQHFML"}],"key":"RthL86cCLx"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Additive color blending involves mixing the primary colors of light, red (R), green (G), and blue (B), while adjusting their luminance levels. By manipulating the luminance of these colors, a wide range of hues can be achieved, with the key characteristic being that combining all three colors results in white.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"I1m6ijxfyh"}],"key":"DnrmOWbmYr"}],"key":"lAfyZAPMY3"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Technique","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"No2qC8Ynmn"}],"key":"R7zjSAvpEb"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"maximum pixel value of images for 2019 (brightest pixel values) is assigned to red (R)","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"RB2maIkUqr"}],"key":"zo3RIFUqaC"}],"key":"nIbE8OmsJO"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"minimum pixel value of images for 2020-2021 (darkest pixel values) is assigned to green (G)","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"r7QHqzg2oe"}],"key":"pW8a1uNZ5Q"}],"key":"IlSPO4qSxt"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"maximum pixel value of images for 2022 (brightest pixel values) is assigned to blue (B)","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"s4xAfC44vb"}],"key":"P5E90w3EQw"}],"key":"HszbVtHeFU"}],"key":"AAWKqNZIST"}],"key":"xJyiELSHjI"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Output","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ThXU0u8HpF"}],"key":"XXNhbud3sg"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"regions where a decrease in nighttime light level occurred are displayed in red","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Uf9hDpuVFm"}],"key":"fSVcmQKtZn"}],"key":"oZCDGK3PtD"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"areas that experienced an increase (presumed to indicate an increase in social activity) are shown in blue","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"CvydUjXG4p"}],"key":"XMzZFhoZcf"}],"key":"AaXQRMoOdn"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"regions where there was no significant change throughout the pandemic are displayed in a gradient from gray to white.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"i1UuH2wviV"}],"key":"nKmECRDBTW"}],"key":"rryVBSIuct"}],"key":"ktpFgrRMeB"}],"key":"VnvRY81AdY"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"pattern = re.compile(r\"h(\\d+)v(\\d+)_(\\d{4})_(\\d)H_median\\.tif\")\n\n\ndef read_and_preprocess(file):\n    with rasterio.open(file) as src:\n        img = src.read(1)\n        img = np.nan_to_num(img, nan=0)  # Replace NaNs with zeros\n        return img, src.profile\n\n    \ndef additive_blending(grouped_files):\n    # Process each group of files for blending\n    for (h, v), file_group in grouped_files.items():\n        # Initialize arrays to store the maximum and minimum values for each year\n        max_2019 = None\n        min_2020_2021 = None\n        max_2022 = None\n        \n        for year, H, file in file_group:\n            img, profile = read_and_preprocess(file)\n            \n            if year == '2019':\n                if max_2019 is None:\n                    max_2019 = img\n                else:\n                    max_2019 = np.maximum(max_2019, img)\n            elif year in ['2020', '2021']:\n                if min_2020_2021 is None:\n                    min_2020_2021 = img\n                else:\n                    min_2020_2021 = np.minimum(min_2020_2021, img)\n            elif year == '2022':\n                if max_2022 is None:\n                    max_2022 = img\n                else:\n                    max_2022 = np.maximum(max_2022, img)\n                                  \n    # Create the blended image using the specified blending technique\n    blended_img = np.zeros((max_2019.shape[0], max_2019.shape[1], 3), dtype=np.float32)\n    blended_img[:, :, 0] = max_2019.astype(np.float32)  # Red band: maximum of 2019\n    blended_img[:, :, 1] = min_2020_2021.astype(np.float32)  # Green band: minimum of 2020-2021 compared\n    blended_img[:, :, 2] = max_2022.astype(np.float32)  # Blue band: maximum of 2022\n    \n    return blended_img, profile        ","key":"LQvvh4tFMv"},{"type":"output","id":"-GD9s376Y7bIIbh1Df8kJ","data":[],"key":"WGuV4qGCLU"}],"key":"jKxt5yERat"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Grouping files per (h,v) tiles and years span\ngrouped_files = {}\nfor root, _, files in os.walk(input_path):\n    \n    \n    # Group files by h and v\n    for file in files:\n        match = pattern.match(file)\n        if match:\n            h, v, year, H = match.groups()\n            key = (h, v)\n            if key not in grouped_files:\n                grouped_files[key] = []\n            grouped_files[key].append((year, H, os.path.join(root, file)))\n\n\n# blending           \nblended_img, profile = additive_blending(grouped_files)","visibility":"show","key":"L3m1pJ1MLq"},{"type":"output","id":"WhZXbRTJQ6ry2X3T2Ap-V","data":[],"visibility":"show","key":"pqO3YS7II1"}],"visibility":"show","key":"gBIRWpPviJ"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Employing “urban” stretch processing","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uKXWpMACCf"}],"identifier":"employing-urban-stretch-processing","label":"Employing “urban” stretch processing","html_id":"employing-urban-stretch-processing","implicit":true,"key":"RhEvYuiEO2"}],"key":"Vy4byuYekD"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The purpose of the stretch processing is to emphasize the nighttime light level of each band (corresponding to 2019, 2020-21, and 2022), focusing on:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zgr9SuIcsy"}],"key":"ZF1z1UrKRp"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"“urban” nighttime light levels: the display range of each band is adjusted to 25-1000 [watts·cm-2·sr-1], emphasizing brighter areas","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"rTTfgd6pXd"}],"key":"CKns1hUB5s"}],"key":"zUqyHvKVGs"}],"key":"EZ1jnszCyq"}],"key":"wCn5R69rSb"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Urban stretch processing: Emphasize brighter areas\ndef urban_stretch_processing(band):\n    min_val = 25\n    max_val = 1000\n    band = np.clip(band, min_val, max_val)\n    band = (band - min_val) / (max_val - min_val) * 255\n    return band.astype(np.uint8)\n\n# Apply urban stretch processing to each band\nblended_img[:, :, 0] = urban_stretch_processing(blended_img[:, :, 0])\nblended_img[:, :, 1] = urban_stretch_processing(blended_img[:, :, 1])\nblended_img[:, :, 2] = urban_stretch_processing(blended_img[:, :, 2])\n        \n# Update the profile for a 3-band image and set nodata value to None\nprofile.update(count=3, dtype=rasterio.uint8, nodata=None)","visibility":"show","key":"etGjHTNYR0"},{"type":"output","id":"jtpJMigVF9fSMjkH46iK0","data":[],"visibility":"show","key":"DDONbEEOPz"}],"visibility":"show","key":"uTtCrNUM3v"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Plotting blended image","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fSnZsKZQgb"}],"identifier":"plotting-blended-image","label":"Plotting blended image","html_id":"plotting-blended-image","implicit":true,"key":"rEInz5S2Bu"}],"key":"kjTh1oYMT6"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"def plot_image(image, factor=1.0, clip_range = None, **kwargs):\n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n    if clip_range is not None:\n        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n    else:\n        ax.imshow(image * factor, **kwargs)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n\nplot_image(blended_img, factor=1.5/255., clip_range=(0,1))","visibility":"show","key":"qqeZTsvajY"},{"type":"output","id":"1srNv3pYswN7XJSRnv68C","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"0049010c11ccd43435e422180285ddb2","path":"/eodashboard-notebooks/build/0049010c11ccd43435e422180285ddb2.png"},"text/plain":{"content":"\u003cFigure size 1500x1500 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"kUNf2hrYwp"}],"visibility":"show","key":"o76z9PnLZW"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Overlaying with an interactive map","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"E3os90UJjR"}],"identifier":"overlaying-with-an-interactive-map","label":"Overlaying with an interactive map","html_id":"overlaying-with-an-interactive-map","implicit":true,"key":"aikP7DRzkF"}],"key":"an0LMDrTYn"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Saving blended image as Cloud Optimized GeoTIFF","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cdcY5WQn1K"}],"key":"Tnw5OSVoKB"}],"key":"bGufaKWk9T"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Exporting output as COG file \nres_name = f\"Nighttimelevel_Urban_{grid_tile}_2019-2022.tif\"\noutput_cog = os.path.join(urban_path, res_name)\n\n\n# Write the blended image directly to a temporary file\nwith tempfile.NamedTemporaryFile(suffix=\".tif\") as temp_file:\n    with rasterio.open(temp_file.name, \"w\", **profile) as dst:\n        dst.write(blended_img[:, :, 0], 1)\n        dst.write(blended_img[:, :, 1], 2)\n        dst.write(blended_img[:, :, 2], 3)\n\n    subprocess.run([\n        \"gdal_translate\", \"-of\", \"COG\",\n        \"-co\", \"COMPRESS=DEFLATE\",\n        \"-co\", \"BLOCKSIZE=512\",\n        \"-co\", \"RESAMPLING=NEAREST\",\n        \"-co\", \"OVERVIEWS=IGNORE_EXISTING\",\n        temp_file.name,\n        output_cog\n    ])\n\nprint(f\"COG file saved as {output_cog}\")","visibility":"show","key":"sjyzZSlJSR"},{"type":"output","id":"wdSa6YsIUDpapwihuPcCT","data":[{"name":"stdout","output_type":"stream","text":"Input file size is 2400, 2400\n0...10...20...30...40...50...60...70...80...90...100 - done.\nCOG file saved as out_urban/Nighttimelevel_Urban_h10v04_2019-2022.tif\n"}],"visibility":"show","key":"LzIHwgy6Go"}],"visibility":"show","key":"NC6PJtRmrE"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Extracting bounding-box coordinates","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Wc1m4RxqUk"}],"key":"wvrEUrkLrL"}],"key":"wzDN2ODyVh"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"p1 = Popen([\"gdalinfo\", \"-json\", output_cog, \"-mm\"], stdout=PIPE)\noutput = p1.communicate()[0]\ndec_out = output.decode('utf-8')\nj_str = json.loads(dec_out)\nbbox = j_str['cornerCoordinates']\nll = bbox['lowerLeft']  # SW coo\nur = bbox['upperRight'] # NE coo\ncenter = bbox['center']","visibility":"show","key":"eyLPNHsgXG"},{"type":"output","id":"bnQBc__LoX6fT7ihDuq68","data":[],"visibility":"show","key":"WUg2HPvrfn"}],"visibility":"show","key":"wIODWq8PDN"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Adding alpha channel to the blended image","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"N4XPbWfiE6"}],"key":"SlBuFs0syA"}],"key":"U7fzNdb9vC"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"def almostEquals(a,b,thres=50):\n    return all(abs(a[i]-b[i])\u003cthres for i in range(len(a)))\n\n\nimage = Image.open(output_cog).convert('RGBA')\npixeldata = list(image.getdata())\n\n\nfor i,pixel in enumerate(pixeldata):\n    if almostEquals(pixel[:3], (0,0,0)):\n        pixeldata[i] = (0,0,0,0)\n\n\nimage.putdata(pixeldata)\npng_path = os.path.join(urban_path, res_name.replace(\".tif\",\".png\"))\nres = image.save(png_path)\n#os.path.abspath(res)\nabs_path = os.path.abspath(png_path)\nwork_dir = os.getcwd()\nid_ = work_dir.split('/')[2]\nbase_url = os.path.join('https://hub-otc-sc.eox.at/user',id_,'files')\n#base_url\nabs_path = '/'.join(abs_path.split('/')[3:])\n#abs_path\n#os.path.join(base_url,abs_path)","visibility":"show","key":"xys73BfeMW"},{"type":"output","id":"OF8rDzc4Eer8HYPbGPsU3","data":[],"visibility":"show","key":"GaZsNU9rbY"}],"visibility":"show","key":"nSlBLDzhyg"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Overlay with OpenStreetMap","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UOrs4ZjBRi"}],"key":"n3meIMvJ33"}],"key":"r07baZEpDG"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"m = Map(basemap=basemaps.CartoDB.DarkMatter, center=(center[1], center[0]), zoom=6)\nimage = ImageOverlay(\n        url=os.path.join(base_url,abs_path), #url=\"https://hub-otc-sc.eox.at/user/\u003cid\u003e/files/\u003cpath_to_png\u003e\n        bounds=((ll[1], ll[0]), (ur[1], ur[0])) # SW and NE corners\n                    )\nm.add_layer(image);\nm","visibility":"show","key":"aoKnVTLyAV"},{"type":"output","id":"QS9TI7r9Ptj6fSv51Jhja","data":[{"output_type":"execute_result","execution_count":81,"metadata":{},"data":{"application/vnd.jupyter.widget-view+json":{"content":"{\"model_id\":\"c690d4c7c957458289f8f9bf72f2e2d1\",\"version_major\":2,\"version_minor\":0}","content_type":"application/vnd.jupyter.widget-view+json"},"text/plain":{"content":"Map(center=[45.0, -75.0], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_ou…","content_type":"text/plain"}}}],"visibility":"show","key":"phiOjtrpVO"}],"visibility":"show","key":"sKroBpk0Xn"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Using additive color blending images to focus on urban areas in the northeastern United States, particularly the southern part of the Boston-Washington Corridor comprising major cities like New York, Philadelphia, Baltimore, and Washington, D.C., revealed relatively little variation in nighttime lights before and after the COVID-19 pandemic, as indicated by the images appearing white. However, significant reductions in nighttime lights during the COVID-19 pandemic (subsequently recovering to pre-pandemic levels) were evident in other medium to large cities, including Boston and Toronto, among others, as indicated by the images appearing pink to reddish.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RCh9uQs4JX"}],"key":"HXc9snDbQY"}],"key":"qWplQFWWpL"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Alternative stretch processing approaches","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ALFYwmXVx1"}],"identifier":"alternative-stretch-processing-approaches","label":"Alternative stretch processing approaches","html_id":"alternative-stretch-processing-approaches","implicit":true,"key":"y3w6u57k33"}],"key":"M5NWKEKwor"},{"type":"block","kind":"notebook-content","children":[{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"“Rural” nighttime light levels: setting each band’s display range to 0-50 [Watts·cm-2·sr-1] to emphasize darker areas","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"a69wRCnunx"}],"key":"JhQBlxmLQe"}],"key":"wtAUKV0Ja1"},{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"For a broader focus (from rural to urban areas): applying a log10 transformation to the values of each band with a display range set to 0-3.6 (equivalent to 0-3981 [Watts·cm-2·sr-1])","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"wW6O5xU3A6"}],"key":"zcqxDRiZcA"}],"key":"YJD7MN48gp"}],"key":"ASjhubi4Lb"}],"key":"xNPCCArIUK"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Final remarks","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XoikgNkp5F"}],"identifier":"final-remarks","label":"Final remarks","html_id":"final-remarks","implicit":true,"key":"laFYL2Pt6W"}],"key":"kKjIC351nj"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"This product has been specifically designed for utilization by researchers in applied scientific fields.\nPotential applications are being explored in environmental and social issue studies, such as disaster recovery, energy, urban land use changes, conflicts, migration, and monitoring of illegal, unreported activities.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"z1nxjLcvv4"}],"key":"MXjBEvIFYa"}],"key":"U77VPCBF8D"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"To learn more","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SgiGm5b0zO"}],"identifier":"to-learn-more","label":"To learn more","html_id":"to-learn-more","implicit":true,"key":"w1V4ZHwYH7"}],"key":"JzlzxfapK0"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"The presented approach is often referenced in scientific and public health research. For example, Bunpei Tojo (2021) used Nightlights data in the study “Application of Earth observation satellite data to public health: Comparison of night light (VIIRS) and solar radiation (SGLI) and domestic COVID-19 epidemic,” presented at the 12th Federation of Science and Technology conference, to analyze the relationship between nighttime light intensity and public health factors.\n","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SH2Y4AmLBw"},{"type":"cite","url":"https://doi.org/10.11487/oukan.2021.0_B-4-4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"東城 (2021)","key":"mxRd1TEw3b"}],"kind":"narrative","label":"2021","identifier":"https://doi.org/10.11487/oukan.2021.0_B-4-4","enumerator":"1","key":"tP9Z4svOKS"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZYjcDJv1cb"}],"key":"BxLvo081LO"}],"key":"rOPmtpyxHj"}],"key":"an2LMKlMzh"},"references":{"cite":{"order":["2021"],"data":{"2021":{"label":"2021","enumerator":"1","doi":"10.11487/oukan.2021.0_B-4-4","html":"東城文柄. (2021). 地球観測衛星データの公衆衛生学への応用. In \u003ci\u003e横幹連合コンファレンス予稿集\u003c/i\u003e (No. 0; Vol. 2021). 特定非営利活動法人　横断型基幹科学技術研究団体連合. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.11487/oukan.2021.0_B-4-4\"\u003e10.11487/oukan.2021.0_B-4-4\u003c/a\u003e","url":"https://doi.org/10.11487/oukan.2021.0_B-4-4"}}}},"footer":{"navigation":{"prev":{"title":"EODashboard STAC access examples","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access","group":"Eodashboard STAC Access"}}},"domain":"http://localhost:3000"},"project":{"subject":"Notebook examples","title":"EO Dashboard Notebooks","description":"Collection of examples relevant to the EO Dashboard project","github":"https://github.com/ESA-eodashboards/eodashboard-notebooks","id":"5aa0318b-5bc1-41e2-b1d4-053e8b61961b","exports":[],"bibliography":[],"index":"readme","pages":[{"title":"External Notebooks","level":1},{"title":"Group1","level":2},{"title":"2025 Bi DS EO Dashboard","level":3},{"slug":"external-notebooks.group1.2025-bids-eodashboard.readme","title":"2025-BiDS-EODashboard","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":4},{"title":"Notebook","level":4},{"slug":"external-notebooks.group1.2025-bids-eodashboard.notebook.urban-health-and-megacities","title":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/header-91647aee0f45b9db42b78b9ec04730b6.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":5},{"title":"Notebooks","level":1},{"slug":"notebooks.fire-impact-analysis","title":"Evaluation of Fire Impact on Populated Areas on a European Site","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/22a5ee1ff975cb9c3eb3b1e899bb858e.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.inland-water-with-edc","title":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.oceanographic-patterns-clustering","title":"\u003ca name=\"toc\"\u003e\u003c/a\u003e\u003cspan style='color:DarkCyan'\u003e Table of Contents \u003c/center\u003e \u003c/span\u003e","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/a737ae6d2b7cf4511053168c9e99be3b.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.openchallangenotebook-team-5-challenge-3-timeserie","title":"Earth System Science Hub Challenge 3: Time series interpolation techniques for remote sensing - Fran, Denise, Mae","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/a737ae6d2b7cf4511053168c9e99be3b.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.openchallengenotebook-c1-jessel-hezzi-roussel","title":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/49e045ccedfe842015ba44cc25ccb377.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.veda-api-bids-2023","title":"Using the NASA VEDA EOAPI","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/5d71b8fb32fb3d611031d0ea697e5422.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"title":"Eodashboard STAC Access","level":2},{"slug":"notebooks.eodashboard-stac-access.eodashboard-stac-access","title":"EODashboard STAC access examples","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/ff5b0d0faa9a9d99644d137afe5bbd92.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3},{"title":"Nightlights Notebook","level":2},{"slug":"notebooks.nightlights-notebook.night-lights-blending","title":"Monitoring socio-economic activities with nighttime light maps","description":"","date":"","thumbnail":"/eodashboard-notebooks/build/nighttime_northeaste-21f472805eb19cbae2eff3b0562af016.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":3}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/eodashboard-notebooks/build/manifest-3481E987.js";
import * as route0 from "/eodashboard-notebooks/build/root-7TUVC4ZT.js";
import * as route1 from "/eodashboard-notebooks/build/routes/$-P6PGXPYX.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/eodashboard-notebooks/build/entry.client-UNPC4GT3.js");</script></body></html>