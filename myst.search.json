{"version":"1","records":[{"hierarchy":{"lvl1":"Example Viewer Template"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Example Viewer Template"},"content":"This template repository is intended to allow easy instantiation of an example viewer for jupyterlab notebooks.\nExternal repositories can be added via git submodules to the external_notebooks folder.\nThe github action will traverse available notebooks and try to extract metadata information as well as build them with Jupyterbook (v2 and MYST).\nThe build package is then deployed on github pages.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"2025-BiDS-EODashboard"},"type":"lvl1","url":"/external-notebooks/group1/2025-bids-eodashboard/readme","position":0},{"hierarchy":{"lvl1":"2025-BiDS-EODashboard"},"content":"Materials for Tutorial Hands-On with EO: Creating Indicators and Stories from Open Satellite Data on Big Data From Space 2025 in Riga.","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/readme","position":1},{"hierarchy":{"lvl1":"2025-BiDS-EODashboard","lvl2":"Workspace"},"type":"lvl2","url":"/external-notebooks/group1/2025-bids-eodashboard/readme#workspace","position":2},{"hierarchy":{"lvl1":"2025-BiDS-EODashboard","lvl2":"Workspace"},"content":"Every participant of the workshop can access the prepared workspace for the tutorial on \n\nhttps://​workspace​.eodashboardtutorial​.hub​-otc​-sc​.eox​.at/\n\nAccess to the workspace will be additionally available until 10.10.2025 - even after the tutorial end for the attendees to be able to rerun the workflow and browse the platform with limited resources.","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/readme#workspace","position":3},{"hierarchy":{"lvl1":"2025-BiDS-EODashboard","lvl2":"Materials"},"type":"lvl2","url":"/external-notebooks/group1/2025-bids-eodashboard/readme#materials","position":4},{"hierarchy":{"lvl1":"2025-BiDS-EODashboard","lvl2":"Materials"},"content":"Collection of materials used for BiDS 2025 EODashboard tutorial:","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/readme#materials","position":5},{"hierarchy":{"lvl1":"2025-BiDS-EODashboard","lvl3":"Playbook","lvl2":"Materials"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/readme#playbook","position":6},{"hierarchy":{"lvl1":"2025-BiDS-EODashboard","lvl3":"Playbook","lvl2":"Materials"},"content":"You can follow the flow of the tutorial with all relevant links on \n\nfollowing link","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/readme#playbook","position":7},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI"},"type":"lvl1","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities","position":0},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI"},"content":"\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities","position":1},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"Running environment:"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#running-environment","position":2},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"Running environment:"},"content":"This notebook can be run by installing the provided Anaconda Python environment (notebook-env.yml).\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#running-environment","position":3},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl2":"USE CASE 1: Nighttime Lights"},"type":"lvl2","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-case-1-nighttime-lights","position":4},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl2":"USE CASE 1: Nighttime Lights"},"content":"","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-case-1-nighttime-lights","position":5},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#creating-nighttime-light-maps-with-color-blending","position":6},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"content":"\n\nThis use case demonstrates how to create nighttime light variation maps over a time interval (from 2019 to 2022) with additive color blending for studying the distribution of artificial lighting in urban and rural regions, offering insights into urbanization, infrastructure development, and socio-economic activity.\nThe Nighttime Light Levels indicator can be explored on the EO Dashboard by selecting the EXPLORE DATASETS mode and choosing \n\nNight lights indicators.\n\nThe study has been carried out by Associate Professor TOJO Bumpei of the Institute of Global Studies (specializing in Geographic Information Systems) in collaboration with JAXA.\n\n\n\nExample of a nighttime light map covering India during 2019-2022, representing areas where a decrease in nighttime light level occurred (indicating a presumed reduction in social activity) in red, and areas where an increase occurred (indicating a presumed increase in social activity) in blue.\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#creating-nighttime-light-maps-with-color-blending","position":7},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.1 Input data","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-1-input-data","position":8},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.1 Input data","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"content":"Visible Infrared Imaging Radiometer Suite (VIIRS, onboard NASA Suomi NPP satellite).\n\nAggregation: data aggregated on a semi-annual basis (using median image generation) with 10-degree lat/lon (geographic) grid h-v tile as Geo Tiff files.\n\nThe tiles are 2400 x 2400 pixels, with pixel size of 0.004166 degrees (~464 m at the equator).\n\nSpatial Resolution: (0.4 - 0.8) km.\n\nMetric: nighttime radiance (measured in watts per square centimeter per steradian, [W/cm²/sr]), which represents the brightness of artificial lighting.\n\nData access: aggregated input data provided by Jaxa and available locally\n\nVIIRS 10-degree tile scheme\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-1-input-data","position":9},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.2 Importing Python libraries","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-2-importing-python-libraries","position":10},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.2 Importing Python libraries","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"content":"\n\n#Import libraries\nimport os\nimport sys\nimport re\nimport numpy as np\nimport rasterio\nimport rioxarray as rxr\nimport subprocess\nfrom subprocess import Popen, PIPE\nimport tempfile\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom PIL import Image\nimport json\nfrom ipyleaflet import Map, ImageOverlay, basemaps\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-2-importing-python-libraries","position":11},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.3 Defining working folders","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-3-defining-working-folders","position":12},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.3 Defining working folders","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"content":"\n\ninput_dir = \"input\"\ninput_path = os.path.join(os.getcwd(), \"Nightlights\", input_dir)\n\noutput_urban = \"output\"\nurban_path = os.path.join(os.getcwd(), \"Nightlights\", output_urban)\n\n# Create output dir\nos.makedirs(urban_path, exist_ok=True)\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-3-defining-working-folders","position":13},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.4 Visualizing input data","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-4-visualizing-input-data","position":14},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.4 Visualizing input data","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"content":"\n\npattern = re.compile(r\"h(\\d+)v(\\d+)_(\\d{4})_(\\d)H_median\\.tif\")\n\nfor root, _, files in os.walk(input_path):\n    grouped_files = {}\n    \n    # Grouping files by h and v\n    for file in files:\n        match = pattern.match(file)\n        if match:\n            h, v, year, H = match.groups()\n            key = (h, v)\n            if key not in grouped_files:\n                grouped_files[key] = []\n            grouped_files[key].append((year, H, os.path.join(root, file))) \n    \n    # Process files for plotting\n    for (h, v), file_group in grouped_files.items():\n        file_group\n\ntuplelist2dict = {c:{'year':a,'half':b} for a,b,c in file_group}\nsorted_dict = {}\n\ngrid_tile = None\nfor item in sorted(tuplelist2dict, key = lambda k: (tuplelist2dict[k]['year'], tuplelist2dict[k]['half'])):\n    sorted_dict.update({item:tuplelist2dict[item]})\n    grid_tile = item.split('/')[-1].split('_')[0]\n#print(sorted_dict)\n\ndef plot_figures(figures, nrows = 1, ncols=1, factor = 1., clip_range = None, **kwargs):\n    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, figsize=(15, 15))\n    for idx,file_name in enumerate(figures):\n        title = file_name.split('/')[-1]\n        title = title.replace(\"_median.tif\", \"\")\n        axeslist.ravel()[idx].imshow(np.clip(mpimg.imread(file_name)*factor, *clip_range), **kwargs) # cmap=plt.gray(), cmap='Greys'\n        axeslist.ravel()[idx].set_title(title)\n        axeslist.ravel()[idx].set_axis_off()\n    fig.suptitle(r'Median nighttime light level [$Wcm^{-2}sr^{-1}$]', fontsize=20)\n    #plt.tight_layout() \n\n    \n\nplot_figures(sorted_dict, 4, 2, clip_range=(0,1), factor=100./255.)\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-4-visualizing-input-data","position":15},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.5 Applying color blending","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-5-applying-color-blending","position":16},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.5 Applying color blending","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"content":"\n\nAdditive color blending involves mixing the primary colors of light, red (R), green (G), and blue (B), while adjusting their luminance levels. By manipulating the luminance of these colors, a wide range of hues can be achieved, with the key characteristic being that combining all three colors results in white.\n\nTechnique\n\nmaximum pixel value of images for 2019 (brightest pixel values) is assigned to red (R)\n\nminimum pixel value of images for 2020-2021 (darkest pixel values) is assigned to green (G)\n\nmaximum pixel value of images for 2022 (brightest pixel values) is assigned to blue (B)\n\nOutput\n\nregions where a decrease in nighttime light level occurred are displayed in red\n\nareas that experienced an increase (presumed to indicate an increase in social activity) are shown in blue\n\nregions where there was no significant change throughout the pandemic are displayed in a gradient from gray to white.\n\npattern = re.compile(r\"h(\\d+)v(\\d+)_(\\d{4})_(\\d)H_median\\.tif\")\n\n\ndef read_and_preprocess(file):\n    with rasterio.open(file) as src:\n        img = src.read(1)\n        img = np.nan_to_num(img, nan=0)  # Replace NaNs with zeros\n        return img, src.profile\n\n    \ndef additive_blending(grouped_files):\n    # Process each group of files for blending\n    for (h, v), file_group in grouped_files.items():\n        # Initialize arrays to store the maximum and minimum values for each year\n        max_2019 = None\n        min_2020_2021 = None\n        max_2022 = None\n        \n        for year, H, file in file_group:\n            img, profile = read_and_preprocess(file)\n            \n            if year == '2019':\n                if max_2019 is None:\n                    max_2019 = img\n                else:\n                    max_2019 = np.maximum(max_2019, img)\n            elif year in ['2020', '2021']:\n                if min_2020_2021 is None:\n                    min_2020_2021 = img\n                else:\n                    min_2020_2021 = np.minimum(min_2020_2021, img)\n            elif year == '2022':\n                if max_2022 is None:\n                    max_2022 = img\n                else:\n                    max_2022 = np.maximum(max_2022, img)\n                                  \n    # Create the blended image using the specified blending technique\n    blended_img = np.zeros((max_2019.shape[0], max_2019.shape[1], 3), dtype=np.float32)\n    blended_img[:, :, 0] = max_2019.astype(np.float32)  # Red band: maximum of 2019\n    blended_img[:, :, 1] = min_2020_2021.astype(np.float32)  # Green band: minimum of 2020-2021 compared\n    blended_img[:, :, 2] = max_2022.astype(np.float32)  # Blue band: maximum of 2022\n    \n    return blended_img, profile        \n\n# Grouping files per (h,v) tiles and years span\ngrouped_files = {}\nfor root, _, files in os.walk(input_path):\n    \n    \n    # Group files by h and v\n    for file in files:\n        match = pattern.match(file)\n        if match:\n            h, v, year, H = match.groups()\n            key = (h, v)\n            if key not in grouped_files:\n                grouped_files[key] = []\n            grouped_files[key].append((year, H, os.path.join(root, file)))\n\n\n# blending           \nblended_img, profile = additive_blending(grouped_files)\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-5-applying-color-blending","position":17},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.6 Employing “urban” stretch processing","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-6-employing-urban-stretch-processing","position":18},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.6 Employing “urban” stretch processing","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"content":"\n\nThe purpose of the stretch processing is to emphasize the nighttime light level of each band (corresponding to 2019, 2020-21, and 2022), focusing on:\n\n“urban” nighttime light levels: the display range of each band is adjusted to 25-1000 [watts·cm-2·sr-1], emphasizing brighter areas\n\n# Urban stretch processing: Emphasize brighter areas\ndef urban_stretch_processing(band):\n    min_val = 25\n    max_val = 1000\n    band = np.clip(band, min_val, max_val)\n    band = (band - min_val) / (max_val - min_val) * 255\n    return band.astype(np.uint8)\n\n# Apply urban stretch processing to each band\nblended_img[:, :, 0] = urban_stretch_processing(blended_img[:, :, 0])\nblended_img[:, :, 1] = urban_stretch_processing(blended_img[:, :, 1])\nblended_img[:, :, 2] = urban_stretch_processing(blended_img[:, :, 2])\n        \n# Update the profile for a 3-band image and set nodata value to None\nprofile.update(count=3, dtype=rasterio.uint8, nodata=None)\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-6-employing-urban-stretch-processing","position":19},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.7 Plotting blended image","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-7-plotting-blended-image","position":20},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.7 Plotting blended image","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"content":"\n\ndef plot_image(image, factor=1.0, clip_range = None, **kwargs):\n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n    if clip_range is not None:\n        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n    else:\n        ax.imshow(image * factor, **kwargs)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n\nplot_image(blended_img, factor=1.5/255., clip_range=(0,1))\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-7-plotting-blended-image","position":21},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.8 Overlaying with an interactive map","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-8-overlaying-with-an-interactive-map","position":22},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.8 Overlaying with an interactive map","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"content":"\n\nSaving blended image as Cloud Optimized GeoTIFF\n\n# Exporting output as COG file \nres_name = f\"Nighttimelevel_Urban_{grid_tile}_2019-2022.tif\"\noutput_cog = os.path.join(urban_path, res_name)\n\n\n# Write the blended image directly to a temporary file\nwith tempfile.NamedTemporaryFile(suffix=\".tif\") as temp_file:\n    with rasterio.open(temp_file.name, \"w\", **profile) as dst:\n        dst.write(blended_img[:, :, 0], 1)\n        dst.write(blended_img[:, :, 1], 2)\n        dst.write(blended_img[:, :, 2], 3)\n\n    subprocess.run([\n        \"gdal_translate\", \"-of\", \"COG\",\n        \"-co\", \"COMPRESS=DEFLATE\",\n        \"-co\", \"BLOCKSIZE=512\",\n        \"-co\", \"RESAMPLING=NEAREST\",\n        \"-co\", \"OVERVIEWS=IGNORE_EXISTING\",\n        temp_file.name,\n        output_cog\n    ])\n\nprint(f\"COG file saved as {output_cog}\")\n\nExtracting bounding-box coordinates\n\np1 = Popen([\"gdalinfo\", \"-json\", output_cog, \"-mm\"], stdout=PIPE)\noutput = p1.communicate()[0]\ndec_out = output.decode('utf-8')\nj_str = json.loads(dec_out)\nbbox = j_str['cornerCoordinates']\nll = bbox['lowerLeft']  # SW coo\nur = bbox['upperRight'] # NE coo\ncenter = bbox['center']\n\nAdding alpha channel to the blended image\n\ndef almostEquals(a,b,thres=50):\n    return all(abs(a[i]-b[i])<thres for i in range(len(a)))\n\n\nimage = Image.open(output_cog).convert('RGBA')\npixeldata = list(image.getdata())\n\n\nfor i,pixel in enumerate(pixeldata):\n    if almostEquals(pixel[:3], (0,0,0)):\n        pixeldata[i] = (0,0,0,0)\n\n\nimage.putdata(pixeldata)\npng_path = os.path.join(urban_path, res_name.replace(\".tif\",\".png\"))\nres = image.save(png_path)\n#os.path.abspath(res)\nabs_path = os.path.abspath(png_path)\nwork_dir = os.getcwd()\nid_ = work_dir.split('/')[2]\nbase_url = os.path.join('https://hub-otc-sc.eox.at/user',id_,'files')\n#base_url\nabs_path = '/'.join(abs_path.split('/')[3:])\nprint(abs_path)\nprint(base_url)\n#abs_path\nprint(os.path.join(base_url,abs_path))\n\n\nOverlay with OpenStreetMap\n\nm = Map(basemap=basemaps.CartoDB.DarkMatter, center=(center[1], center[0]), zoom=6)\nosm_url = os.path.join(base_url,abs_path)\nimage = ImageOverlay(url=osm_url,bounds=((ll[1], ll[0]), (ur[1], ur[0])))\nm.add_layer(image);\nm\n\nUsing additive color blending images to focus on urban areas in India, in particular the North-West part comprising New Delhi, Jaipur, Agra, Gwalior, ...\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-8-overlaying-with-an-interactive-map","position":23},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.9 Alternative stretch processing approaches","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-9-alternative-stretch-processing-approaches","position":24},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.9 Alternative stretch processing approaches","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"content":"\n\n“Rural” nighttime light levels: setting each band’s display range to 0-50 [Watts·cm-2·sr-1] to emphasize darker areas\n\nFor a broader focus (from rural to urban areas): applying a log10 transformation to the values of each band with a display range set to 0-3.6 (equivalent to 0-3981 [Watts·cm-2·sr-1])\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-9-alternative-stretch-processing-approaches","position":25},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.10 Final remarks","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-10-final-remarks","position":26},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"1.10 Final remarks","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"content":"\n\nThis product has been specifically designed for utilization by researchers in applied scientific fields.\nPotential applications are being explored in environmental and social issue studies, such as:\n\ndisaster recovery\n\nenergy\n\nurban land use changes\n\nconflicts\n\nmigration\n\nmonitoring of illegal, unreported activities\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-1-10-final-remarks","position":27},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"To learn more","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#to-learn-more","position":28},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"To learn more","lvl3":"Creating nighttime light maps with color blending","lvl2":"USE CASE 1: Nighttime Lights"},"content":"\n\nThe presented approach is often referenced in scientific and public health research. For example, Bunpei Tojo (2021) used Nightlights data in the study “Application of Earth observation satellite data to public health: Comparison of night light (VIIRS) and solar radiation (SGLI) and domestic COVID-19 epidemic,” presented at the 12th Federation of Science and Technology conference, to analyze the relationship between nighttime light intensity and public health factors.\n\n\n東城 (2021).\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#to-learn-more","position":29},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl2":"USE CASE 2: Air Pollution"},"type":"lvl2","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-case-2-air-pollution","position":30},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl2":"USE CASE 2: Air Pollution"},"content":"","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-case-2-air-pollution","position":31},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#monitoring-no2-concentrations-over-northern-india","position":32},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"content":"\n\nAir quality is poor across India, but especially poor in Northern India due to a mix of human activity and seasonal weather conditions:\n\nVehicle emissions: The city’s high population density results in heavy traffic and significant pollution from older and poorly maintained vehicles. Increased investment in mass transportation and stricter fuel efficiency enforcement could help mitigate these issues in future.\n\nIndustrial and construction dust: Industrial operations and ongoing construction projects release fine particulate matter into the air.\n\nHome heating: Coal, firewood, and diesel generator use can contribute to poor air quality.\n\nWeather patterns: Chillier temperatures, low wind speeds, and heavy air trap pollutants close to the ground during colder months, worsening smog.\n\nCrop stubble burning: Farmers in neighboring states including Bihar, Haryana, and Uttar Pradesh burn agricultural waste, contributing to particulate pollution\n\nCombined, these factors create a toxic atmosphere. Air quality is particularly dangerous during the winter months, when weather conditions exacerbate pollution.\n\n\n\nIn particular, Delhi and large parts of North India experienced a significant air quality crisis towards the end of 2024, with air quality reaching the “Severe” and “Hazardous” categories, leading to a public health emergency.\n\nThis use case aims at analyzing the air quality over North India, showing how to create a time series plot of mean tropospheric NO2 values accompanied by the standard deviation to assess the impact of the pollutant agent.\n\nThe tropospheric NO2 concetrations can be further explored on the EO Dashboard by selecting the ATMOSPHERE Theme and choosing \n\nAir Quality (tropospheric NO2 concentrations).\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#monitoring-no2-concentrations-over-northern-india","position":33},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"2.1 Input data","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-2-1-input-data","position":34},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"2.1 Input data","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"content":"Tropospheric nitrogen dioxide (NO2) measurements obtained by TROPOMI (multispectral imaging spectrometer) aboard ESA Sentinel-5 Precursor (S5P) satellite (part of the European Copernicus programme)\n\nAggregation: data combined over 14 days for averaging out meteorological daily variability\n\nSpectral bands: ultraviolet and visible (270–500 nm), near-infrared (675–775 nm) and shortwave infrared (2305–2385 nm)\n\nResolution: (7 × 3.5) km\n\nMetric: micromoles per square meter [μmol/m²], total number of molecules of NO2 within a column of the atmosphere\n\nData access: aggregated data collection available on Sentinel Hub as \n\nBring Your Own COG (BYOC) and accessed using Sentinel Hub APIs\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-2-1-input-data","position":35},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"2.2 Importing Python libraries","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-2-2-importing-python-libraries","position":36},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"2.2 Importing Python libraries","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"content":"\n\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\nimport subprocess\nimport json\nimport requests\nimport pandas as pd\nimport os \nimport IPython.display\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nfrom sentinelhub import BBox\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-2-2-importing-python-libraries","position":37},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"2.3 Visualizing the AoI (Gurugram, South-West of New Delhi)","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-2-3-visualizing-the-aoi-gurugram-south-west-of-new-delhi","position":38},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"2.3 Visualizing the AoI (Gurugram, South-West of New Delhi)","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"content":"\n\n# Gurugram coordinates\ntop_left_x =  76.9602268594042\ntop_left_y = 28.5355222251629\nbottom_right_x = 77.11128887112295 \nbottom_right_y = 28.394875392026698\n\nbbox = [   \n  top_left_x,\n  bottom_right_y,\n  bottom_right_x,\n  top_left_y\n        ]\n\n# Bbox EPSG\nbbox_epsg = 4326\n\n# Plotting the bounding box on a map\n\nIPython.display.GeoJSON(BBox(bbox,crs=bbox_epsg).get_geojson())\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-2-3-visualizing-the-aoi-gurugram-south-west-of-new-delhi","position":39},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"2.4 Using Sentinel Hub statistical API request to access NO2 data collection for the selected AoI","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-2-4-using-sentinel-hub-statistical-api-request-to-access-no2-data-collection-for-the-selected-aoi","position":40},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"2.4 Using Sentinel Hub statistical API request to access NO2 data collection for the selected AoI","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"content":"\n\nThe Statistical API (or shortly “Stats API”) enables to get statistics calculated based on satellite imagery without having to download images.\nIn the Statistical API request, one can specify the following inputs:\n\narea of interest (AoI)\n\ntime period\n\ndata collection data collection id info on the publicly accessible \n\nSTAC catalog (it can be also be queried via the pystac library as in this \n\nexample)\n\nevalscript or “custom script” is a piece of Javascript code which defines how the satellite data shall be processed by Sentinel Hub and what values the service shall return (more info \n\nhere)\n\nstatistics to be calculated are returned in the API response in a json format. Further details can be found on the corresponding \n\nSH documentation.\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-2-4-using-sentinel-hub-statistical-api-request-to-access-no2-data-collection-for-the-selected-aoi","position":41},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Defining Statistical API input parameters: AoI, time period, data collection","lvl4":"2.4 Using Sentinel Hub statistical API request to access NO2 data collection for the selected AoI","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#defining-statistical-api-input-parameters-aoi-time-period-data-collection","position":42},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Defining Statistical API input parameters: AoI, time period, data collection","lvl4":"2.4 Using Sentinel Hub statistical API request to access NO2 data collection for the selected AoI","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"content":"\n\n# AoI coordinates WGS84 (Gurugram)\nbbox = [   \n  top_left_x,\n  top_left_y,\n  bottom_right_x,\n  bottom_right_y,\n        ]\n\n# Time period\ndate_from = \"2024-11-01T00:00:00.000Z\"\ndate_to = \"2025-02-28T00:00:00.000Z\"\n\n# Data collection id\ndata_collection = \"byoc-972e67a7-2ca8-4bf6-964a-11fe772e3ac2\"\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#defining-statistical-api-input-parameters-aoi-time-period-data-collection","position":43},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Defining Statistical API input parameters: custom script (evalscript)","lvl4":"2.4 Using Sentinel Hub statistical API request to access NO2 data collection for the selected AoI","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#defining-statistical-api-input-parameters-custom-script-evalscript","position":44},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Defining Statistical API input parameters: custom script (evalscript)","lvl4":"2.4 Using Sentinel Hub statistical API request to access NO2 data collection for the selected AoI","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"content":"\n\nEvalscript version 3 (V3) requires to specify two functions:\n\nsetup: where you specify inputs and outputs.\n\nevaluatePixel: which calculates the output values for each pixel.\n\nevaluatePixel() function must, in addition to other output, always return also dataMask output.\nThis output defines which pixels are excluded from calculations.\n\n# Evalscript\nevalscript=\"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{bands: [\"tropno2\",\"dataMask\"]}],\n    output: [\n      {\n      id: \"data\",\n      bands: 1,\n      sampleType: \"FLOAT32\"\n      },\n      {\n      id: \"dataMask\",\n      bands: 1\n      }]\n    }\n}\n\nfunction evaluatePixel(samples) {\n  let validValue = 1    // data sanitation\n  if (samples.tropno2 >= 1e20 ){\n    validValue = 0\n    }\n  let index = samples.tropno2;\n  return {\n    data:  [index],\n    dataMask: [samples.dataMask * validValue]\n    }\n}\n\"\"\"\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#defining-statistical-api-input-parameters-custom-script-evalscript","position":45},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Building NO2 data request","lvl4":"2.4 Using Sentinel Hub statistical API request to access NO2 data collection for the selected AoI","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#building-no2-data-request","position":46},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Building NO2 data request","lvl4":"2.4 Using Sentinel Hub statistical API request to access NO2 data collection for the selected AoI","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"content":"\n\ndata_req = {\n  \"input\": {\n    \"bounds\": {\n      \"bbox\": bbox\n    },\n    \"data\": [\n      {\n        \"dataFilter\": {},\n        \"type\": data_collection\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"evalscript\": evalscript,\n    \"timeRange\": {\n      \"from\": date_from,\n      \"to\": date_to\n    },\n    \"aggregationInterval\": {\n      \"of\": \"P1D\"\n    },\n    \"width\": 100,\n    \"height\": 100\n  },\n  \"calculations\": {\n    \"default\": {}\n  }\n}\n\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#building-no2-data-request","position":47},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Setting credentials for accessing Sentinel Hub services","lvl4":"2.4 Using Sentinel Hub statistical API request to access NO2 data collection for the selected AoI","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#setting-credentials-for-accessing-sentinel-hub-services","position":48},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Setting credentials for accessing Sentinel Hub services","lvl4":"2.4 Using Sentinel Hub statistical API request to access NO2 data collection for the selected AoI","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"content":"OAuth credentials to access SH services can be obtained by following the \n\ninstructions provided on the SH platform.\n\nimport os\n# Creating a session\nservice_url = \"https://services.sentinel-hub.com\" # SH services endpoint\n\n# OAuth Client configuration\nclient_id = os.environ.get(\"SH_CLIENT_ID\")\nclient_secret = os.environ.get(\"SH_CLIENT_SECRET\")\n\nclient = BackendApplicationClient(client_id=client_id)\noauth = OAuth2Session(client=client)\n\n# Get token for the session\ntoken_url = f\"{service_url}/oauth/token\" # Sentinel-Hub OAuth2 server token endpoint\ntoken = oauth.fetch_token(token_url=token_url,\n                          client_secret=client_secret)\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#setting-credentials-for-accessing-sentinel-hub-services","position":49},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Sending a POST request to SH Statistical API","lvl4":"2.4 Using Sentinel Hub statistical API request to access NO2 data collection for the selected AoI","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#sending-a-post-request-to-sh-statistical-api","position":50},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Sending a POST request to SH Statistical API","lvl4":"2.4 Using Sentinel Hub statistical API request to access NO2 data collection for the selected AoI","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"content":"\n\nstat_url = f\"{service_url}/api/v1/statistics\" # SH statistical API endpoint\nresp = oauth.post(stat_url,\n                  headers={\"Accept\":\"application/json\",\"Content-Type\":\"application/json\"},\n                  json=data_req)\n#print(resp.status_code, resp.text)\n\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#sending-a-post-request-to-sh-statistical-api","position":51},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Parsing response and extracting relevant statistics","lvl4":"2.4 Using Sentinel Hub statistical API request to access NO2 data collection for the selected AoI","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#parsing-response-and-extracting-relevant-statistics","position":52},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Parsing response and extracting relevant statistics","lvl4":"2.4 Using Sentinel Hub statistical API request to access NO2 data collection for the selected AoI","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"content":"\n\n# Extracting stats from timeseries data within the specified time interval\ndata_r = resp.json() # parsing response to json\ntime_axis = [datetime.strptime(entry[\"interval\"][\"from\"], \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y/%m/%d\") for entry in data_r[\"data\"]]\nmeans = [float(entry['outputs']['data']['bands']['B0']['stats']['mean']) for entry in data_r[\"data\"]]\nstd_devs = [float(entry['outputs']['data']['bands']['B0']['stats']['stDev']) for entry in data_r[\"data\"]]\nstd_upper = [m+s for (m,s) in zip(means, std_devs)]\nstd_lower = [m-s for (m,s) in zip(means, std_devs)]\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#parsing-response-and-extracting-relevant-statistics","position":53},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"2.5 Plotting the statistics for the NO2 timeseries","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-2-5-plotting-the-statistics-for-the-no2-timeseries","position":54},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"2.5 Plotting the statistics for the NO2 timeseries","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"content":"\n\nfig = plt.figure(figsize=(20,10))\n# plot mean values \nplt.plot(time_axis, means, linestyle='solid', linewidth=2, color=\"black\", label=\"Mean Tropospheric NO2 values [umol/ m^2]\")\n\n# plot standard deviation error bars\nplt.errorbar(time_axis, means, yerr=std_devs, linestyle=\"-\")\n\nplt.title('Tropospheric NO2 Values over the AOI')\nplt.legend()\nfig.autofmt_xdate()\n\n# Saving plot\noutput_no2 = \"output\"\noutput_no2_path = os.path.join(os.getcwd(), \"Air_pollution\", output_no2)\nos.makedirs(output_no2_path, exist_ok=True)\nplt.savefig(os.path.join(output_no2_path, 'NO2_Gurugram.png'))\n\nplt.show()\n\nThe plot shows a spike in NO2 concentration over Gurugram in December 2024, when the significant air quality crisis in Northern India has been reported.\nIn particular, it can be noticed that the standard deviation starts increasing over this month with respect to the preceding and subsequent  time interval.\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-2-5-plotting-the-statistics-for-the-no2-timeseries","position":55},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"2.6 Final remarks","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-2-6-final-remarks","position":56},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"2.6 Final remarks","lvl3":"Monitoring NO2 concentrations over Northern India","lvl2":"USE CASE 2: Air Pollution"},"content":"\n\nThe analysis carried out in this use case demonstrates how the Sentinel-5 Precursor Copernicus mission represents an essential contribution to monitoring air quality and providing critical information to services and decision makers to safeguard the everyday life of citizens.\n\nIn addition to nitrogen dioxide, the Tropomi spectrometer can map a multitude of trace gases such as:\n\nozone\n\nformaldehyde\n\nsulphur dioxide\n\nmethane\n\ncarbon monoxide\n\naerosols\n\nall of which affect the air we breathe and therefore our health, and our climate.\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-2-6-final-remarks","position":57},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl2":"USE CASE 3: HEATWAVES"},"type":"lvl2","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-case-3-heatwaves","position":58},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl2":"USE CASE 3: HEATWAVES"},"content":"","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-case-3-heatwaves","position":59},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#analyzing-land-surface-temperature-with-gcom-c-shikisai-satellite-data-from-jaxa","position":60},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"content":"In this use case, we will explore GCOM (Global Change Observation Mission) satellite data to analyze Land Surface Temperature (LST). Specifically, we’ll look at data from the GCOM-C satellite, which is part of the Japan Aerospace Exploration Agency’s (JAXA) efforts to monitor global climate change. GCOM-C provides valuable information on various environmental factors, including temperature, vegetation, and water bodies, through its thermal infrared sensors.\nOur focus will be on studying the heatwave that occurred in New Delhi, India, in 2024. In particular, the city experienced a significant temperature surge during the peak summer months. The temperature exceeded 45°C (113°F), causing severe disruptions to daily life, and raising concerns about the increasing frequency and intensity of heatwaves due to climate change.\nBy analyzing GCOM-C’s satellite data, we can better understand the spatial distribution of land surface temperature during that period.\n\nThe July LST can be further explored on the \n\nEO Dashboard .\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#analyzing-land-surface-temperature-with-gcom-c-shikisai-satellite-data-from-jaxa","position":61},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.1 Input data","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-1-input-data","position":62},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.1 Input data","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"content":"Aggregation: Monthly averaged global dataset for July 2024 (daytime measurements)\n\nVariable: Land Surface Temperature (LST) (which is a Level-2 product, calculating from two thermal infrared (TIR) bands  two TIR bands (10.8 µm & 12.0 µm) using a hybrid split-window + semi-analytical algorithm that accounts for emissivity and atmospheric effects.\n\nSpatial coverage: spatial coordinates 0°–90° East and 0°–90° North.\n\nResolution: Approximately 1 km (spatial resolution of SGLI Level 3 products).\n\nMetric (units): Kelvin (°K) with scale factor of 0.02, since: K = DN*0.02.\n\nDataset documentation: \n\nhttps://​suzaku​.eorc​.jaxa​.jp​/GCOM​_C​/data​/ATBD​/ver2​/V2ATBD​_T4A​_LST​_Moriyama​_r1​.pdf\n\nDOI: 10.57746/EO.01gs73bfs5sbzhyxg4j9ytajsa\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-1-input-data","position":63},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.2 Import libraries","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-2-import-libraries","position":64},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.2 Import libraries","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"content":"\n\nimport os\nimport geopandas as gpd\nimport rasterio\nfrom rasterio.mask import mask\nimport matplotlib.pyplot as plt\nfrom osgeo import gdal\nimport requests\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom osgeo import gdal\nfrom matplotlib.colors import LinearSegmentedColormap\nimport matplotlib.patches as patches\nimport matplotlib.colors as mcolors\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-2-import-libraries","position":65},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.3 Defining working folders","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-3-defining-working-folders","position":66},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.3 Defining working folders","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"content":"\n\noutput_urban = \"output\"\nurban_path = os.path.join(os.getcwd(), \"Heatwaves\", output_urban)\n\n# Create output dir\nos.makedirs(urban_path, exist_ok=True)\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-3-defining-working-folders","position":67},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.4 Visualizing input dataset","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-4-visualizing-input-dataset","position":68},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.4 Visualizing input dataset","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"content":"\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-4-visualizing-input-dataset","position":69},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Saving dataset locally from data endpoint","lvl4":"3.4 Visualizing input dataset","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#saving-dataset-locally-from-data-endpoint","position":70},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Saving dataset locally from data endpoint","lvl4":"3.4 Visualizing input dataset","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"content":"This URL (data endpoint) contains a GeoTIFF file from LST and \n\nit’s part of the EO Dashboard data ecosystem\n\nDataset originally was generated in the \n\nJAXA’s G-Portal and JAXA provides direct access to this and other COGs through their Earth API\n\nWhile these COGs differ between Level 0 and Level 1 data (meaning it is not yet possible to create composite layers), the EO Dashboard allows integration of raw Level 1 COGs hosted by JAXA (\n\nexample)\n\n# Data endpoint\nurl = \"https://s3.ap-northeast-1.wasabisys.com/je-pds/cog/v1/JAXA.G-Portal_GCOM-C.SGLI_standard.L3-LST.daytime.v3_global_monthly/2024-07/1/E000.00-E090.00/E000.00-N00.00-E090.00-N90.00-LST.tiff\"\n# Downloads the file from the URL\nresponse = requests.get(url)\n# Saves file locally \nwith open(\"Heatwaves/LST.tiff\", \"wb\") as f:\n    f.write(response.content)\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#saving-dataset-locally-from-data-endpoint","position":71},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Plot the image","lvl4":"3.4 Visualizing input dataset","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#plot-the-image","position":72},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Plot the image","lvl4":"3.4 Visualizing input dataset","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"content":"\n\n# Opening the file with GDAL (library for geospatial raster data)\nds = gdal.Open(\"Heatwaves/LST.tiff\")\n# Gests the first (and in this case) only band refering to LST.\nband = ds.GetRasterBand(1)\n#Reads the raster into a NumPy array (a sort of matrix)\narr = band.ReadAsArray().astype(float)\n\n# Plotting\nimport matplotlib.pyplot as plt\nplt.imshow(arr, cmap=\"viridis\")\nplt.colorbar()\nplt.title(\"LST\")\nplt.show()\n\nprint(' - - - ')\nprint('Aditional information about the dataset:')\nprint(' - - - ')\nprint(ds.GetProjection(), ds.GetGeoTransform())\n\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#plot-the-image","position":73},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.4 Converting to Celsius Degrees and clean unvalid pixels","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-4-converting-to-celsius-degrees-and-clean-unvalid-pixels","position":74},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.4 Converting to Celsius Degrees and clean unvalid pixels","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"content":"The JAXA GCOM-C SGLI L3 LST had a 0.02 scalling factor and was in Kelvin.\n\nRemoving values of pixels (consider them as NaN)\n\n# Now we mask invalid or unrealistic values (sometimes satellite data have artifacts or other issues that render the value of a pixel wrong)\narr[(arr <= 0) | (arr > 35000)] = np.nan\n\n# Re-scale and convert from Kelvin to Celsius\narr_c = arr * 0.02 - 273.15  \n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-4-converting-to-celsius-degrees-and-clean-unvalid-pixels","position":75},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.4 Croping to areas of interest: Northern India and New Dehli","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-4-croping-to-areas-of-interest-northern-india-and-new-dehli","position":76},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.4 Croping to areas of interest: Northern India and New Dehli","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"content":"\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-4-croping-to-areas-of-interest-northern-india-and-new-dehli","position":77},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Defining locations of interest","lvl4":"3.4 Croping to areas of interest: Northern India and New Dehli","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#defining-locations-of-interest","position":78},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Defining locations of interest","lvl4":"3.4 Croping to areas of interest: Northern India and New Dehli","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"content":"\n\n# GeoTransform is a GDAL function that helps map between the raster coordinates and georeference coordinates\n# In other words it is converting geographic coordinates (lat, lon) into pixel coordinates of our matrix (X, y)\ngt = ds.GetGeoTransform()\ndef latlon_to_pixel(lat, lon, gt):\n    px = int((lon - gt[0]) / gt[1])\n    py = int((lat - gt[3]) / gt[5])\n    return px, py\n\n# Now we use this function to get the pixel coordinates of an area around Northern India \nlon_min, lon_max = 70, 90\nlat_min, lat_max = 20, 37\npx_min, py_max = latlon_to_pixel(lat_min, lon_min, gt)\npx_max, py_min = latlon_to_pixel(lat_max, lon_max, gt)\n# 'Bounding box of northern India'\narr_crop_india = arr_c[py_min:py_max, px_min:px_max]\n\n# We do the same for New Dehli\nlon_min, lon_max = 76.8, 77.5\nlat_min, lat_max = 28.4, 28.9\npx_min2, py_max2 = latlon_to_pixel(lat_min, lon_min, gt)\npx_max2, py_min2 = latlon_to_pixel(lat_max, lon_max, gt)\narr_crop_delhi = arr_c[py_min2:py_max2, px_min2:px_max2]\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#defining-locations-of-interest","position":79},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Plotting results","lvl4":"3.4 Croping to areas of interest: Northern India and New Dehli","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#plotting-results","position":80},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Plotting results","lvl4":"3.4 Croping to areas of interest: Northern India and New Dehli","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"content":"\n\n# Selecting the color scheme \ncmap = \"plasma\"  \n\n# Settlings to ensure we have 2 plots, side by side\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\nvmin, vmax = 27, 50  \n\n# \nim1 = axes[0].imshow(arr_crop_india, cmap=cmap, vmin=vmin, vmax=vmax)\naxes[0].set_title(\"LST (°C) - Northern India\")\ncbar1 = fig.colorbar(im1, ax=axes[0], orientation=\"horizontal\", fraction=0.046, pad=0.08)\ncbar1.set_label(\"LST (°C)\")\n\n# Mark New Delhi on Northern India map\ndelhi_lat, delhi_lon = 28.61, 77.21\npx_delhi, py_delhi = latlon_to_pixel(delhi_lat, delhi_lon, gt)\npx_delhi_rel = px_delhi - px_min\npy_delhi_rel = py_delhi - py_min\naxes[0].scatter(px_delhi_rel, py_delhi_rel, color=\"red\", s=40, marker=\"o\")\naxes[0].text(px_delhi_rel + 5, py_delhi_rel - 5, \"New Delhi\", color=\"white\",\n             fontsize=10, weight=\"bold\", backgroundcolor=\"black\")\n\n# Plot side-by-side\nim2 = axes[1].imshow(arr_crop_delhi, cmap=cmap, vmin=vmin, vmax=vmax)\naxes[1].set_title(\"LST (°C) - New Delhi (Cropped and zoomed it)\")\ncbar2 = fig.colorbar(im2, ax=axes[1], orientation=\"horizontal\", fraction=0.046, pad=0.08)\ncbar2.set_label(\"LST (°C)\")\n\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#plotting-results","position":81},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.5 Identifying locations where Heatwave has occured in June 2024","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-5-identifying-locations-where-heatwave-has-occured-in-june-2024","position":82},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.5 Identifying locations where Heatwave has occured in June 2024","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"content":"","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-5-identifying-locations-where-heatwave-has-occured-in-june-2024","position":83},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl6":"Defiyning the threshold:","lvl4":"3.5 Identifying locations where Heatwave has occured in June 2024","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"type":"lvl6","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#defiyning-the-threshold","position":84},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl6":"Defiyning the threshold:","lvl4":"3.5 Identifying locations where Heatwave has occured in June 2024","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"content":"Applying a threshold (temperature limit from which it’s considered to be a ‘heatwave’): 40\n\nthreshold = 40\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#defiyning-the-threshold","position":85},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl6":"Selecting the AoI","lvl4":"3.5 Identifying locations where Heatwave has occured in June 2024","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"type":"lvl6","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#selecting-the-aoi","position":86},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl6":"Selecting the AoI","lvl4":"3.5 Identifying locations where Heatwave has occured in June 2024","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"content":"From before we defined New Delhi arr_crop_delhi or northern india arr_crop_india\n\narr_view = arr_crop_delhi\n\nCreating a mask with that value\n\n# Create a colormap from plasma\nbase_cmap = plt.cm.plasma\nnewcolors = base_cmap(np.linspace(0, 1, 256))\nvmin, vmax = 27, 49\n\n# Create a ListedColormap\ncmap = mcolors.ListedColormap(newcolors)\n\n# Create a mask for values > threshold\narr_masked = np.where(arr_view > threshold, np.nan, arr_view)\n\n# Plot\nfig, ax = plt.subplots(figsize=(12, 9))\nim = ax.imshow(arr_masked, cmap=cmap, vmin=vmin, vmax=vmax)\n\n# Overlay black for pixels > threshold\nax.imshow(np.where(arr_view > threshold, 1, np.nan), cmap=mcolors.ListedColormap([[0,0,0,1]]))\n\n# Colorbar\ncbar = fig.colorbar(im, ax=ax, orientation=\"horizontal\", fraction=0.046, pad=0.08)\ncbar.set_label(\"LST (°C)\")\ncbar.ax.text(0.99, -0.99, f\">{threshold}°C = black = heatwave location\", color=\"black\",\n             fontsize=12, ha='center', va='center', transform=cbar.ax.transAxes)\n\n# Title\nax.set_title(\"LST (°C) July Average Land Surface Temperatures\", fontsize=16)\n\n\n# Only show New Delhi if arr_view is arr_crop_india\nif 'arr_crop_india' in globals() and arr_view is arr_crop_india:\n    ax.scatter(px_delhi_rel, py_delhi_rel, color=\"red\", s=100, marker=\"X\")\n    circle = patches.Circle((px_delhi_rel, py_delhi_rel), radius=40,\n                            edgecolor='red', facecolor='none', linewidth=2.5)\n    ax.add_patch(circle)\n    ax.text(px_delhi_rel + 50, py_delhi_rel - 15, \"New Delhi\",\n            color=\"white\", fontsize=10, weight=\"bold\", backgroundcolor=\"black\")\n\n\nplt.tight_layout()\nplt.show()\n\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#selecting-the-aoi","position":87},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.6 Calculating areas (sqkm) affected within the selected area","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-6-calculating-areas-sqkm-affected-within-the-selected-area","position":88},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.6 Calculating areas (sqkm) affected within the selected area","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"content":"\n\n# Mask pixels above threshold value\nhot_pixels = arr_view > threshold\n\n# Count pixels\nnum_hot_pixels = np.sum(hot_pixels)\n\n# Assuming 1 km² per pixel\narea_km2 = num_hot_pixels * 1  # 1 km² per pixel\n\nprint(f\"Number of pixels > {threshold}°C: {num_hot_pixels}\")\nprint(f\"Total area > {threshold}°C: {area_km2} km²\")\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-6-calculating-areas-sqkm-affected-within-the-selected-area","position":89},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.7 Final remarks","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-7-final-remarks","position":90},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"3.7 Final remarks","lvl3":"Analyzing Land Surface Temperature with GCOM-C ‘Shikisai’ Satellite Data from JAXA","lvl2":"USE CASE 3: HEATWAVES"},"content":"High Temperatures Around New Delhi\nThe highlighted region (New Delhi) shows elevated land surface temperatures, consistent with the reported heatwave where values exceeded 40 °C.\n\nCentral and northwestern plains (yellow/orange shades) show much higher LST, typical of semi-arid and urbanized regions during peak summer.\n\nUrban Heat Island Effect - The dense, bright patch around New Delhi suggests an intensified heating effect compared to the surrounding rural areas, which may be attributed to urbanization, infrastructure, and reduced vegetation cover.\n\nIn contrast, coastal and mountainous regions show a clear temperature contrast, indicating geographical control over heat distribution.\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-7-final-remarks","position":91},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl2","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-case-4-urban-health","position":92},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-case-4-urban-health","position":93},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#assessing-deprivation-and-poverty-in-new-dehli-and-gurugram","position":94},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"\n\nThis use case demonstrates how to estimate deprivation and poverty of two cities, using the Global Gridded Relative Deprivation Index (GRDI), Version 1 dataset. characterizes the relative levels of multidimensional deprivation and poverty where a value of 100 represents the highest level of deprivation and a value of 0 the lowest. GRDI is built from sociodemographic and satellite data inputs that were spatially harmonized, indexed, and weighted into six main components to produce the final GRDI layer. Inputs were selected from the best-available data that either continuously vary across space or have at least administrative level 1 (provincial/state) resolution, and which have global spatial coverage. GRDI has six input components, or dimensions, that are combined to determine the degree of relative deprivation:\n\nBuilt-up to Non-built-up Area Ratio (BUILT): Lower ratios mean higher deprivation, as rural areas (with less built-up land) tend to face more poverty.\n\nChild Dependency Ratio (CDR): Higher ratios mean higher deprivation, since more children depend on fewer working-age adults.\n\nInfant Mortality Rate (IMR): Higher mortality rates signal higher deprivation.\n\nSubnational Human Development Index (SHDI): Lower values mean higher deprivation in education, health, and living standards.\n\nVIIRS Night Lights (VNL): Lower light intensity indicates higher deprivation, reflecting weaker economic activity and infrastructure.\n\nVNL Slope (2012–2020): A positive slope (increasing brightness) implies decreasing deprivation; a negative slope implies increasing deprivation.\n\nIn this use case, we will compare both the GRDI and VNL slope specifically to the the cities of New Dehli and Gurugram.\n\nThe Global Gridded Relative Deprivation Indexindicator can be explored on the EO Dashboard by selecting the EXPLORE DATASETS mode and choosing \n\nGRDI Indicator.\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#assessing-deprivation-and-poverty-in-new-dehli-and-gurugram","position":95},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"4.1. Input data (GRDI)","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-1-input-data-grdi","position":96},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"4.1. Input data (GRDI)","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"Temporal Resolution: n/a ( single image resulting from the aggregation of 6 indicators collected within (2010-2020)\n\nSpatial Extent: Global\n\nSpatial Resolution: 30 arc-second (~1 km x 1 km)\n\nData Units: relative level of multidimensional deprivation and poverty in each pixel represented as an index from 0 to 100\n\nDOI: \n\nCenter For International Earth Science Information Network-CIESIN-Columbia University (2022)\n\nDataset documentation: \n\nhttps://​www​.earthdata​.nasa​.gov​/data​/catalog​/sedac​-ciesin​-sedac​-pmp​-grdi​-2010​-2020​-1​.00​#documents​-and​-resources\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-1-input-data-grdi","position":97},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"4.2 Import python libraries","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-2-import-python-libraries","position":98},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"4.2 Import python libraries","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"\n\nimport os\nimport requests\nfrom IPython.display import Image\nimport mercantile\nfrom io import BytesIO\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport mercantile\nimport numpy as np\nfrom shapely.geometry import Polygon, Point\n#from pykml import parser\nimport matplotlib.pyplot as plt\n#!pip install fastkml shapely\n#!pip install pykml\nimport requests\nimport folium\nfrom folium.raster_layers import ImageOverlay\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-2-import-python-libraries","position":99},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"4.3 Defining working folders","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-3-defining-working-folders","position":100},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"4.3 Defining working folders","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"\n\noutput_urban = \"output\"\nurban_path = os.path.join(os.getcwd(), \"Poverty\", output_urban)\n\n# Create output dir\nos.makedirs(urban_path, exist_ok=True)\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-3-defining-working-folders","position":101},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"4.4. Visualizing the input data","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-4-visualizing-the-input-data","position":102},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"4.4. Visualizing the input data","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-4-visualizing-the-input-data","position":103},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Query the STAC endpoint","lvl4":"4.4. Visualizing the input data","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#query-the-stac-endpoint","position":104},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Query the STAC endpoint","lvl4":"4.4. Visualizing the input data","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"GRDI dataset and all its 6 forming components \n\nare part of the EO Dashboard data ecosystem: check the collections. and explore them on the EO Dashboard:\n\nGRDI; \n\nBuiltup Area; \n\nChild Dependency Ratio; \n\nInfant Mortality Rates.\n\nThe data endpoint in this case is not public accessible, but NASA VEDA allows to use a Tile Endpoint, which enables to show interactive map without downloading the full raster (VEDA API handles S3 authentication). VEDA endpoint is used by EO Dashboard that directly interacts with the services provided by VEDA, e.g. like rendering the image.\n\nfrom pystac_client import Client\n\n# STAC endpoint\nstac_url = \"https://openveda.cloud/api/stac/\"\nclient = Client.open(stac_url)\n\n# list available collections. \n# Uncomment below to see all collecions:\n#collections = [c.id for c in client.get_collections()]\n#print(collections[:])  # print all collections\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#query-the-stac-endpoint","position":105},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Selection of collection","lvl4":"4.4. Visualizing the input data","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#selection-of-collection","position":106},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Selection of collection","lvl4":"4.4. Visualizing the input data","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"Selecting which dataset to query\n\ncollection_id = \"grdi-v1-raster\"\n#collection_id =  \"grdi-v1-raster\" or \"grdi-vnl-slope-raster\" or  'grdi-vnl-raster' or grdi-v1-built', 'grdi-v1-raster',\"grdi-vnl-slope-raster\" or\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#selection-of-collection","position":107},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Query the STAC Endpoint with selected collection","lvl4":"4.4. Visualizing the input data","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#query-the-stac-endpoint-with-selected-collection","position":108},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Query the STAC Endpoint with selected collection","lvl4":"4.4. Visualizing the input data","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"\n\nsearch = client.search(collections=[collection_id], max_items=5)\nitems = list(search.items())\n\nprint(f\"Found {len(items)} items\")\n\n# Look at the first item\nitem = items[0]\nprint(\"Item ID:\", item.id)\nprint(\"Assets:\", item.assets.keys())\n\ncog_url = item.assets[\"cog_default\"].href\nprint(\"Data endpoint: COG URL:\", cog_url)\n\ncog_url = item.assets[\"rendered_preview\"].href\nprint(\"Rendered preview:\", cog_url)\n\ncog_path = item.assets.get(\"cog_default\", None)\nif cog_path is None:\n    raise ValueError(\"No COG asset found for this item!\")\n\ncog_path = cog_path.href\nprint(\"COG PATH:\", cog_path)\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#query-the-stac-endpoint-with-selected-collection","position":109},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Preview of data","lvl4":"4.4. Visualizing the input data","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#preview-of-data","position":110},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Preview of data","lvl4":"4.4. Visualizing the input data","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"\n\ncog_preview_url = item.assets[\"rendered_preview\"].href\n\nresponse = requests.get(cog_preview_url)\nimg = Image.open(BytesIO(response.content))\n\nplt.figure(figsize=(8,6))\nplt.imshow(img)\nplt.axis(\"off\")\nplt.title(\"Rendered Preview\")\nplt.show()\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#preview-of-data","position":111},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Tile Endpoint","lvl4":"4.4. Visualizing the input data","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#tile-endpoint","position":112},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Tile Endpoint","lvl4":"4.4. Visualizing the input data","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"Using Tile endpoint since in this case S3 path is not public\n\nThe VEDA Tile endpoint generates Web Mercator map tiles from a Cloud-Optimized GeoTIFF (COG) for given z/x/y coordinates, applying optional resampling, band selection, colormap, and value rescaling.\n\n# Coordinates over India\nlon, lat = 77.1025, 28.7041\nzoom = 6\n\n# Converts longitude and latitude into a tile in the Web Mercator grid\ntile = mercantile.tile(lon, lat, zoom)\n\n# Tile endpoint (which takes the COG and returns map tiles)\nbase_url = \"https://openveda.cloud/api/raster/cog/tiles/WebMercatorQuad\"\n\n# Constructs the full url to request the tile image\ntile_url = (\n    f\"{base_url}/{tile.z}/{tile.x}/{tile.y}\"\n    f\"?url={cog_path}&resampling_method=nearest&bidx=1\"\n    f\"&colormap_name=viridis&rescale=0,100\"\n)\n\n# Request and plot the tile\nresponse = requests.get(tile_url)\nimg = Image.open(BytesIO(response.content))\n\nplt.imshow(img)\nplt.axis(\"off\")\nplt.title(f\"GRDI - Zoomed to India (Zoom level: {zoom})\")\nplt.show()\n\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#tile-endpoint","position":113},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"4.4 Comparing two cities: New Delhi vs Gurugram","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-4-comparing-two-cities-new-delhi-vs-gurugram","position":114},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"4.4 Comparing two cities: New Delhi vs Gurugram","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-4-comparing-two-cities-new-delhi-vs-gurugram","position":115},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Definition of the city boundaries","lvl4":"4.4 Comparing two cities: New Delhi vs Gurugram","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#definition-of-the-city-boundaries","position":116},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Definition of the city boundaries","lvl4":"4.4 Comparing two cities: New Delhi vs Gurugram","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"Since we are comparing specifically the overall indicator of two distinct cities, we will try to focus on their admnistrative context\n\nYou can hand-draw your own coordinates, or downdload kml or shapefile for your AoI\n\n# Coordinates for cities \nnewdelhi_nd = Polygon([(77.05010024928556, 28.545329632240488),(77.06932632350431, 28.527232785401164),(77.12151138209806, 28.493443691269704),(77.11052505397306, 28.458436437649425),(77.15172378444181, 28.435494362127248),(77.19292251491056, 28.4463622814295),(77.20253555201994, 28.472923604842666),(77.19292251491056, 28.497064469025712),(77.23961440944181, 28.5043056518795),(77.28355972194181, 28.530852403411522),(77.31102554225431, 28.545329632240488),(77.28767959498869, 28.571866050451412),(77.32201187037931, 28.574278120363793),(77.35085098170744, 28.6032186447749),(77.34398452662931, 28.633356550416348),(77.36321060084806, 28.65505048508341),(77.32475845241056, 28.73214811494396),(77.34398452662931, 28.777897949422616),(77.25884048366056, 28.786323363598065),(77.23961440944181, 28.730943901281826),(77.23686782741056, 28.705652209939004),(77.19841567897306, 28.729739673745172),(77.17094985866056, 28.751413646301874),(77.11876480006681, 28.768268071318303),(77.10365859889494, 28.751413646301874),(77.06245986842619, 28.724922624860923),(77.02812759303556, 28.67914959345852),(77.01027480983244, 28.638177812503272),(77.00478164576994, 28.593572688482055),(77.01988784694181, 28.569453925238474),(77.05010024928556, 28.545329632240488)])\ngurugram_nd = Polygon([(77.03636733912931, 28.552567500585084),(77.06795303248869, 28.526026218441455),(77.10777847194181, 28.493443691269704),(77.11464492701994, 28.43066381740982),(76.99928848170744, 28.389595287262374),(76.97319595241056, 28.388387148302826),(76.92650405787931, 28.334006651363715),(76.87981216334806, 28.359387683848297),(76.89079849147306, 28.400467918290314),(76.92238418483244, 28.478959338289766),(76.96844764838063, 28.48499472683416),(77.00827308783376, 28.50792605695689),(77.00415321478688, 28.540504110335135),(77.03636733912931, 28.552567500585084)])\n#ballabgarh_nd = Polygon([(77.305, 28.390),(77.315, 28.385),(77.325, 28.375),(77.330, 28.365),(77.320, 28.355),(77.310, 28.350),(77.300, 28.355),(77.295, 28.365),(77.295, 28.375),(77.300, 28.385),(77.305, 28.390)])\n#ghaziabad_nd = Polygon([(77.380, 28.670),(77.400, 28.660),(77.420, 28.645),(77.435, 28.625),(77.430, 28.605),(77.410, 28.590),(77.390, 28.595),(77.370, 28.610),(77.360, 28.630),(77.365, 28.650),(77.380, 28.670)])\n\n# Creating a dictionary of the cities to loop through them later\npolygons = {\n    \"New Delhi\": newdelhi_nd,\n    \"Gurugram\": gurugram_nd\n}\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#definition-of-the-city-boundaries","position":117},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Fetch COG into tile","lvl4":"4.4 Comparing two cities: New Delhi vs Gurugram","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#fetch-cog-into-tile","position":118},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Fetch COG into tile","lvl4":"4.4 Comparing two cities: New Delhi vs Gurugram","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"Fetches COG map tiles for polygon-centered coordinates, crops them to the polygons, and overlays onto a Folium map\n\n\n# This will fetch the map tile image of defined lon and lat and a cog_raster\ndef get_tile_image(lon, lat, zoom, cog_path, base_url):\n    tile = mercantile.tile(lon, lat, zoom)\n    url = (\n        f\"{base_url}/{tile.z}/{tile.x}/{tile.y}\"\n        f\"?url={cog_path}&resampling_method=nearest&bidx=1\"\n        f\"&colormap_name=viridis&rescale=0,100\"\n    )\n    response = requests.get(url)\n    img = Image.open(BytesIO(response.content)).convert(\"RGBA\")\n    return np.array(img), tile\n\n# Crops the tile into defined polygon\ndef crop_to_polygon(img_array, tile, polygon):\n    height, width = img_array.shape[:2]\n    lon_ul, lat_ul = mercantile.ul(tile.x, tile.y, tile.z).lng, mercantile.ul(tile.x, tile.y, tile.z).lat\n    lon_lr, lat_lr = mercantile.ul(tile.x+1, tile.y+1, tile.z).lng, mercantile.ul(tile.x+1, tile.y+1, tile.z).lat\n    res_lon = (lon_lr - lon_ul) / width\n    res_lat = (lat_lr - lat_ul) / height\n\n    mask = np.zeros((height, width), dtype=bool)\n    for i in range(height):\n        for j in range(width):\n            lat_p = lat_ul + i * res_lat\n            lon_p = lon_ul + j * res_lon\n            if polygon.contains(Point(lon_p, lat_p)):\n                mask[i, j] = True\n    img_array[~mask] = [0, 0, 0, 0]\n    return img_array\n\n# --- Settings ---\nzoom = 8\n#base_url = \"https://openveda.cloud/api/raster/cog/tiles/WebMercatorQuad\"\n#cog_path = \"s3://veda-data-store/grdi-v1-raster/povmap-grdi-v1_2010-01-01_2021-12-31.tif\"\n# cog_path= \"s3://veda-data-store/grdi-vnl-slope-raster/povmap-grdi-v1_VNL-slope_2012-01-01_2020-12-31.tif\"\n\n\n\n# Loop through each city to get the tile crop and plot\nm = folium.Map(location=[28.55, 77.13], zoom_start=11)\n\nfor city, polygon in polygons.items():\n    # Get approximate center of polygon for fetching tile\n    lon, lat = polygon.centroid.x, polygon.centroid.y\n    img, tile = get_tile_image(lon, lat, zoom, cog_path, base_url)\n    img = crop_to_polygon(img, tile, polygon)\n\n    # Overlay image\n    ul_lat, ul_lon = mercantile.ul(tile.x, tile.y, tile.z).lat, mercantile.ul(tile.x, tile.y, tile.z).lng\n    lr_lat, lr_lon = mercantile.ul(tile.x+1, tile.y+1, tile.z).lat, mercantile.ul(tile.x+1, tile.y+1, tile.z).lng\n    ImageOverlay(image=img, bounds=[[lr_lat, ul_lon], [ul_lat, lr_lon]], opacity=0.6).add_to(m)\n\n    # Add border\n    folium.Polygon(\n        locations=[(lat, lon) for lon, lat in polygon.exterior.coords],\n        color='red' if city==\"New Delhi\" else 'blue',\n        weight=6,  # <-- thicker border\n        fill=False\n).add_to(m)\n\nm\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#fetch-cog-into-tile","position":119},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"4.5 Estimating poverty (average values): New Delhi vs Gurugram","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-5-estimating-poverty-average-values-new-delhi-vs-gurugram","position":120},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"4.5 Estimating poverty (average values): New Delhi vs Gurugram","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"\n\n# Fetch tile image \ndef get_tile_image(lon, lat, zoom, cog_path, base_url):\n    tile = mercantile.tile(lon, lat, zoom)\n    url = (\n        f\"{base_url}/{tile.z}/{tile.x}/{tile.y}\"\n        f\"?url={cog_path}&resampling_method=nearest&bidx=1\"\n        f\"&colormap_name=viridis&rescale=0,100\"\n    )\n    response = requests.get(url)\n    img = Image.open(BytesIO(response.content))\n    img_array = np.array(img).astype(float)\n\n    # Rescale if tile is in 0-255\n    if img_array.max() > 100:\n        img_array = img_array * (100.0 / 255.0)\n\n    return img_array, tile\n\n#  Generate boolean mask for each city/polygon\ndef polygon_mask(tile, polygon, img_shape):\n    height, width = img_shape[:2]\n    lon_ul, lat_ul = mercantile.ul(tile.x, tile.y, tile.z).lng, mercantile.ul(tile.x, tile.y, tile.z).lat\n    lon_lr, lat_lr = mercantile.ul(tile.x+1, tile.y+1, tile.z).lng, mercantile.ul(tile.x+1, tile.y+1, tile.z).lat\n\n    res_lon = (lon_lr - lon_ul) / width\n    res_lat = (lat_lr - lat_ul) / height\n\n    mask = np.zeros((height, width), dtype=bool)\n    for i in range(height):\n        for j in range(width):\n            lon = lon_ul + j * res_lon\n            lat = lat_ul + i * res_lat\n            if polygon.contains(Point(lon, lat)):\n                mask[i, j] = True\n    return mask\n\n# Compute average GRDI for each polygon\ndef compute_average_grdi(polygon, zoom=8):\n    min_lon, min_lat, max_lon, max_lat = polygon.bounds\n    tiles = list(mercantile.tiles(min_lon, min_lat, max_lon, max_lat, zoom))\n    all_values = []\n\n    for tile in tiles:\n        lon = (mercantile.ul(tile.x, tile.y, tile.z).lng + mercantile.ul(tile.x+1, tile.y+1, tile.z).lng) / 2\n        lat = (mercantile.ul(tile.x, tile.y, tile.z).lat + mercantile.ul(tile.x+1, tile.y+1, tile.z).lat) / 2\n\n        img_array, tile = get_tile_image(lon, lat, tile.z, cog_path, base_url)\n\n        mask = polygon_mask(tile, polygon, img_array.shape)\n        all_values.extend(img_array[mask])\n\n    return np.mean(all_values) if all_values else np.nan\n\n\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-5-estimating-poverty-average-values-new-delhi-vs-gurugram","position":121},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Visualizing averaged values by city","lvl4":"4.5 Estimating poverty (average values): New Delhi vs Gurugram","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#visualizing-averaged-values-by-city","position":122},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Visualizing averaged values by city","lvl4":"4.5 Estimating poverty (average values): New Delhi vs Gurugram","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"\n\n# Compute averages\naverages = {city: compute_average_grdi(poly, zoom) for city, poly in polygons.items()}\n\n# Print results\nfor city, avg in averages.items():\n    print(f\"Average GRDI for {city}: {avg:.2f}\")\n\n# Plot results\nplt.figure(figsize=(6, 4))\nplt.bar(averages.keys(), averages.values(), color=['red', 'blue'])\nplt.ylabel(\"Average GRDI Value\")\nplt.title(\"Average GRDI (Masked by Polygons)\")\nfor i, v in enumerate(averages.values()):\n    plt.text(i, v + 0.5, f\"{v:.1f}\", ha='center', fontsize=10, fontweight='bold')\nplt.ylim(0, max(averages.values()) * 1.2)\nplt.show()\n\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#visualizing-averaged-values-by-city","position":123},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Export graph results","lvl4":"4.5 Estimating poverty (average values): New Delhi vs Gurugram","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl5","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#export-graph-results","position":124},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl5":"Export graph results","lvl4":"4.5 Estimating poverty (average values): New Delhi vs Gurugram","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"\n\n# Sets location of output\noutput_file = os.path.join(urban_path, \"average_grdi.png\")\n\n# --- Plot bar chart and save ---\nplt.figure(figsize=(6, 4))\nplt.bar(averages.keys(), averages.values(), color=['red', 'blue'])\nplt.ylabel(\"Average Value\")\nplt.title(\"Average GRDI (Masked by Polygons)\")\nfor i, v in enumerate(averages.values()):\n    plt.text(i, v + 0.5, f\"{v:.1f}\", ha='center', fontsize=10, fontweight='bold')\nplt.ylim(0, max(averages.values()) * 1.2)\n\n# Save figure\nplt.savefig(output_file, dpi=300, bbox_inches='tight')\nplt.close()\nprint(f\"Graph saved to: {output_file}\")\n\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#export-graph-results","position":125},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"4.5 Final remarks","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-5-final-remarks","position":126},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl4":"4.5 Final remarks","lvl3":"Assessing deprivation and poverty in New Dehli and Gurugram","lvl2":"USE CASE 4: URBAN HEALTH"},"content":"\n\nOverall GRDI values are ‘mid’. Both New Delhi (51.6) and Gurugram (52) have GRDI values close to the middle on a 0–100 scale, suggesting relative deprivation & proverty . Gurugram slightly higher than New Delhi, Gurugram’s average higher than New Delhi could indicate marginally worse development indicators, but the difference is small—so not necessarily a large practical difference.\n\nHowever, other indicators might indicate a relatively different result.","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-5-final-remarks","position":127},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site"},"type":"lvl1","url":"/notebooks/fire-impact-analysis","position":0},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site"},"content":"","type":"content","url":"/notebooks/fire-impact-analysis","position":1},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Geo-storytelling with RACE, EO Dashboard and the Euro Data Cube"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#geo-storytelling-with-race-eo-dashboard-and-the-euro-data-cube","position":2},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Geo-storytelling with RACE, EO Dashboard and the Euro Data Cube"},"content":"\n\nThis notebook demonstates how to access and analyse data found on the \n\nRapid Action for Citizens with Earth Observation (RACE) and \n\nEarth Observation Dashboard. It uses the EC-JRC’s Global Human Settlement (GHS) Layer which contains global data about the total built-up surface from 1975 to 2030 and was derived from Sentinel2 composite and Landsat imagery. The data is openly available and can be downloaded \n\nhere. It was ingested in EDC and provided as a layer, check out the documentation \n\nhere for further information about the data properties in EDC.\nThe GHS indicator can be explored on the EO Dashboard by selecting the \n\nEXPLORE DATASETS mode.\n\n","type":"content","url":"/notebooks/fire-impact-analysis#geo-storytelling-with-race-eo-dashboard-and-the-euro-data-cube","position":3},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Euro Data Cube - EDC Platform presentation"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#euro-data-cube-edc-platform-presentation","position":4},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Euro Data Cube - EDC Platform presentation"},"content":"\n\n\n\n","type":"content","url":"/notebooks/fire-impact-analysis#euro-data-cube-edc-platform-presentation","position":5},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"EDC - cloud-optimized platform offering:"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#edc-cloud-optimized-platform-offering","position":6},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"EDC - cloud-optimized platform offering:"},"content":"Access to EO archives from main all open missions (e.g. Sentinel, Landsat, MODIS, etc.), commercial satellites (PlanetScope, Pleiades, SPOT, WorldView, etc.) as well as Level 3 products (Copernicus Land Monitoring Services, C3S, etc.)\n\nAnalyse, compare and correlate EO data through Xcube and operational tools (Sentinel Hub)\n\nManage different data formats and type in a transparent way (raster, vector, COGs, Zarr, etc.)\n\nBring and store your own data and algorithm for real-time and batch processing operations\n\nComputational resources and storage to run Jupyter Notebooks and your deployed Applications within your Kubernetes-powered workspace\n\nExpose your apps on the EDC marketplace to third-parties and provide easy access to your managed API service to customers\n\n\n\n","type":"content","url":"/notebooks/fire-impact-analysis#edc-cloud-optimized-platform-offering","position":7},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"EDC - Market Place"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#edc-market-place","position":8},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"EDC - Market Place"},"content":"\n\nData Products: e.g. \n\nSentinel Hub\n\nPlatform Services: e.g. \n\nEOxHub\n\nAPI Services: e.g. \n\nGeoDB, \n\nSH-Statistical API\n\n","type":"content","url":"/notebooks/fire-impact-analysis#edc-market-place","position":9},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"Content of this notebook:"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#content-of-this-notebook","position":10},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"Content of this notebook:"},"content":"Visualizing wildfire events with Sentinel-2 imagery\n\nQuerying data via Statistical API for the chosen Area of Interest\n\nTransforming the output of the API request into a geoJSON polygon that contains the extent of the built up area in the AOI\n\nAccessing Sentinel-5p Carbon monoxide data from SentinelHub\n\nDisplaying the time series of the CO concentration over the populated area to evaluate the possible impact of the fire emissions\n\nThis notebook runs with the python environment users-edc-2023.07-01 and was prepared by Leah Sturm (University of Trier, Germany).\n\n#import necessary libraries\nimport os\nimport numpy as np\nimport geopandas as gpd\nimport rasterio\nfrom rasterio.features import shapes\nimport requests\nimport geojson\nfrom shapely.geometry import shape\nfrom rasterio.transform import from_origin\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\n\n# Sentinel Hub requirements\nfrom sentinelhub import (SHConfig, DataCollection, Geometry, BBox, Geometry,\n                         SentinelHubRequest, filter_times, bbox_to_dimensions, MimeType, \n                         SentinelHubBYOC, ByocCollection, ByocTile, ByocCollectionAdditionalData,\n                         DownloadFailedException, CRS, SentinelHubStatistical)\n\n# Pass Sentinel Hub credentials to SHConfig\nconfig = SHConfig()\nconfig.sh_client_id = os.environ[\"SH_CLIENT_ID\"]\nconfig.sh_client_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\nclient_id = os.environ[\"SH_CLIENT_ID\"]\nclient_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\n\n# config\n\n","type":"content","url":"/notebooks/fire-impact-analysis#content-of-this-notebook","position":11},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Create a folder for the session in which all files will be stored","lvl2":"Content of this notebook:"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#create-a-folder-for-the-session-in-which-all-files-will-be-stored","position":12},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Create a folder for the session in which all files will be stored","lvl2":"Content of this notebook:"},"content":"\n\n# Get the current date and format it as a string\ncurrent_date = datetime.now().strftime(\"%Y-%m-%d\")\n\n# Define the folder name and path\nfolder_name = f\"folder_{current_date}\"\nfolder_path = os.path.join(os.getcwd(), folder_name)\n\n# Check if the folder already exists, and create it if not\nif not os.path.exists(folder_path):\n    os.mkdir(folder_path)\n    print(f\"Folder '{folder_name}' created at: {folder_path}\")\nelse:\n    print(f\"Folder '{folder_name}' already exists at: {folder_path}\")\n\n","type":"content","url":"/notebooks/fire-impact-analysis#create-a-folder-for-the-session-in-which-all-files-will-be-stored","position":13},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"Wildfire Impacts and Carbon Emissions"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#wildfire-impacts-and-carbon-emissions","position":14},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"Wildfire Impacts and Carbon Emissions"},"content":"The wildfire season during the summer of 2022 in Europe was exceptional, marked by a high number of observed fires, a large extent of burned area, and remarkably high atmospheric emissions linked to these fires. According to data from the European Forest Fire Information System (EFFIS), fires were reported in 26 out of the 27 European countries, collectively burning 837,212 hectares. A significant portion of these wildfires happened in July, with Spain, Portugal, France, and Italy experiencing the most damages.\n\nThe selected wildfire incident for this notebook occurred in the Gironde region of southwestern France, near the city of Bordeaux, in 2022. The significant fire event started on July 17, 2022, lasted for two weeks while burning approximately 7,000 hectares of land. Notably, the Copernicus Atmosphere Monitoring Service (CAMS) recorded exceptionally elevated levels of carbon monoxide emissions throughout the duration of this event.\n\nRelated articles about the event and the wildfire occurrence in 2022:\n\nEuropean Space Agency\n\nEU ScienceHub\n\nEFFIS\n\nCopernicus Atmosphere Monitoring Service\n\nEUMETSAT\n\n","type":"content","url":"/notebooks/fire-impact-analysis#wildfire-impacts-and-carbon-emissions","position":15},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#id-1-visualize-wildfire-event-with-sentinel-2","position":16},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"In this first part we are going to visualize the fire event to get an overview of the location and the occuring emissions. In the following cells we will access Sentinel-2 imagery from \n\nSentinel Hub. Sentinel Hub is a multi-spectral and multi-temporal big data satellite imagery service, capable of fully automated archiving, real-time processing and distribution of remote sensing data and related EO products. Users can use APIs to retrieve satellite data over their AOI and specific time range from full archives in a matter of seconds. The following cells to access Sentinel-2 data are based on the example notebook “Australian Bushfires” which is available in the \n\nEuro Data Cube Marketplace.\n\nTo get a first overview of the fire event we are going to look at the true colour image captured on the day of the start of the fire.\n\n","type":"content","url":"/notebooks/fire-impact-analysis#id-1-visualize-wildfire-event-with-sentinel-2","position":17},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Define Area of Interest","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#define-area-of-interest","position":18},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Define Area of Interest","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"\n\nbbox_coords =[\n  -1.006524,\n  44.318762,\n  -0.406214,\n  44.586411\n]\n\nresolution = 20\nArea_of_interest_bbox = BBox(bbox=bbox_coords, crs=CRS.WGS84)\nArea_of_interest_size = bbox_to_dimensions(Area_of_interest_bbox, resolution=resolution)\n\n# Bbox EPSG\nbbox_epsg = 4326\n\n# Utilities\nimport IPython.display\nfrom IPython.display import display, GeoJSON\n\n# Plot the bounding box on a map\nIPython.display.GeoJSON(BBox(bbox_coords,crs=bbox_epsg).get_geojson())\n\n","type":"content","url":"/notebooks/fire-impact-analysis#define-area-of-interest","position":19},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Access Sentinel-2 data","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#access-sentinel-2-data","position":20},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Access Sentinel-2 data","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"We build the request according to the \n\nAPI Reference, using the SentinelHubRequest class. Each Process API request also needs an \n\nevalscript.\n\nThe information that we specify in the SentinelHubRequest object is:\n\nan evalscript,\n\na list of input data collections with time interval,\n\na format of the response,\n\na bounding box and it’s size (size or resolution).\n\nThe evalscript is used to select the appropriate bands. We return the RGB (B04, B03, B02) Sentinel-2 L2A bands.\n\n# define the evalscript \n\nevalscript_true_color = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B02\", \"B03\", \"B04\"]\n            }],\n            output: {\n                bands: 3\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B04, sample.B03, sample.B02];\n    }\n\"\"\"\n\n# we nned to specify the collection and the time interval\n# for a list of collections available in the Sentinel Hub visit https://docs.sentinel-hub.com/api/latest/data/ \n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_true_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L2A, \n            time_interval=('2022-07-16', '2022-07-18'),\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.PNG)\n    ],\n    bbox=Area_of_interest_bbox,\n    size=Area_of_interest_size,\n    config=config\n)\n\n","type":"content","url":"/notebooks/fire-impact-analysis#access-sentinel-2-data","position":21},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Visualize the requested Sentinel image","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#visualize-the-requested-sentinel-image","position":22},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Visualize the requested Sentinel image","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"\n\n# send the request to Sentinel Hub\n#true_color_imgs = request_true_color.get_data()\n\nmax_retries = 3\nretry_count = 0\nwhile retry_count < max_retries:\n    try:\n        true_color_imgs = request_true_color.get_data()\n        break  # Image displayed successfully, exit the loop\n    except Exception as e:\n        print(f\"Failed to display image: {e}\")\n        retry_count += 1\n        if retry_count < max_retries:\n            print(f\"Retrying (Attempt {retry_count})...\")\n \nif retry_count >= max_retries:\n    print(\"Maximum retries reached. Unable to retrieve the image.\")\n    \n# Define the plot_image function\n\ndef plot_image(image, factor=1.0, clip_range = None, **kwargs):\n    \"\"\"\n    Utility function for plotting RGB images.\n    \"\"\"\n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n    if clip_range is not None:\n        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n    else:\n        ax.imshow(image * factor, **kwargs)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nimage = true_color_imgs[0]\nprint(f'Image type: {image.dtype}')\n    \n# plot function\n# factor 1/255 to scale between 0-1\n# factor 3.5 to increase brightness\n\n# Maximum number of retry attempts\n\nplot_image(image, factor=3.5/255, clip_range=(0,1))\n\nThe visualized image captures the start of the  wildfire event which is prominently visible in the top right corner. The plume and emissions from the fire event extend westwards. Consequently, the analysis within this notebook will center around urban areas within those western regions.\n\n","type":"content","url":"/notebooks/fire-impact-analysis#visualize-the-requested-sentinel-image","position":23},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Define and visualize AOI for the analysis","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#define-and-visualize-aoi-for-the-analysis","position":24},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Define and visualize AOI for the analysis","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"\n\n# define the coordinates\ntop_left_x =  -1.26747\ntop_left_y = 44.674299\nbottom_right_x = -0.962647\nbottom_right_y = 44.508045\n\nbbox = [   \n  top_left_x,\n  bottom_right_y,\n  bottom_right_x,\n  top_left_y\n        ]\n\n# Bbox EPSG\nbbox_epsg = 4326\n\n# Plot the bounding box on a map\nIPython.display.GeoJSON(BBox(bbox,crs=bbox_epsg).get_geojson())\n\n","type":"content","url":"/notebooks/fire-impact-analysis#define-and-visualize-aoi-for-the-analysis","position":25},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Check the resolution and size of the AOI","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#check-the-resolution-and-size-of-the-aoi","position":26},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Check the resolution and size of the AOI","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"\n\n# Check the resolution and pixels constrains (they have to be maximal 2500x2500)\nresolution = 10\naoi = BBox(bbox=bbox, crs=CRS.WGS84)\naoi_size = bbox_to_dimensions(aoi, resolution=resolution)\n\n# These values are needed to set the right dimensions for saving the request as tiff file later\nwidth = aoi_size[0]  \nheight = aoi_size[1] \n\nprint(f\"Image shape at {resolution} m resolution: {aoi_size} pixels\")\n\n","type":"content","url":"/notebooks/fire-impact-analysis#check-the-resolution-and-size-of-the-aoi","position":27},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#id-2-query-ghs-population-density-layer-with-sentinelhub-api-request","position":28},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"The \n\nStatistical API empowers users to derive insightful statistics from satellite imagery, eliminating the need to download large image files. When making a Statistical API request,it is possible to define an AOI, time frame, evalscript, and the specific statistical measures you wish to compute. The resulting statistics are conveniently included in the API response. With the Statistical API, the user can compute statistics such as cloud pixel percentages within a defined area and timeframe or calculate metrics like mean, standard deviation, and histogram of band values for a specific parcel over a given time frame.\n\nTo access the population density layer, we need to use the designated BYOC ID: 0c7aa265-50f9-4947-9980-2ee5ae204803 found on EDC. To query the GHS layer effectively, we need to provide the BYOC ID, the coordinates from the created GeoJSON file as AOI, the desired timeframe, and the necessary user credentials as inputs. The GHS layer contains data from 1975 to 2030 in 5 years intervals. We are going to query the data for 2020 because it is temporally closest to the chosen wildfire event in 2022.\n\nSource for EC-JRC’s GHS layer: Pesaresi, Martino; Politis, Panagiotis (2023): GHS-BUILT-S R2023A - GHS built-up surface grid, derived from Sentinel2 composite and Landsat, multitemporal (1975-2030). European Commission, Joint Research Centre (JRC) [Dataset] doi: 10.2905/9F06F36F-4B11-47EC-ABB0-4F8B7B1D72EA\n\nThe evalscript in this request creates a new output image where the “dataMask” band is modified based on the values in the GHS layer. If the GHS value is 0, it masks the pixel in the “dataMask” band by setting it to zero. Otherwise, it retains the original GHS value.\n\npopulation_dens = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\"BUILT\", \"dataMask\"], // this sets which bands to use\n    }],\n    output: { // this defines the output image type\n      bands: 1,\n      sampleType: \"UINT8\"\n    }\n  };\n}\n \nfunction evaluatePixel(sample) {\n    let pixelMask = 1\n    \n    if (sample.BUILT == 0){\n        pixelMask = 0\n    }\n  return {\n    default: [sample.BUILT],\n    dataMask: [sample.dataMask * pixelMask]\n  };\n}\n\"\"\"\n\nrequest_data = SentinelHubRequest(\n    evalscript=population_dens,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.define_byoc('0c7aa265-50f9-4947-9980-2ee5ae204803'),\n            time_interval=(\"2020-01-01\", \"2020-01-01\"),\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=aoi,\n    size=aoi_size,\n    config=config,\n)\n\npopulation_density = request_data.get_data()\n\n","type":"content","url":"/notebooks/fire-impact-analysis#id-2-query-ghs-population-density-layer-with-sentinelhub-api-request","position":29},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Extract the population density extent as GeoTiff file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#extract-the-population-density-extent-as-geotiff-file","position":30},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Extract the population density extent as GeoTiff file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"The GHS layer contains \n\nvalues ranging from 0 to 10,000, where higher values indicate greater population density. In this notebook, we only exclude pixels with zero values, but I would be possible to add a threshold to the script below to pinpoint areas of exceptionally high population density.\n\n# the final geotiff is a binary mask with values of 1 representing built-up pixels\nimage_data_list = population_density\n\n# Calculate pixel width and height based on image shape\npixel_width = (bottom_right_x - top_left_x) /  width \npixel_height = (top_left_y - bottom_right_y) / height\n\n# Specify the path to the directory where GeoTIFF files will be saved\noutput_directory = f\"./{folder_name}\"\n# Loop through the list of image arrays\nfor i, image_data in enumerate(image_data_list):\n    # Extract the pixel values (assuming single-band data)\n    pixel_values = image_data[:, :]\n\n    # Set values equal to zero to zero, and all other values to 1\n    pixel_values = np.where(pixel_values == 0, 0, 1)\n\n    # Specify the output path for each GeoTIFF file with the current time\n    output_path = os.path.join(output_directory, f\"output_{current_date}.tif\")\n\n    # Create a transformation for the GeoTIFF\n    transform = from_origin(top_left_x, top_left_y, pixel_width, pixel_height)\n\n    # Open a new GeoTIFF file for writing with NoData value set to NaN\n    with rasterio.open(\n        output_path,\n        'w',\n        driver='GTiff',\n        height=pixel_values.shape[0],\n        width=pixel_values.shape[1],\n        count=1,  # Only one band for pixel values\n        dtype=rasterio.float32,  # Use float32 for NaN values\n        crs='EPSG:4326',\n        transform=transform,\n        nodata=np.nan  # Set NoData value to NaN\n    ) as dst:\n        # Write the pixel values to the GeoTIFF\n        dst.write(pixel_values, 1)  # Use band 1\n\n\n","type":"content","url":"/notebooks/fire-impact-analysis#extract-the-population-density-extent-as-geotiff-file","position":31},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Visualize the extent of the population density layer","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#visualize-the-extent-of-the-population-density-layer","position":32},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Visualize the extent of the population density layer","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"\n\n# Specify the path to the GeoTIFF file\ngeotiff_path = f\"./{folder_name}/output_{current_date}.tif\"\n\n# Open the GeoTIFF file using rasterio\nwith rasterio.open(geotiff_path) as src:\n    # Read the raster data\n    raster_data = src.read(1)  # Assuming you have a single band GeoTIFF\n\n    # Get the spatial transformation information\n    transform = src.transform\n\n# Calculate the bounds based on the width and height of the raster\nleft, bottom, right, top = src.bounds\n\n# Plot the GeoTIFF data using matplotlib\nplt.figure(figsize=(8, 8))\nplt.imshow(raster_data, cmap='gray', extent=(left, right, bottom, top), origin='upper')\nplt.title('Population density in AOI')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.grid(True)\nplt.show()\n\nAll non populated areas are displayed in black in the plot while the populated areas are colored white. From this binary mask we can now create a GeoJSON file that contains only the populated areas.\n\n","type":"content","url":"/notebooks/fire-impact-analysis#visualize-the-extent-of-the-population-density-layer","position":33},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"3. Convert the binary raster mask into a GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#id-3-convert-the-binary-raster-mask-into-a-geojson-file","position":34},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"3. Convert the binary raster mask into a GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"The resulting GeoJSON will only contain polygons for built up areas and will be used as spatial extend to query the Sentinel-5p data later.\n\n# Specify the path to the GeoTIFF file\ngeotiff_path = f\"./{folder_name}/output_{current_date}.tif\"\n\n# Open the GeoTIFF file\nwith rasterio.open(geotiff_path) as src:\n    # Read the binary mask data\n    mask = src.read(1)\n\n# Convert the binary mask to vector polygons\ngeoms = list(shapes(mask, transform=src.transform, connectivity=4))  # Specify connectivity=4 for 4-connected pixels\n\n# Filter the polygons to include only those corresponding to pixels with a value of 1\nfiltered_geoms = [geom for geom, value in geoms if value == 1]\n\n# Create a GeoDataFrame from the filtered polygons\ngdf = gpd.GeoDataFrame({'geometry': [shape(geom) for geom in filtered_geoms]})\n\n# Merge all the geometries into a single MultiPolygon\nmulti_polygon = gdf.unary_union\n\n# Create a GeoDataFrame with the MultiPolygon geometry\nmulti_polygon_gdf = gpd.GeoDataFrame(geometry=[multi_polygon], crs=gdf.crs)\n\n# Specify the path to save the MultiPolygon GeoJSON file\noutput_geojson_file = f\"./{folder_name}/multi_polygon_{current_date}.geojson\"\n\n# Save the GeoDataFrame with the MultiPolygon to a GeoJSON file\nmulti_polygon_gdf.to_file(output_geojson_file, driver='GeoJSON')\n\n","type":"content","url":"/notebooks/fire-impact-analysis#id-3-convert-the-binary-raster-mask-into-a-geojson-file","position":35},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Plot the GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#plot-the-geojson-file","position":36},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Plot the GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"\n\ndisplay(GeoJSON(data=f\"./{folder_name}/multi_polygon_{current_date}.geojson\", crs=bbox_epsg))\n\nWe can see that now only the built-up areas are stored in the GeoJSON file and we can extract the coordinates from this and use them as an input for the Sentinel-5p data\n\n","type":"content","url":"/notebooks/fire-impact-analysis#plot-the-geojson-file","position":37},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Extract the coordinates of the created GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#extract-the-coordinates-of-the-created-geojson-file","position":38},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Extract the coordinates of the created GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"\n\nwith open(f\"./{folder_name}/multi_polygon_{current_date}.geojson\") as f:\n    gj = geojson.load(f)\ndata_coordinates = gj['features'][0]['geometry']['coordinates']\n\n#print(data_coordinates)\n\n","type":"content","url":"/notebooks/fire-impact-analysis#extract-the-coordinates-of-the-created-geojson-file","position":39},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"4. Use Statistical API request to access Sentinel-5p CO data for the extracted populated areas"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#id-4-use-statistical-api-request-to-access-sentinel-5p-co-data-for-the-extracted-populated-areas","position":40},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"4. Use Statistical API request to access Sentinel-5p CO data for the extracted populated areas"},"content":"\n\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\n\n# Create a session\nclient = BackendApplicationClient(client_id=client_id)\noauth = OAuth2Session(client=client)\n\n# Get token for the session\ntoken = oauth.fetch_token(token_url='https://services.sentinel-hub.com/oauth/token',\n                          client_secret=client_secret)\n\n# All requests using this session will have an access token automatically added\nresp = oauth.get(\"https://services.sentinel-hub.com/oauth/tokeninfo\")\n\nurl = \"https://creodias.sentinel-hub.com/api/v1/statistics\"\nheaders = {\n  \"Accept\": \"application/json\",\n  \"Content-Type\": \"application/json\"\n}\ndata = {\n  \"input\": {\n    \"bounds\": {\n      \"geometry\": {\n        \"type\": \"MultiPolygon\",\n        \"coordinates\": data_coordinates\n                 }\n              },\n    \"data\": [\n      {\n        \"dataFilter\": {},\n        \"type\": \"sentinel-5p-l2\"\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n      \"from\": \"2022-07-01T00:00:00Z\",\n      \"to\": \"2022-08-09T23:59:59Z\"\n    },\n    \"aggregationInterval\": {\n      \"of\": \"P1D\"\n    },\n    \"width\": 512,\n    \"height\": 402.581,\n    \"evalscript\": \"//VERSION=3\\nfunction setup() {\\n  return {\\n    input: [{\\n      bands: [\\\"CO\\\", \\\"dataMask\\\"], // this sets which bands to use\\n    }],\\n    output: [\\n      { id:\\\"default\\\", bands: 1, sampleType: \\\"FLOAT32\\\" },\\n      { id: \\\"dataMask\\\", bands: 1 }\\n    ]\\n  };\\n}\\n \\n\\n\\nfunction evaluatePixel(sample) {\\n  return {\\n    default: [sample.CO],\\n    dataMask: [sample.dataMask]\\n  };\\n}\"\n  },\n  \"calculations\": {\n    \"default\": {}\n  }\n}\n\nresponse = oauth.post(url, headers=headers, json=data)\n\n","type":"content","url":"/notebooks/fire-impact-analysis#id-4-use-statistical-api-request-to-access-sentinel-5p-co-data-for-the-extracted-populated-areas","position":41},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Save the extracted statistics","lvl2":"4. Use Statistical API request to access Sentinel-5p CO data for the extracted populated areas"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#save-the-extracted-statistics","position":42},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Save the extracted statistics","lvl2":"4. Use Statistical API request to access Sentinel-5p CO data for the extracted populated areas"},"content":"\n\nresponse_data = response.json()\n#print(response_data)\n\n","type":"content","url":"/notebooks/fire-impact-analysis#save-the-extracted-statistics","position":43},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"5. Plot the statistics for the S5p CO data"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#id-5-plot-the-statistics-for-the-s5p-co-data","position":44},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"5. Plot the statistics for the S5p CO data"},"content":"\n\ntime_axis = [datetime.strptime(entry[\"interval\"][\"from\"], \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y/%m/%d\") for entry in response_data[\"data\"]]\nmeans = [float(entry['outputs']['default']['bands']['B0']['stats']['mean']) for entry in response_data[\"data\"]]\nstd_devs = [float(entry['outputs']['default']['bands']['B0']['stats']['stDev']) for entry in response_data[\"data\"]]\nstd_upper = [m+s for (m,s) in zip(means, std_devs)]\nstd_lower = [m-s for (m,s) in zip(means, std_devs)]\n\nfig = plt.figure(figsize=(20,10))\n# plot mean values \nplt.plot_date(time_axis, means, linestyle='solid', linewidth=2, color=\"black\", label=\"Mean CO values [mol/ m^2]\")\n\n# plot standard deviation error bars\nplt.errorbar(time_axis, means, yerr=std_devs, linestyle=\"-\")\n\nplt.title('CO Values over the AOI (07/2022 - 08/2022)')\nplt.legend()\nfig.autofmt_xdate()\nplt.show()\n\nThe graph illustrates a noticeable increase in CO concentration across populated areas on July 17th, when the fire event started. Additionally, the Standard Deviation on this day and the following days is increased in comparison to the days before the fire. The highest \n\ncarbon emissions in France were recorded from June to August in 2022 which aligns well with the result of this analysis. To learn more about the carbon emissions resulting from wildfires check out this \n\nstory on the EO Dashboard that also incorporates further indicators to analyse wildfires.","type":"content","url":"/notebooks/fire-impact-analysis#id-5-plot-the-statistics-for-the-s5p-co-data","position":45},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC"},"type":"lvl1","url":"/notebooks/inland-water-with-edc","position":0},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.03-02\", dependencies=[\"SH\"])\n\n\n\nauthor: Anca Anghelea, based on a \n\nnotebook by: William Ray\n\nSeveral lakes and other inland water bodies are featured on EO Dashboard. The datasets supporting the various geo-stories are accessible by means similar to what you will learn in this notebook.\n\nExplore EO Dashboard Stories on Oceans and Inland Water.","type":"content","url":"/notebooks/inland-water-with-edc","position":1},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"In this notebook"},"type":"lvl2","url":"/notebooks/inland-water-with-edc#in-this-notebook","position":2},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"In this notebook"},"content":"In this demonstration Jupyter Notebook, we will be visualising and analysing inland water bodies using Sentinel data, demonstrating the use of EDC.\n\nWe are going to use the EDC and its associated libaries and APIs to do this. In this notebook we will learn how to:\n\nBuild a cube\n\nVisualise a variable in your data cube\n\nCreate a new variable\n\nCreate a new variable using a threshold\n\nVisualise a spatial subset of a variable over time\n\nCreate a new variable based upon space and time.\n\n","type":"content","url":"/notebooks/inland-water-with-edc#in-this-notebook","position":3},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"Configuration"},"type":"lvl2","url":"/notebooks/inland-water-with-edc#configuration","position":4},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"Configuration"},"content":"Before acccessing the data, we will start by importing the necessary Python libraries (already configured in your EDC workspace), and generate credentials automatically to access the services.\n\n# EDC libraries\nfrom edc import setup_environment_variables\nfrom xcube_sh.config import CubeConfig\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.sentinelhub import SentinelHub\nfrom xcube.core.gen2.local.combiner import CubesCombiner\nfrom xcube.core.geom import mask_dataset_by_geometry\n\n# Sentinel Hub\nfrom sentinelhub import BBox, SentinelHubRequest, bbox_to_dimensions, DataCollection, MimeType, SHConfig, geometry\n\n# Utilities\nimport IPython.display\nfrom os import environ\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport geopandas\nimport rioxarray\n\n# Numerical computation\nimport xarray as xr\nimport numpy as np\n\n# Fetch credentials as environement variables\nsetup_environment_variables()\n\n# Pass Sentinel Hub credentials to dictionnary\nsh_credentials = dict(client_id=environ[\"SH_CLIENT_ID\"],\n                      client_secret=environ[\"SH_CLIENT_SECRET\"])\n\nDefine an AOI\n\nNext, we will define our area of interest using a bounding box. This must be provided in WGS84 coordinates to build the cube.\n\nWe have chosen an AOI covering the natural park “Valli di Comacchio” in Italy.\n\n# Define the coordinates of the bounding box\nlake_bbox = [12.09, 44.54, 12.27, 44.70]\n\n# Bbox EPSG\nbbox_epsg = 4326\n\n\n# Plot the bounding box on a map\nIPython.display.GeoJSON(BBox(lake_bbox,crs=bbox_epsg).get_geojson())\n\n","type":"content","url":"/notebooks/inland-water-with-edc#configuration","position":5},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"How to build a data cube","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#how-to-build-a-data-cube","position":6},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"How to build a data cube","lvl2":"Configuration"},"content":"Firstly, we will go through how to build a data cube.\n\nWe are going to visualise the floods using Sentinel-2 imagery. Sentinel-2 is part of the Copernicus programme and collects multispectral data globally with a revisit time of 5 days. The satellite’s multispectral imager provides collects data in 13 spectral bands spanning from the visible and near infrared to the shortwave infrared. The visible and near infrared data we will use in this example is collected at 10m resolution.\n\nCheck Sentinel-2 L2A available bands\n\nUsing EDC inbuilt functions that query Sentinel Hub services, we can easily list the available bands for a given dataset to help us build the cube!\n\n# Create a Sentinel Hub class, using our Sentinel Hub credentials\nSH = SentinelHub(**sh_credentials)\n\n# List bands for S2-L2A\nSH.band_names('S2L2A')\n\nBuild an xcube\n\nIn the following cell we will specify the input parameters needed to build an xcube array. The following parameters are specified:\n\ndataset_name: the Sentinel Hub identification of the dataset. Here we will call S2L2A for Sentinel-2 L2A. All available datasets can be listed with SH.dataset_names\n\nband_names: the band names to be used in the xcube array (see previous code cell). Here, we will call the B02, B03, B04, B08, CLM (Blue, Green, Red, NIR, Cloud Mask) bands.\n\nbbox: the bounding box that sets the extent of the AOI. Because we are using the default WGS84 coordinate system here, the CRS parameter doesn’t need to be set.\n\nspatial_res: the spatial resolution of the rasters contained in the xcube array. The spatial resolution is expressed in the units of the coordinate system used. Therefore, in this example, the spatial resolution is set in degrees. For an approximate pixel size of 10 meters, we set the resolution to 0.000089 degrees.\n\ntime_range: a list of two dates [start_date, end_date] forming a time period for which all acquisitions will be returned. Sentinel-2 L2A data is available from October 2016 onwards. In this example, we will fetch data for June 2023 - mid July 2023.\n\ntime_tolerance: The tolerance used to identify whether a dataset should still be included within a time period. Here, 30m corresponds to 30 minutes, thus avoiding duplicate datasets.\n\n# Setup xcube\ns2_cube_config = CubeConfig(dataset_name='S2L2A',\n                         band_names=['B02', 'B03', 'B04', 'B08', 'CLM'],\n                         bbox=lake_bbox,\n                         spatial_res=0.000089,\n                         time_range=['2023-06-01', '2023-07-16'],\n                         time_tolerance='30m')\n\nOpen the xcube\n\nIn the following cell we open the cube and display its contents. The automatically generated credentials obtained earlier in this Jupyter Notebook are specified as a parameter when opening the cube. It’s important to note that at this stage, we’re not processing anything, just generating a cube on the fly with data ready to be called when needed for analysis.\n\nOnce you open the cube, you can visualise the contents. You can view the number of timestamps and a list of them all too in the Coordinates tab. You can also visualise the seperate variables, with information on the size of the variables and their data type too.\n\n# Open cube (on the fly)\ns2_cube = open_cube(s2_cube_config, **sh_credentials)\n\n# Display contents\ns2_cube\n\n","type":"content","url":"/notebooks/inland-water-with-edc#how-to-build-a-data-cube","position":7},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"How to visualise your datacube","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#how-to-visualise-your-datacube","position":8},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"How to visualise your datacube","lvl2":"Configuration"},"content":"Now we have built our cube, let’s visualise the data! We are going to visualise a True Color image and an NDWI image in the same plot. In the below cell you can see we are selecting each band for 10:00:00 16th June 2023, and selecting the nearest acquisition to this date and time. We then stack the three bands and plot this using Matplotlib. We will call the three bands in the visible spectrum. In addition we will multiply the reflectance values by 5 to brighten the image.\n\nAnother way to visualise the extent of surface water is to use the Normalised Difference Water Index (NDWI). This is an index that can be used to extract surface water using multispectral imagery such as Sentinel-2. We can calculate the index with the Green and NIR bands as stated below, and add it into the data cube as a new variable.\n\nNDWI = Green - NIR / Green + NIR\n\nFor this we are going to create a new variable in the next cell. To create the new variable we are using two existing variables defined as s2_cube.B03 and s2_cube.B08. We then insert these variables into an index formula to create NDWI. Once ndwi has been calculated it’s attributed a long_name and units before being defined as ndwi so that we can call it as a definition later in the notebook.\n\n# Define NDWI in visualisation\nndwi = ((s2_cube.B03-s2_cube.B08)/(s2_cube.B03+s2_cube.B08))\n\nndwi.attrs['long_name']='NDWI'\nndwi.attrs['units']='unitless'\n\ns2_cube['NDWI']= ndwi  \n\nNext we want to plot both the True Color image and the NDWI in the same plot. We will use Matplotlib to achieve this.\n\n# Select the bands and stack them.\nRed = s2_cube.B04.sel(time='2023-06-17 10:00:00', method='nearest')\nGreen = s2_cube.B03.sel(time='2023-06-17 10:00:00', method='nearest')\nBlue = s2_cube.B02.sel(time='2023-06-17 10:00:00', method='nearest')\n\nrgb = np.dstack((Red,Green,Blue)) #Stack the three arrays\n\nndwi = s2_cube.NDWI.sel(time='2023-06-17 10:00:00', method='nearest')\n\n# Plot \nf = plt.figure(figsize=[10, 15])\nf.add_subplot(1, 2, 1)\nplt.title(f\"True Color: {str(s2_cube.time.sel(time='2023-06-17 10:00:00', method='nearest').data).split('T')[0]}\")\nplt.imshow(5 * rgb)  # We multiply the rgb by 5 to make the image brighter\nf.add_subplot(1, 2, 2)\nplt.title(f\"NDWI: {str(s2_cube.time.sel(time='2023-06-17 10:00:00', method='nearest').data).split('T')[0]}\")\nplt.imshow(ndwi, vmin=-1, vmax=1, cmap='GnBu')\nplt.show()\n\nThis looks good, and the extent of the flood waters is visualised really nicely here. The 10m resolution also enables us to see individual fields around the lake with the linear boundaries of the fields highlighted nicely in the high resolution image provided by the 10m Sentinel 2 bands.\n\nLet’s try and visualise some more dates in the time period that we are examining;\n\n# Select timestamps\nndwi1 = s2_cube.NDWI.sel(time='2023-06-17 10:00:00', method='nearest')\nndwi2 = s2_cube.NDWI.sel(time='2023-06-24 10:00:00', method='nearest')\nndwi3 = s2_cube.NDWI.sel(time='2023-06-29 10:00:00', method='nearest')\nndwi4 = s2_cube.NDWI.sel(time='2023-07-04 10:00:00', method='nearest')\nndwi5 = s2_cube.NDWI.sel(time='2023-07-07 10:00:00', method='nearest')\nndwi6 = s2_cube.NDWI.sel(time='2023-07-09 10:00:00', method='nearest')\n\n\n# Plot \nf = plt.figure(figsize=[15,11])\nax1 = f.add_subplot(2,3, 1)\nax2 = f.add_subplot(2,3, 2)\nax3 = f.add_subplot(2,3, 3)\nax4 = f.add_subplot(2,3, 4)\nax5 = f.add_subplot(2,3, 5)\nax6 = f.add_subplot(2,3, 6)\n\naxlist=[ax1,ax2,ax3,ax4,ax5,ax6]\n\nt = ndwi1.plot.imshow(ax=ax1, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi2.plot.imshow(ax=ax2, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi3.plot.imshow(ax=ax3, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi4.plot.imshow(ax=ax4, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi5.plot.imshow(ax=ax5, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi6.plot.imshow(ax=ax6, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\n\ncbar_ax = f.add_axes([1, 0.15, 0.05, 0.7])\nf.colorbar(t, cax=cbar_ax, label=\"NDWI\")\n\n#we will save the output image so we need to ensure that it is fully rendered \nplt.tight_layout() \n\n# Save the figure to a PNG file\nplt.savefig('NDWI.png')\n\nplt.show()\n\nWe could use the NDWI to estimate the surface water extent. The more images we have available, the more reliable the estimate can be. Examining the satellite images above we observe that not all of the images would be useful, as some of the lake area is covered with clouds. To overcome this limitation and have a denser time series we could rely on synthetic aperture radar observations, for example from the Copernicus Sentinel-1 platform.\n\n","type":"content","url":"/notebooks/inland-water-with-edc#how-to-visualise-your-datacube","position":9},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Sentinel-1 description","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#sentinel-1-description","position":10},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Sentinel-1 description","lvl2":"Configuration"},"content":"Like Sentinel-2, Sentinel-1 is also part of the Copernicus programme and collects data globally with a revisit time of 5 days. In contrast to Sentinel-2, Sentinel-1 SAR is an active sensor using SAR signals recording the backscatter. Due to the wavelengths used, SAR is not hindered by clouds and can be operated day and night.\n\n","type":"content","url":"/notebooks/inland-water-with-edc#sentinel-1-description","position":11},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Check Sentinel-1 GRD available bands","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#check-sentinel-1-grd-available-bands","position":12},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Check Sentinel-1 GRD available bands","lvl2":"Configuration"},"content":"Using EDC inbuilt functions that query Sentinel Hub services, we can easily list the available bands for a given dataset.\n\n# List bands for S1-GRD\nSH.band_names('S1GRD')\n\n","type":"content","url":"/notebooks/inland-water-with-edc#check-sentinel-1-grd-available-bands","position":13},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Build an xcube","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#build-an-xcube","position":14},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Build an xcube","lvl2":"Configuration"},"content":"In the following cell we will specify the input parameters needed to build an xcube array. The following parameters are specified:\n\ndataset_name: the Sentinel Hub identification of the dataset. Here we will call S1GRD for Sentinel-1 GRD. All available datasets can be listed with SH.dataset_names\n\nband_names: the band names to be used in the xcube array (see previous code cell). Here, we will call just the VV polarisation band.\n\nbbox: the bounding box that sets the extent of the AOI. Because we are using the default WGS84 coordinate system here, the CRS parameter doesn’t need to be set.\n\nspatial_res: the spatial resolution of the rasters contained in the xcube array. The spatial resolution is expressed in the units of the coordinate system used. Therefore, in this example, the spatial resolution is set in degrees. For an approximate pixel size of 10 meters, we set the resolution to 0.000089 degrees.\n\ntime_range: a list of two dates [start_date, end_date] forming a time period for which all acquisitions will be returned. Sentinel-1 GRD data is available from February 2015 onwards. In this example, we will fetch data for June 2023 - mid July 2023.\n\ntime_tolerance: The tolerance used to identify whether a dataset should still be included within a time period. Here, 30m corresponds to 30 minutes, thus avoiding duplicate datasets.\n\n# Setup xcube\ns1_cube_config = CubeConfig(dataset_name='S1GRD',\n                         band_names=['VV'],\n                         bbox=lake_bbox,\n                         spatial_res=0.000089,\n                         time_range=['2023-06-01', '2023-07-16'],\n                         time_tolerance='30m')\n\n","type":"content","url":"/notebooks/inland-water-with-edc#build-an-xcube","position":15},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Open the xcube","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#open-the-xcube","position":16},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Open the xcube","lvl2":"Configuration"},"content":"In the following cell we open the cube and display its contents. The automatically generated credentials obtained earlier in this Jupyter Notebook are specified as a parameter when opening the cube.\n\n# Open cube (on the fly)\ns1_cube = open_cube(s1_cube_config, **sh_credentials)\n\n# Display contents\ns1_cube\n\n","type":"content","url":"/notebooks/inland-water-with-edc#open-the-xcube","position":17},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Visualising the water areas using SAR","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#visualising-the-water-areas-using-sar","position":18},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Visualising the water areas using SAR","lvl2":"Configuration"},"content":"We are going to use the VV band to visualise the flooding. From our earlier visualisation, we know that the area had some cloud coverage around the date 2023-07-04. We will search for Sentinel-1 acquisitions around that date in order to obtain a denser time series.\n\nRadar data has very large dynamic range a very imbalanced histogram (>95% of all values are smaller than 1, but the remaining 5 % can be impractically large). Thus, to obtain a visualisation with a better contrast in which the water bodies would be darker and the land pixels would be brighter, it is recommended to convert the data to log-scale.\nTo convert the pixel values from Digital Number to decibels we can mutiply the log10 of each DN pixel by 10. Secondly, as there will be pixels with a value of -inf after this operation, we need to account for this with the second function which will automatically assign 0 to these pixels.\n\n# Convert VV Digital numbers to Decibels\nvv_dn = s1_cube.VV\nvv_db = 10 * (np.log10(vv_dn))\n\nvv_db = vv_db.where(np.isfinite(vv_db), 0)\n\nvv_db.attrs['long_name']='VV_dB'\nvv_db.attrs['units']='decibels'\n\ns1_cube['VV_dB']= vv_db\n\nLike previously, we are going to visualise the VV_dB variable we have just generated for our AOI.\n\n# select and define the timestamp you want to visualise \nVV_dB_timestamp = s1_cube.VV_dB.sel(time='2023-07-09 10:00:00', method='nearest')\n\n# plot the timestamp\nVV_dB_timestamp.plot.imshow(vmin=-40, vmax=0, cmap='winter', figsize=(10, 10))\n\n# save and display the plot\nplt.show()\n\nThis looks very similar to the NDWI we derived earlier showing the water extent fairly clearly (the blue areas). Let’s visualise it over several timestamps to confirm that this is a good variable to use to generate a lake mask.\n\n#### Timestamp selection\nvv1 = s1_cube.VV_dB.sel(time='2023-06-03 10:00:00', method='nearest')\nvv2 = s1_cube.VV_dB.sel(time='2023-06-04 10:00:00', method='nearest')\nvv3 = s1_cube.VV_dB.sel(time='2023-06-15 10:00:00', method='nearest')\nvv4 = s1_cube.VV_dB.sel(time='2023-06-27 10:00:00', method='nearest')\nvv5 = s1_cube.VV_dB.sel(time='2023-07-09 10:00:00', method='nearest')\nvv6 = s1_cube.VV_dB.sel(time='2023-07-10 10:00:00', method='nearest')\n\n# Plot \nf = plt.figure(figsize=[16,11])\nax1 = f.add_subplot(2,3, 1)\nax2 = f.add_subplot(2,3, 2)\nax3 = f.add_subplot(2,3, 3)\nax4 = f.add_subplot(2,3, 4)\nax5 = f.add_subplot(2,3, 5)\nax6 = f.add_subplot(2,3, 6)\n\naxlist=[ax1,ax2,ax3,ax4,ax5,ax6]\n\nt = vv1.plot.imshow(ax=ax1, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv2.plot.imshow(ax=ax2, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv3.plot.imshow(ax=ax3, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv4.plot.imshow(ax=ax4, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv5.plot.imshow(ax=ax5, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv6.plot.imshow(ax=ax6, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\n\ncbar_ax = f.add_axes([1, 0.15, 0.05, 0.7])\nf.colorbar(t, cax=cbar_ax, label=\"VV dB\")\n\nplt.show()\n\nDepending on the local conditions (e.g. terrain orientation, slope) and weather conditions, optical or radar imagery may be more useful. In this case both types of observations seem to provide a good view of the water surface area extent.\n\nNext we will generate a flood mask using a threshold.\n\nfor SAR images, generally, as a good rule of thumb, in the VV band, values below -20 dB are usually surface water. We will try this value first, but we will also look to visualise how the flood mask changes if we adjust the threshold value.\n\nobserving the NDWI range of values, we can chose values above 0.25 to correspond to the water class.\n\nFirst, let’s generate the new variable using the .where function in xarray.\n\nAt first glance, the below cell may not make much sense. It may read that the step 1 function as assigning a value of 1 to pixels in VV_dB that are equal or more than -20. However, what is actually happening is that the .where function preserves all the pixel values in the variable that are below -20 and assigns everything else a value of 1. More can be found in the xarray documentation \n\nhttp://​xarray​.pydata​.org​/en​/stable​/generated​/xarray​.DataArray​.where​.html\n\n# mask the Sentinel-1 data\n\n# Assign all pixels equal or smaller than -20 a value of 1 and preserve the values of all other pixels \nstep1 = s1_cube.VV_dB.where(s1_cube.VV_dB > -20, 1)\n\n# Assign all other pixels a value of 0. \nwater = step1.where(step1 == 1, 0)\n\nwater.attrs['long_name'] ='water'\nwater.attrs['units'] ='nounits'\n\ns1_cube['water'] = water\n\nNext let’s see what happens to the mask extent if we change the threshold to -15 dB and -25dB:\n\n# Sentinel-1\nwater_threshold1_step1 = s1_cube.VV_dB.where(s1_cube.VV_dB > -15, 1)\nwater_threshold2_step1 = s1_cube.VV_dB.where(s1_cube.VV_dB > -20, 1)\nwater_threshold3_step1 = s1_cube.VV_dB.where(s1_cube.VV_dB > -25, 1)\n\nwater_threshold1_step2 = water_threshold1_step1.where(water_threshold1_step1 == 1, 0)\nwater_threshold2_step2 = water_threshold2_step1.where(water_threshold2_step1 == 1, 0)\nwater_threshold3_step2 = water_threshold3_step1.where(water_threshold3_step1 == 1, 0)\n\nwater_threshold1 = water_threshold1_step2.sel(time='2023-06-15 10:00:00', method='nearest')\nwater_threshold2 = water_threshold2_step2.sel(time='2023-06-15 10:00:00', method='nearest')\nwater_threshold3 = water_threshold3_step2.sel(time='2023-06-15 10:00:00', method='nearest')\n\nNext we will plot the new thresholds we want to test:\n\n# Plot \nf = plt.figure(figsize=[20,12])\nax1 = f.add_subplot(2,3, 1)\nax2 = f.add_subplot(2,3, 2)\nax3 = f.add_subplot(2,3, 3)\n\nwater_threshold1.plot.imshow(ax=ax1, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nwater_threshold2.plot.imshow(ax=ax2, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nwater_threshold3.plot.imshow(ax=ax3, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\n\nplt.show()\n\n# mask the Sentinel-2 data\n\n# Assign all pixels equal or larger than 0.25 a value of 1 and preserve the values of pixels \nstep11 = ndwi1.where(ndwi1 < 0.25, 1)\n\n# Assign all other pixels a value of 0. \nwater1 = step1.where(step1 == 1, 0)\n\nwater1.attrs['long_name'] ='water'\nwater1.attrs['units'] ='nounits'\n\ns2_cube['water'] = water1\n\n# Sentinel-2\nwater_threshold1_step11 = ndwi1.where(ndwi1 < 0.15, 1)\nwater_threshold2_step11 = ndwi1.where(ndwi1 < 0.25, 1)\nwater_threshold3_step11 = ndwi1.where(ndwi1 < 0.30, 1)\n\nwater_threshold1_step21 = water_threshold1_step11.where(water_threshold1_step11 == 1, 0)\nwater_threshold2_step21 = water_threshold2_step11.where(water_threshold2_step11 == 1, 0)\nwater_threshold3_step21 = water_threshold3_step11.where(water_threshold3_step11 == 1, 0)\n\nwater_threshold11 = water_threshold1_step21\nwater_threshold21 = water_threshold2_step21\nwater_threshold31 = water_threshold3_step21\n\n# Plot \nf = plt.figure(figsize=[20,12])\nax1 = f.add_subplot(2,3, 1)\nax2 = f.add_subplot(2,3, 2)\nax3 = f.add_subplot(2,3, 3)\n\nwater_threshold11.plot.imshow(ax=ax1, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nwater_threshold21.plot.imshow(ax=ax2, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nwater_threshold31.plot.imshow(ax=ax3, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\n\nplt.show()\n\nObserve the differences in the water mask due to the threshold.\n\n","type":"content","url":"/notebooks/inland-water-with-edc#visualising-the-water-areas-using-sar","position":19},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Estimating the surface water area extent","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#estimating-the-surface-water-area-extent","position":20},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Estimating the surface water area extent","lvl2":"Configuration"},"content":"Let’s estimate the area covered by water during the time period we are examining.\n\nWe can also estimate which is the area that is most covered by water by dividing the sum of the water pixels by the number of timesteps in the data cube (the count).\n\n# previously we only kept 1 time step when we selected ndwi1\n# now we want to keep the full datacube in order to average in time\n\n# Assign all pixels equal or larger than 0.25 a value of 1 and preserve the values of all other pixels \nstep1 = s2_cube.NDWI.where(s2_cube.NDWI < 0.25, 1)\n\n# Assign all other pixels a value of 0. \nwater = step1.where(step1 == 1, 0)\n\nwater.attrs['long_name'] ='water'\nwater.attrs['units'] ='nounits'\n\ns2_cube['water'] = water\n\n\nwater_sum = s2_cube.NDWI.sum(dim=\"time\")\nwater_count = s2_cube.NDWI.count(dim=\"time\")\nwater_average = water_sum / water_count\n\n\nwater_average.attrs['long_name']='water area'\nwater_average.attrs['units']='nounits'\n\nndwi['water_average']= water_average\n\nNow let’s plot the water_average into a plot:\n\nwater_average.plot.imshow(cmap='GnBu', vmin=0, vmax=0.5, figsize=(10, 10))\n\nplt.tight_layout()\n\n#expport to png\nplt.savefig('figure.png')\n\nplt.show()\n\nThis looks great, we have identified the lake area very clearly here and can also observe how the lake may change in size over time.\n\n","type":"content","url":"/notebooks/inland-water-with-edc#estimating-the-surface-water-area-extent","position":21},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"Access environmental variables and other datasets"},"type":"lvl2","url":"/notebooks/inland-water-with-edc#access-environmental-variables-and-other-datasets","position":22},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"Access environmental variables and other datasets"},"content":"This \n\nNotebook demonstrates how to:\n\nrequest data from selected Copernicus Services,\nrequest data from Copernicus Climate Data Store,\nrequest data from ESA Climate Change Initiative.","type":"content","url":"/notebooks/inland-water-with-edc#access-environmental-variables-and-other-datasets","position":23},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel"},"type":"lvl1","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel","position":0},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel"},"content":"\n\nThis concise notebook demonstrates guidelines for submission of your projects developed under the Earth System Science Open Challenge! Please use this notebook as a template for delivering your workflow with the code you used to produce the results! For more information, refer to Open Challenge website: \n\nhttps://​eo4society​.esa​.int​/event​/sciencehubchallengefeb2024/\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel","position":1},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"1. Title "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-1-title","position":2},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"1. Title "},"content":"Author(s): Lucas Jessel, Sabrine Hezzi, Marie-Laure Roussel  \nGroup name: Extreme precip  \nChallenge: 1 - “Cevenols episodes” or rainfall extreme events in the South-East of France \n\nSubmission date: 01/03/2024 \n\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-1-title","position":3},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"2. Description "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-2-description","position":4},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"2. Description "},"content":"","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-2-description","position":5},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"Description of research approach","lvl2":"2. Description "},"type":"lvl4","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#description-of-research-approach","position":6},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"Description of research approach","lvl2":"2. Description "},"content":"Mediterranean events of intense rainfall can happen in late summer or in fall in the south-east of France (Cevennes, Rhone valley, Roussillon, Provence) due to warm and humid air coming from the heated sea, thanks to south-east flux mainly driven by any disturbance on France. It causes thunderstorms and heavy precipitation because of the cold air in altitude (that is explained in this region because of the topography : Massif Central, Alpes, Pyrenees). Flooding, runoff and landslides are the most important consequences of these events, due to blocked rainfall in the area.\n\nMonitoring this kind of extreme event is a massive challenge for weather forecasts models, that is why observations from space are a really great tool to help in that way.\n\nIn this study, the objective is to use observations products from space to try to detect massive rainfall events and evaluate the accuracy of the results in terms of caracteristics of the precipitation event (daily maximum value and location).\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#description-of-research-approach","position":7},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"3. Table of Contents "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-3-table-of-contents","position":8},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"3. Table of Contents "},"content":"Title\n\nDescription\n\nTable of Contents\n\nReferences\n\nKey Conclusions\n\nSocietal Context\n\nImport libraries\n\nAccess dataset\n\nAnalysis cells\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-3-table-of-contents","position":9},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"4. References "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-4-references","position":10},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"4. References "},"content":"Brocca et al. 2014. Soil as a natural rain gauge: Estimating global rainfall from satellite soil moisture data, \n\nBrocca et al. (2014).\n\nHuffman et al. 2001. Global Precipitation at One-Degree Daily Resolution from Multisatellite Observations, \n\nhttps://​doi​.org​/10​.1175​/1525​-7541(2001)002<0036:GPAODD>\n\n2.0.CO;2\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-4-references","position":11},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"5. Key Conclusions "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-5-key-conclusions","position":12},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"5. Key Conclusions "},"content":"Among the two observational datasets compared to ERA5 reanalyses, which we have taken as a reference, it emerges as a conclusion that the GPM-CPC product provides a more accurate and faithful representation of an extreme Cevenol precipitation event, such as the one studied, both for the location and the value of the maximum of precipitation.\n\nOn the contrary, the GPCP product appears to produce too little precipitation for a Mediterranean episode day and fails to reproduce the maximum precipitation at the correct location.\n\nA more in-depth analysis could be considered to account for differences in spatial resolution between the datasets, as well as to study different days over a longer period of time.\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-5-key-conclusions","position":13},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"6. Societal Context "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-6-societal-context","position":14},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"6. Societal Context "},"content":"Mediterranean episodes can be dangerous for the population due to their significant and difficult-to-predict consequences such as floods and landslides. Numerous damages need to be considered during these sometimes dramatic events.\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-6-societal-context","position":15},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"PART 2: SCIENTIFIC EXPLOITATION AND ANALYSIS"},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#part-2-scientific-exploitation-and-analysis","position":16},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"PART 2: SCIENTIFIC EXPLOITATION AND ANALYSIS"},"content":"\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#part-2-scientific-exploitation-and-analysis","position":17},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"7. Import Libraries "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-7-import-libraries","position":18},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"7. Import Libraries "},"content":"This notebook runs with the python environment deepesdl-xcube-1.1.2, please checkout the documentation for \n\nhelp on changing the environment.\n\nimport xcube\nfrom xcube.core.store import find_data_store_extensions\nfrom xcube.core.store import get_data_store_params_schema\nfrom xcube.core.store import new_data_store\n\nimport boto3\nfrom botocore.exceptions import NoCredentialsError\n\nimport os\nimport shapely.geometry\nfrom IPython.display import JSON\nimport numpy as np\nimport xarray as xr\n\n# for the plots\nfrom cartopy import crs as ccrs, feature as cfeature\nprojPC = ccrs.PlateCarree(central_longitude=0)\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nimport matplotlib.ticker as ticker\n%matplotlib inline\nplt.rcParams[\"figure.figsize\"] = 16,8\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-7-import-libraries","position":19},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"8. Data sources "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-8-data-sources","position":20},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"8. Data sources "},"content":"\n\nDatacube name\n\nVariable name\n\nDescription\n\nReference*\n\nRegion\n\nTime range\n\nResolution\n\n(GPM-CPC) hydrology-1D-0.009deg-100x60x60-3.0.2.zarr\n\nprecip\n\nmetadata description\n\nlink to source\n\nsouth-east of France (40-45°N, 0-10°E)\n\ndaily\n\n0.01°\n\n(GPCP) cube_GPCP_complete_nomissingvalue_lat_1996-2022.zarr\n\nprecip\n\nmetadata description\n\nlink to source\n\nsouth-east of France (40-45°N, 0-10°E)\n\ndaily\n\n1°\n\n(ERA5) cube_tpsum.2015-2022.fs1e5.GLOBAL_025.zarr\n\ntp\n\nmetadata description\n\nlink to source\n\nsouth-east of France (40-45°N, 0-10°E)\n\ndaily\n\n0.25°\n\n# CODE SECTION\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-8-data-sources","position":21},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"Setting stores variables","lvl2":"8. Data sources "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#setting-stores-variables","position":22},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"Setting stores variables","lvl2":"8. Data sources "},"content":"\n\n# PUBLIC STORE : for GPM-CPC dataset in the hydrology cube\npublic_store = new_data_store(\"s3\", root=\"deep-esdl-public\", storage_options=dict(anon=True))\n\n# USER/TEAM STORE : for GPCP and ERA5 datasets in the \"homemade\" cubes\nS3_USER_STORAGE_KEY = os.environ[\"S3_USER_STORAGE_KEY\"]\nS3_USER_STORAGE_SECRET = os.environ[\"S3_USER_STORAGE_SECRET\"]\nS3_USER_STORAGE_BUCKET = os.environ[\"endpoint\"]\nuser_store = new_data_store(\"s3\", max_depth=3, root=S3_USER_STORAGE_BUCKET,storage_options=dict(anon=False, key=S3_USER_STORAGE_KEY,secret=S3_USER_STORAGE_SECRET))\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#setting-stores-variables","position":23},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"Extracting GPM-CPC SM2RAIN ASCAT Dataset (from hydrology cube)","lvl2":"8. Data sources "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#extracting-gpm-cpc-sm2rain-ascat-dataset-from-hydrology-cube","position":24},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"Extracting GPM-CPC SM2RAIN ASCAT Dataset (from hydrology cube)","lvl2":"8. Data sources "},"content":"\n\nhydro_cube = public_store.open_data('hydrology-1D-0.009deg-100x60x60-3.0.2.zarr')\nprecip_data_hydro=hydro_cube['precip']\nprecip_data_hydro\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#extracting-gpm-cpc-sm2rain-ascat-dataset-from-hydrology-cube","position":25},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"Extracting GPCP Dataset","lvl2":"8. Data sources "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#extracting-gpcp-dataset","position":26},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"Extracting GPCP Dataset","lvl2":"8. Data sources "},"content":"\n\ngpcp_cube = user_store.open_data('cube_GPCP_complete_nomissingvalue_lat_1996-2022.zarr')\nprecip_data_gpcp = gpcp_cube['precip']\nprecip_data_gpcp\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#extracting-gpcp-dataset","position":27},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"Extracting ERA5 Dataset","lvl2":"8. Data sources "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#extracting-era5-dataset","position":28},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"Extracting ERA5 Dataset","lvl2":"8. Data sources "},"content":"\n\nera_cube = user_store.open_data('cube_tpsum.2015-2022.fs1e5.GLOBAL_025.zarr')\nprecip_data_era = era_cube['tp']*3600. # convert mm/s to mm/d \nprecip_data_era\n\n\n\n\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#extracting-era5-dataset","position":29},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"9. Analysis cells "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-analysis-cells","position":30},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"9. Analysis cells "},"content":"\n\n# defining some coordinates inside the region of interest\n\nlat1=45 ; lon1=5\nlat2=45 ; lon2=7\nlat3=43 ; lon3=3\nlat4=44 ; lon4=7\nlat5=44 ; lon5=4\nlat6=44 ; lon6=5\nlat7=44 ; lon7=6\nlat8=44 ; lon8=3\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-analysis-cells","position":31},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.1) Plots of the long-term time-series","lvl2":"9. Analysis cells "},"type":"lvl4","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-1-plots-of-the-long-term-time-series","position":32},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.1) Plots of the long-term time-series","lvl2":"9. Analysis cells "},"content":"\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-1-plots-of-the-long-term-time-series","position":33},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.1.1) From the hydrology cube :","lvl4":"9.1) Plots of the long-term time-series","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-1-1-from-the-hydrology-cube","position":34},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.1.1) From the hydrology cube :","lvl4":"9.1) Plots of the long-term time-series","lvl2":"9. Analysis cells "},"content":"\n\n# selecting local precipitation data\n\nprecip_point1 = precip_data_hydro.sel(lat=lat1, lon=lon1, method='nearest')\nprecip_point2 = precip_data_hydro.sel(lat=lat2, lon=lon2, method='nearest')\nprecip_point3 = precip_data_hydro.sel(lat=lat3, lon=lon3, method='nearest')\nprecip_point4 = precip_data_hydro.sel(lat=lat4, lon=lon4, method='nearest')\nprecip_point5 = precip_data_hydro.sel(lat=lat5, lon=lon5, method='nearest')\nprecip_point6 = precip_data_hydro.sel(lat=lat6, lon=lon6, method='nearest')\nprecip_point7 = precip_data_hydro.sel(lat=lat7, lon=lon7, method='nearest')\nprecip_point8 = precip_data_hydro.sel(lat=lat8, lon=lon8, method='nearest')\n\nplt.figure(figsize=(20, 6))\nprecip_point1.plot(marker='o', linestyle='-',color='blue')\nprecip_point2.plot(marker='o', linestyle='-',color='red')\nprecip_point3.plot(marker='o', linestyle='-',color='green')\nprecip_point4.plot(marker='o', linestyle='-',color='yellow')\nprecip_point5.plot(marker='o', linestyle='-',color='purple')\nprecip_point6.plot(marker='o', linestyle='-',color='cyan')\nprecip_point7.plot(marker='o', linestyle='-',color='magenta')\nprecip_point8.plot(marker='o', linestyle='-',color='orange')\nplt.xlabel('Day')\nplt.ylabel('Daily rainfall (mm/d)')\nplt.title('Precipitation from GPM-CPC SM2RAIN-ASCAT (hydrology cube)')\nplt.grid(True)\nplt.show()\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-1-1-from-the-hydrology-cube","position":35},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.1.2) From the GPCP cube :","lvl4":"9.1) Plots of the long-term time-series","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-1-2-from-the-gpcp-cube","position":36},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.1.2) From the GPCP cube :","lvl4":"9.1) Plots of the long-term time-series","lvl2":"9. Analysis cells "},"content":"\n\n# selecting local precipitation data\nprecip_point1 = precip_data_gpcp.sel(latitude=lat1, longitude=lon1, method='nearest')\nprecip_point2 = precip_data_gpcp.sel(latitude=lat2, longitude=lon2, method='nearest')\nprecip_point3 = precip_data_gpcp.sel(latitude=lat3, longitude=lon3, method='nearest')\nprecip_point4 = precip_data_gpcp.sel(latitude=lat4, longitude=lon4, method='nearest')\nprecip_point5 = precip_data_gpcp.sel(latitude=lat5, longitude=lon5, method='nearest')\nprecip_point6 = precip_data_gpcp.sel(latitude=lat6, longitude=lon6, method='nearest')\nprecip_point7 = precip_data_gpcp.sel(latitude=lat7, longitude=lon7, method='nearest')\nprecip_point8 = precip_data_gpcp.sel(latitude=lat8, longitude=lon8, method='nearest')\n\nplt.figure(figsize=(20, 6))\nprecip_point1.plot(marker='o', linestyle='-',color='blue')\nprecip_point2.plot(marker='o', linestyle='-',color='red')\nprecip_point3.plot(marker='o', linestyle='-',color='green')\nprecip_point4.plot(marker='o', linestyle='-',color='yellow')\nprecip_point5.plot(marker='o', linestyle='-',color='purple')\nprecip_point6.plot(marker='o', linestyle='-',color='cyan')\nprecip_point7.plot(marker='o', linestyle='-',color='magenta')\nprecip_point8.plot(marker='o', linestyle='-',color='orange')\n\nplt.xlabel('Day')\nplt.ylabel('Daily rainfall (mm/d)')\nplt.ylim(0,80)\nplt.title('Precipitation from GPCP')\nplt.grid(True)\nplt.show()\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-1-2-from-the-gpcp-cube","position":37},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.1.3) From the ERA5 cube :","lvl4":"9.1) Plots of the long-term time-series","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-1-3-from-the-era5-cube","position":38},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.1.3) From the ERA5 cube :","lvl4":"9.1) Plots of the long-term time-series","lvl2":"9. Analysis cells "},"content":"\n\n# selecting local precipitation data\n\nprecip_point1 = precip_data_era.sel(latitude=lat1, longitude=lon1, method='nearest')\nprecip_point2 = precip_data_era.sel(latitude=lat2, longitude=lon2, method='nearest')\nprecip_point3 = precip_data_era.sel(latitude=lat3, longitude=lon3, method='nearest')\nprecip_point4 = precip_data_era.sel(latitude=lat4, longitude=lon4, method='nearest')\nprecip_point5 = precip_data_era.sel(latitude=lat5, longitude=lon5, method='nearest')\nprecip_point6 = precip_data_era.sel(latitude=lat6, longitude=lon6, method='nearest')\nprecip_point7 = precip_data_era.sel(latitude=lat7, longitude=lon7, method='nearest')\nprecip_point8 = precip_data_era.sel(latitude=lat8, longitude=lon8, method='nearest')\n\nplt.figure(figsize=(20, 6))\nprecip_point1.plot(marker='o', linestyle='-',color='blue')\nprecip_point2.plot(marker='o', linestyle='-',color='red')\nprecip_point3.plot(marker='o', linestyle='-',color='green')\nprecip_point4.plot(marker='o', linestyle='-',color='yellow')\nprecip_point5.plot(marker='o', linestyle='-',color='purple')\nprecip_point6.plot(marker='o', linestyle='-',color='cyan')\nprecip_point7.plot(marker='o', linestyle='-',color='magenta')\nprecip_point8.plot(marker='o', linestyle='-',color='orange')\n\nplt.xlabel('Day')\nplt.ylabel('Daily rainfall (mm/d)')\nplt.title('Precipitation from ERA5')\nplt.grid(True)\nplt.show()\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-1-3-from-the-era5-cube","position":39},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.2) Filtering => minicube selection on the studied region","lvl2":"9. Analysis cells "},"type":"lvl4","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-2-filtering-minicube-selection-on-the-studied-region","position":40},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.2) Filtering => minicube selection on the studied region","lvl2":"9. Analysis cells "},"content":"\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-2-filtering-minicube-selection-on-the-studied-region","position":41},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.2.1) On the hydrology cube","lvl4":"9.2) Filtering => minicube selection on the studied region","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-2-1-on-the-hydrology-cube","position":42},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.2.1) On the hydrology cube","lvl4":"9.2) Filtering => minicube selection on the studied region","lvl2":"9. Analysis cells "},"content":"\n\nlatm=43; latM=45; lonm=2.5; lonM=8  \n\nhydro_region_precip = hydro_cube['precip'].sel(lat=slice(latM,latm), lon = slice(lonm,lonM))\nhydro_region_precip\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-2-1-on-the-hydrology-cube","position":43},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.2.2) On the GPCP cube","lvl4":"9.2) Filtering => minicube selection on the studied region","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-2-2-on-the-gpcp-cube","position":44},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.2.2) On the GPCP cube","lvl4":"9.2) Filtering => minicube selection on the studied region","lvl2":"9. Analysis cells "},"content":"\n\ngpcp_region_precip = gpcp_cube['precip'].sel(latitude=slice(latm,latM), longitude= slice(lonm,lonM))\ngpcp_region_precip\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-2-2-on-the-gpcp-cube","position":45},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.2.3) On the ERA5 cube","lvl4":"9.2) Filtering => minicube selection on the studied region","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-2-3-on-the-era5-cube","position":46},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.2.3) On the ERA5 cube","lvl4":"9.2) Filtering => minicube selection on the studied region","lvl2":"9. Analysis cells "},"content":"\n\nera_region_precip = era_cube['tp'].sel(latitude=slice(latM,latm), longitude= slice(lonm,lonM))\nera_region_precip \n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-2-3-on-the-era5-cube","position":47},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.3) Searching the maximum values at each grid point for the whole time-serie","lvl2":"9. Analysis cells "},"type":"lvl4","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-3-searching-the-maximum-values-at-each-grid-point-for-the-whole-time-serie","position":48},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.3) Searching the maximum values at each grid point for the whole time-serie","lvl2":"9. Analysis cells "},"content":"\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-3-searching-the-maximum-values-at-each-grid-point-for-the-whole-time-serie","position":49},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.3.1) compute the maximum values on the region during the whole time-serie for each grid cell","lvl4":"9.3) Searching the maximum values at each grid point for the whole time-serie","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-3-1-compute-the-maximum-values-on-the-region-during-the-whole-time-serie-for-each-grid-cell","position":50},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.3.1) compute the maximum values on the region during the whole time-serie for each grid cell","lvl4":"9.3) Searching the maximum values at each grid point for the whole time-serie","lvl2":"9. Analysis cells "},"content":"\n\nhydro_region_precip_max = hydro_region_precip.max(dim = ['time'])\n\ngpcp_region_precip_max = gpcp_cube['precip'].max(dim = ['time'])\n\nera_region_precip_max = era_region_precip.max(dim = ['time'])\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-3-1-compute-the-maximum-values-on-the-region-during-the-whole-time-serie-for-each-grid-cell","position":51},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.3.2) Searching the days of massive precip events","lvl4":"9.3) Searching the maximum values at each grid point for the whole time-serie","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-3-2-searching-the-days-of-massive-precip-events","position":52},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.3.2) Searching the days of massive precip events","lvl4":"9.3) Searching the maximum values at each grid point for the whole time-serie","lvl2":"9. Analysis cells "},"content":"\n\n# defining the threshold matrix (maximum values to consider extreme events) \n# applying to datasets to find dates (where the daily precip > threshold)\n\nhydro_threshold = 0.99 * hydro_region_precip_max  \nhydro_dates_sup_threshold = hydro_region_precip['time'].where(hydro_region_precip >= hydro_threshold)\nhydro_tt = hydro_dates_sup_threshold.dropna(dim='time', how='all')\n\ngpcp_threshold = 0.99 * gpcp_region_precip_max  \ngpcp_dates_sup_threshold = gpcp_region_precip['time'].where(gpcp_cube['precip'] >= gpcp_threshold)\ngpcp_tt = gpcp_dates_sup_threshold.dropna(dim='time', how='all')\n\nera_threshold = 0.99 * era_region_precip_max \nera_dates_sup_threshold = era_region_precip['time'].where(era_cube['tp'] >= era_threshold)\nera_tt = era_dates_sup_threshold.dropna(dim='time', how='all')\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-3-2-searching-the-days-of-massive-precip-events","position":53},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"type":"lvl3","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-we-select-the-2nd-of-october-2020-detected-by-gpm-cpc-and-gpcp","position":54},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"content":"\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-we-select-the-2nd-of-october-2020-detected-by-gpm-cpc-and-gpcp","position":55},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.4) Maps of the daily precipitation for the three datasets on that particular day","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"type":"lvl4","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-4-maps-of-the-daily-precipitation-for-the-three-datasets-on-that-particular-day","position":56},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.4) Maps of the daily precipitation for the three datasets on that particular day","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"content":"\n\nhydro_xtrem_precip_20201002 = hydro_cube['precip'].sel(time='2020-10-02') \n\nfig = plt.figure()\nax = plt.axes(projection = projPC)\nim = ax.pcolormesh(hydro_xtrem_precip_20201002.lon, hydro_xtrem_precip_20201002.lat, hydro_xtrem_precip_20201002.values)\nax.set_extent([lonm, lonM, latm, latM], crs=projPC)\ngl = ax.gridlines(draw_labels=True, linewidth=0, alpha=0.5)\n\nax.coastlines()          \nax.add_feature(cfeature.LAND)\nax.add_feature(cfeature.COASTLINE)\nax.add_feature(cfeature.LAKES, alpha=0.5)\nax.add_feature(cfeature.RIVERS)\ncbar = plt.colorbar(im, label='precipitation (mm/d)',  extend='max', anchor=(0.2, 0.5), shrink=0.6, aspect=20)  # ajout de la colorbar\nax.set_title('Total precipitation (mm) on the south-east of France on the 02/10/2020 - from GPM-CPC dataset') \n\ngpcp_xtrem_precip_20201002 = gpcp_region_precip.sel(time='2020-10-02', latitude=slice(latm,latM)) \n\n# Define a normalization instance for the colorbar (not used here)\nnorm1 = mcolors.TwoSlopeNorm(vmin=0, vcenter=131.45/2, vmax=131.45)\n\nfig = plt.figure()\nax = plt.axes(projection = projPC)\nim = ax.pcolormesh(gpcp_xtrem_precip_20201002.longitude, gpcp_xtrem_precip_20201002.latitude, gpcp_xtrem_precip_20201002.values)#, norm=norm1)\nax.set_extent([lonm, lonM, latm, latM], crs=projPC)\ngl = ax.gridlines(draw_labels=True, linewidth=0, alpha=0.5)\n\nax.coastlines()          \nax.add_feature(cfeature.LAND)\nax.add_feature(cfeature.COASTLINE)\nax.add_feature(cfeature.LAKES, alpha=0.5)\nax.add_feature(cfeature.RIVERS)\ncbar = plt.colorbar(im, label='precipitation (mm/d)',  extend='max', anchor=(0.2, 0.5), shrink=0.6, aspect=20) \nax.set_title('Total precipitation (mm) on the south-east of France on the 02/10/2020 - from GPCP dataset')\n\nera_xtrem_precip_20201002 = 3600.*era_region_precip.sel(time='2020-10-02')[0] \n\n# Define a normalization instance for the colorbar (not used here)\nnorm2 = mcolors.TwoSlopeNorm(vmin=0, vcenter=131.45/2, vmax=131.45)\n\nfig = plt.figure()\nax = plt.axes(projection = projPC)\nim = ax.pcolormesh(era_xtrem_precip_20201002.longitude, era_xtrem_precip_20201002.latitude, era_xtrem_precip_20201002.values)#, norm=norm2)\nax.set_extent([lonm, lonM, latm, latM], crs=projPC)\ngl = ax.gridlines(draw_labels=True, linewidth=0, alpha=0.5)\n\nax.coastlines()          \nax.add_feature(cfeature.LAND)\nax.add_feature(cfeature.COASTLINE)\nax.add_feature(cfeature.LAKES, alpha=0.5)\nax.add_feature(cfeature.RIVERS)\ncbar = plt.colorbar(im, label='precipitation (mm/d)',  extend='max', anchor=(0.2, 0.5), shrink=0.6, aspect=20)  # ajout de la colorbar\nax.set_title('Total precipitation (mm) on the south-east of France on the 02/10/2020 - from ERA5 dataset')\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-4-maps-of-the-daily-precipitation-for-the-three-datasets-on-that-particular-day","position":57},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.5) Quantity and location of the maximum of precipitation (+ refined time-serie around the event)","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"type":"lvl4","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-5-quantity-and-location-of-the-maximum-of-precipitation-refined-time-serie-around-the-event","position":58},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.5) Quantity and location of the maximum of precipitation (+ refined time-serie around the event)","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"content":"\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-5-quantity-and-location-of-the-maximum-of-precipitation-refined-time-serie-around-the-event","position":59},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.5.1) On the hydrology cube","lvl4":"9.5) Quantity and location of the maximum of precipitation (+ refined time-serie around the event)","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-5-1-on-the-hydrology-cube","position":60},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.5.1) On the hydrology cube","lvl4":"9.5) Quantity and location of the maximum of precipitation (+ refined time-serie around the event)","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"content":"\n\n# maximum value and index of latitude and longitude of the maximum\n\nprint('FOR GPM-CPC')\nprint('maximum value: (mm/d)', np.nanmax(hydro_xtrem_precip_20201002))\nprint('index for latitude and longitude of the maximum: ', np.where(hydro_xtrem_precip_20201002 == np.nanmax(hydro_xtrem_precip_20201002)))\nhydro_xtrem_precip_20201002.isel(lat=446, lon=1487) \n\n### time serie around the 2nd of october 2020, at the grid cell of the maximum value\n\nlat_hydro=44.16 ; lon_hydro=7.687\n\nprecip_point_hydro = precip_data_hydro.sel(lat=lat_hydro, lon=lon_hydro, method='nearest')\nprecip_point_hydro1 = precip_point_hydro.sel(time=slice('2020-09-30', '2020-10-06'))\n\nplt.figure(figsize=(8, 4))\nplt.bar(precip_point_hydro1.time.values, precip_point_hydro1.values, width=0.1, color='blue', align='center')\nplt.title('Precipitation from GPM CPC SM2RAIN-ASCAT (hydrology cube)')\nplt.xlabel('Day')\nplt.ylabel('Daily rainfall (mm/d)')\nplt.xticks(rotation=45, ha='right')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-5-1-on-the-hydrology-cube","position":61},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.5.2) On the GPCP cube","lvl4":"9.5) Quantity and location of the maximum of precipitation (+ refined time-serie around the event)","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-5-2-on-the-gpcp-cube","position":62},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.5.2) On the GPCP cube","lvl4":"9.5) Quantity and location of the maximum of precipitation (+ refined time-serie around the event)","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"content":"\n\n# maximum value and index of latitude and longitude of the maximum\n\nprint('FOR GPCP')\nprint('maximum value: (mm/d)', np.nanmax(gpcp_xtrem_precip_20201002))\nprint('index for latitude and longitude of the maximum: ', np.where(gpcp_xtrem_precip_20201002 == np.nanmax(gpcp_xtrem_precip_20201002)))\n\ngpcp_xtrem_precip_20201002.isel(latitude=2, longitude=5) \n\n### time serie around the 2nd of october 2020, at the grid cell of the maximum value\n\nlat_gpcp= 45 ; lon_gpcp= 8\n\nprecip_point_gpcp = precip_data_gpcp.sel(latitude=lat_gpcp, longitude=lon_gpcp, method='nearest')\nprecip_point_gpcp1 = precip_point_gpcp.sel(time=slice('2020-09-30', '2020-10-06'))\n\nplt.figure(figsize=(8, 4))\nplt.bar(precip_point_gpcp1.time.values, precip_point_gpcp1.values, width=0.1, color='blue', align='center')\nplt.title('Precipitation from GPCP')\nplt.xlabel('Day')\nplt.ylabel('Daily rainfall (mm/d)')\nplt.xticks(rotation=45, ha='right')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-5-2-on-the-gpcp-cube","position":63},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.5.3) On the ERA5 cube","lvl4":"9.5) Quantity and location of the maximum of precipitation (+ refined time-serie around the event)","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-5-3-on-the-era5-cube","position":64},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.5.3) On the ERA5 cube","lvl4":"9.5) Quantity and location of the maximum of precipitation (+ refined time-serie around the event)","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"content":"\n\nprint('FOR ERA5')\nprint('maximum value: (mm/d)', np.nanmax(era_xtrem_precip_20201002))\nprint('index for latitude and longitude of the maximum: ', np.where(era_xtrem_precip_20201002 == np.nanmax(era_xtrem_precip_20201002)))\n\nlat_era= 44; lon_era= 7\n\nprecip_point_era = 3600.0*era_cube['tp'].sel(latitude=lat_era, longitude=lon_era, method='nearest')\nprecip_point_era1 = precip_point_era.sel(time=slice('2020-09-30', '2020-10-06'))\n\nplt.figure(figsize=(8, 4))\nplt.bar(precip_point_era1.time.values, precip_point_era1.values, width=0.1, color='blue', align='center')\nplt.title('Precipitation from ERA5')\nplt.xlabel('Day')\nplt.ylabel('Daily rainfall (mm/d)')\nplt.xticks(rotation=45, ha='right')\nplt.grid(True)\nplt.tight_layout()\nplt.show()","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-5-3-on-the-era5-cube","position":65},{"hierarchy":{"lvl1":"EODashboard STAC access examples"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access","position":0},{"hierarchy":{"lvl1":"EODashboard STAC access examples"},"content":"","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access","position":1},{"hierarchy":{"lvl1":"EODashboard STAC access examples"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#eodashboard-stac-access-examples","position":2},{"hierarchy":{"lvl1":"EODashboard STAC access examples"},"content":"eodashboard.org uses a standard static STAC catalog\n\nThis example notebook outlines\n\naccessing eodashboard STAC catalog\n\ndiscovery of the collections\n\nchecking individual metadata fields\n\nbrowsing through items inside linked GeoParquet storage\n\nshowing linked XYZ service on an interactive map for a single date\n\ntime series analysis using referenced statistics endpoint\n\n","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#eodashboard-stac-access-examples","position":3},{"hierarchy":{"lvl1":"Step 1: Accessing the EODashboard STAC Catalog"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-1-accessing-the-eodashboard-stac-catalog","position":4},{"hierarchy":{"lvl1":"Step 1: Accessing the EODashboard STAC Catalog"},"content":"The \n\neodashboard.org platform provides a publicly accessible STAC catalog.In this step, we use the pystac library to load the root catalog from the provided URL to explore provided collections.\n\nThis root catalog serves as the entry point and provides metadata and links to collections and subcatalogs.\nWe’ll inspect the catalog description, and check how many child collections are directly linked.","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-1-accessing-the-eodashboard-stac-catalog","position":5},{"hierarchy":{"lvl1":"Step 1: Accessing the EODashboard STAC Catalog","lvl2":"Structure"},"type":"lvl2","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#structure","position":6},{"hierarchy":{"lvl1":"Step 1: Accessing the EODashboard STAC Catalog","lvl2":"Structure"},"content":"eodash organizes its data in a two-level STAC structure:\n\nThe top level consists of “indicators”, represented as STAC collections. Each indicator describes a derived environmental variable or theme (e.g. “SMOS Ocean Salinity”).\n\nEach indicator then groups one or more sub-collections, represented also as STAC collections. They group the actual datasets contributing to the indicator and each subcollection is shown as separate layer in the eodash client interface.\n\n# Step 1: Access the EODashboard STAC Catalog via PySTAC\n\nfrom pystac import Catalog\n\n# URL to the root STAC catalog (adjust if necessary)\ncatalog_url = \"https://ESA-eodashboards.github.io/eodashboard-catalog/trilateral/catalog.json\"\n\n# Load the catalog\ncatalog = Catalog.from_file(catalog_url)\n\n# Print basic information\nprint(f\"Catalog ID: {catalog.id}\")\nprint(f\"Description: {catalog.description}\")\nindicators = list(catalog.get_children())\n\nprint(f\"Number of child indicators: {len(indicators)}\")\n\n\n\n","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#structure","position":7},{"hierarchy":{"lvl1":"Step 2: Discovering and Filtering Indicators"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-2-discovering-and-filtering-indicators","position":8},{"hierarchy":{"lvl1":"Step 2: Discovering and Filtering Indicators"},"content":"The STAC catalog contains over 100 indicators.In this step, we retrieve all indicators and filter them to include only those relevant to Soil Moisture and Ocean Salinity satellite (SMOS).\n\nWe look for the keyword “SMOS” in the collection’s satellite metadata field.This helps us isolate datasets derived from or related to ESA’s SMOS mission.\n\n# Step 2: Filter indicators related to SMOS\n\n# Filter indicators that mention 'SMOS' in satellite property\nsmos_indicators = [\n    ind for ind in indicators\n    if \"satellite\" in ind.extra_fields and \"SMOS\" in [s.upper() for s in ind.extra_fields[\"satellite\"]]\n]\n\n# Show results\nprint(f\"Found {len(smos_indicators)} SMOS-related collections (strict filter):\")\nfor ind in smos_indicators:\n    print(f\"{ind.id}: {ind.title}\")\n\n","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-2-discovering-and-filtering-indicators","position":9},{"hierarchy":{"lvl1":"Step 3: Checking Individual Metadata Fields"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-3-checking-individual-metadata-fields","position":10},{"hierarchy":{"lvl1":"Step 3: Checking Individual Metadata Fields"},"content":"Now that we’ve identified SMOS-related indicators, we’ll examine one specific indicator in detail:smos_ocean_salinity, which shows the sea surface salinity globally acquired by the SMOS mission.\n\nWe’ll print out the main metadata fields, including:\n\nBasic identification (title, description)\n\nSpatial and temporal extent\n\nLicensing and providers\n\nCustom fields such as satellite, region, and data_source if available\n\nindicator = next(ind for ind in indicators if ind.id == \"smos_ocean_salinity\") \n# Print basic metadata\nprint(f\"Title: {indicator.title}\")\nprint(f\"License: {indicator.license}\")\nprint(f\"Temporal Extent: {indicator.extent.temporal.to_dict()}\")\nprint(f\"Spatial Extent (bbox): {indicator.extent.spatial.bboxes}\")\nprint(\"-----------------------------------------------\")\nprint(f\"Description: {indicator.description}\")\n\n","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-3-checking-individual-metadata-fields","position":11},{"hierarchy":{"lvl1":"Step 4: Navigating the Indicator and Dataset Hierarchy"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-4-navigating-the-indicator-and-dataset-hierarchy","position":12},{"hierarchy":{"lvl1":"Step 4: Navigating the Indicator and Dataset Hierarchy"},"content":"So far, we’ve explored the indicator STAC Collection smos_ocean_salinity as explained in the Step 1.\n\nTo access the actual data items on a subcollection STAC Collection we now need to look at its child collections, which contain the STAC Items and assets.\n\nIn this step, we identify and load those child collections so we can continue our exploration at the data level.\n\nIn our case, the indicator has just one collection - itself so it looks easy.\n\n# Get child links that are STAC collections\nchild_collections = []\nfor link in indicator.get_links(\"child\"):\n    if link.rel == \"child\":\n        child_collection = link.resolve_stac_object().target\n        child_collections.append(child_collection)\n\n# Show child collection IDs and titles\nprint(f\"{len(child_collections)} child collections found under 'smos_ocean_salinity':\")\nfor col in child_collections:\n    print(f\"- {col.id}: {col.title}\")\n\n","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-4-navigating-the-indicator-and-dataset-hierarchy","position":13},{"hierarchy":{"lvl1":"Step 5: Accessing and Browsing STAC Items via GeoParquet"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-5-accessing-and-browsing-stac-items-via-geoparquet","position":14},{"hierarchy":{"lvl1":"Step 5: Accessing and Browsing STAC Items via GeoParquet"},"content":"In eodashboard, each child collection under an indicator may reference a bulk listing of STAC Items using a GeoParquet file for performance reasons during the catalog creation.\nThis file acts as a storage for the STAC Items associated with that dataset and can be efficiently read and queried.\n\nWe identify this asset by checking for an Asset with a roles array containing \"collection-mirror\" which is eodash specific way of distinction of the GeoParquet.\n\nOnce found, we load it and use pyarrow.parquet to load the GeoParquet file and stac_geoparquet to convert it back to STAC Item structure and display their contents.\n\nThis enables fast, local-style exploration of all STAC items in the dataset, including geometry, timestamp, and links to assets like XYZ tiles or statistics endpoints.\n\nimport requests\nimport pyarrow.parquet as pq\nimport io\nimport stac_geoparquet\n\ngeoparquet_asset = None\nfor key, asset in child_collection.assets.items():\n    # specific way how eodash labels the asset with a geoparquet of items\n    if \"collection-mirror\" in asset.roles:\n        geoparquet_asset = asset\n        break\n\nif geoparquet_asset is None:\n    raise ValueError(\"No asset with role 'collection-mirror' found in the child collection.\")\n# eodash catalog links the asset href with relative path, we need to get absolute to retrieve it\nparquet_url = geoparquet_asset.get_absolute_href()\nprint(f\"Reading remote GeoParquet from: {parquet_url}\")\n\nresponse = requests.get(parquet_url)\nif response.status_code != 200:\n    print(f\"Failed to download parquet file from {parquet_url}\")\n# Read the table with pyarrow\ntable = pq.read_table(io.BytesIO(response.content))\n\n# Convert to a list of STAC dictionaries\nitems = list(stac_geoparquet.arrow.stac_table_to_items(table))\nprint(f\"In total {len(items)} items were retrieved.\")\nprint(f\"Submission {len(items)} items were retrieved.\")\n# show example of metadata of one item\nitem = items[0]\nprint(\"-------------------------------------\")\nprint(f\"Datetime: {item['properties'].get('datetime')}\")\nprint(f\"BBox: {item['bbox']}\")\nprint(f\"Number of service links: {len(item['links'])}\")\n\n\n","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-5-accessing-and-browsing-stac-items-via-geoparquet","position":15},{"hierarchy":{"lvl1":"Step 6. Visualize Linked XYZ Tile Layer"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-6-visualize-linked-xyz-tile-layer","position":16},{"hierarchy":{"lvl1":"Step 6. Visualize Linked XYZ Tile Layer"},"content":"For each item, eodash links the suggested rendering of the visualization layer, which we can display using folium on the map.\n\nWe selected the first Item containing data for 1.4.2023 and add the tile layer with a eox cloudless background..\n\nimport folium\n\n# Find the xyz tile link for 1.4.2023\nxyz_link = next((l for l in item[\"links\"] if l[\"rel\"] == \"xyz\"), None)\nprint(f\"Actual link is {xyz_link}\")\nm = folium.Map(location=[45, 10], zoom_start=4, tiles=None)\nif xyz_link:\n    folium.TileLayer(\n        tiles=xyz_link[\"href\"],\n        attr='Rendering of SMOS datacube provided by xcube-server operated by Brockmann Consult GmbH',\n        name=xyz_link.get(\"title\", \"Tile Layer\"),\n        overlay=True,\n        control=True\n    ).add_to(m)\n\n# Add EOxCloudless layer\nfolium.TileLayer(\n    tiles=\"https://tiles.maps.eox.at/wmts/1.0.0/s2cloudless-2024_3857/default/GoogleMapsCompatible/{z}/{y}/{x}.jpg\",\n    attr='<a href=\"https://maps.eox.at\">Overlay</a> { Data &copy; <a href=\"http://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors, Rendering &copy; <a href=\"https://eox.at\">EOX</a> and <a href=\"https://github.com/mapserver/basemaps\">MapServer</a> }',\n    name=\"EOxCloudless 2024\",\n    overlay=False,\n    control=True\n).add_to(m)\n\nfolium.LayerControl().add_to(m)\nm\n\n","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-6-visualize-linked-xyz-tile-layer","position":17},{"hierarchy":{"lvl1":"Step 7. Create the legend for the provided layer"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-7-create-the-legend-for-the-provided-layer","position":18},{"hierarchy":{"lvl1":"Step 7. Create the legend for the provided layer"},"content":"When viewing geospatial datasets, especially those using color mapped imagery such as the SMOS ocean salinity layer, the colors themselves have no meaning without a reference.\n\nIn our case, the SMOS layer visualization uses the jet colormap scaled from 0 to 50 as seen in the XYZ link from metadata, which corresponds to sea surface salinity in parts per 1000 (ppt).\n\nIncluding a legend ensures that viewers can correctly interpret the scientific meaning behind the visual patterns.\n\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(6, 1))\nfig.subplots_adjust(bottom=0.5)\n\n# Create a colorbar image from the \"jet\" colormap\ncmap = plt.get_cmap('jet')\nnorm = plt.Normalize(vmin=0, vmax=50)\n\ncb = plt.colorbar(\n    plt.cm.ScalarMappable(norm=norm, cmap=cmap),\n    cax=ax,\n    orientation='horizontal'\n)\n\ncb.set_label(\"Sea Surface Salinity (ppt)\")\nplt.show()\n\n","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-7-create-the-legend-for-the-provided-layer","position":19},{"hierarchy":{"lvl1":"Step 8. Fetching and Plotting Time Series Statistics"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-8-fetching-and-plotting-time-series-statistics","position":20},{"hierarchy":{"lvl1":"Step 8. Fetching and Plotting Time Series Statistics"},"content":"In this step, we access the statistics service linked from the indicator level STAC collection.\nWe sent a POST request with a specified geographic polygon to retrieve median values of the satellite data over time.\nThe response provides a time series which we then visualized using Matplotlib.\n\nTo ensure the date labels on the x-axis are readable and well-formatted, we converted the time strings to datetime objects and used Matplotlib’s date locators and formatters.\n\nimport requests\nimport json\nimport matplotlib.pyplot as plt\nfrom shapely.geometry import Polygon, mapping\nimport matplotlib.dates as mdates\nfrom datetime import datetime\n\n# Find the statistics link in the indicator-level STAC Collection\nstats_link = next(\n    link for link in indicator.links\n    if link.rel == \"service\" and link.media_type == \"application/json\"\n)\nprint(f\"Statistics link {stats_link.target}\")\n# Prepare the polygon geometry (example: small box in the Mediterranean sea south of France)\npolygon_geom = Polygon([\n    (4.35, 40.55),\n    (4.35, 42.35),\n    (7.2, 42.35),\n    (7.2, 40.55),\n    (4.35, 40.55)\n])\n\ngeometry_geojson = mapping(polygon_geom)\n\n# Load POST body template from linked JSON file and fill {{{geometry}}}\nbody_url = stats_link.extra_fields[\"body\"]\nbody_template_str = requests.get(body_url).text\n# Replace the placeholder with the actual JSON object text\nbody_filled_str = body_template_str.replace(\n    \"{{{polygon}}}\",\n    json.dumps(geometry_geojson)\n)\n\n# Now parse into a Python dict\nbody_filled = json.loads(body_filled_str)\n\n# Send the POST request\nresponse = requests.post(stats_link.target, json=body_filled)\nresponse.raise_for_status()\ndata = response.json()\n\n# Extract times and median values\ntimes = [entry[\"time\"] for entry in data[\"result\"]]\n# Convert to datetime\ntimes_dt = [datetime.fromisoformat(t.replace(\"Z\", \"+00:00\")) for t in times]\nmedians = [entry[\"median\"] for entry in data[\"result\"]]\n\n# Plot as a time series\nfig, ax = plt.subplots(figsize=(10, 5))\nax.plot(times_dt, medians, marker=\"o\")\n\nax.set_title(\"SMOS Ocean Salinity Median Values\")\nax.set_xlabel(\"Time\")\nax.set_ylabel(\"Median Value Salinity (ppt)\")\n\n# Format the x-axis dates\nax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))  # one tick per month\nax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n\nplt.xticks(rotation=45, ha=\"right\")\nplt.tight_layout()\nplt.show()","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-8-fetching-and-plotting-time-series-statistics","position":21},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps"},"type":"lvl1","url":"/notebooks/nightlights-notebook/night-lights-blending","position":0},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps"},"content":"","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending","position":1},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Case study: Creating nighttime light maps with color blending"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#case-study-creating-nighttime-light-maps-with-color-blending","position":2},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Case study: Creating nighttime light maps with color blending"},"content":"\n\nThis notebook demonstrates how to create nighttime light variation maps over a time interval (from 2019 to 2022) with additive color blending for studying the distribution of artificial lighting in urban and rural regions, offering insights into urbanization, infrastructure development, and socio-economic activity.\nThe Nighttime Light Levels indicator can be explored on the EO Dashboard by selecting the EXPLORE DATASETS mode and choosing \n\nNight lights indicators.\n\nThe study has been carried out by Bumpei Tojo PhD (Associate Professor), School of International and Area Studies, Tokyo University of Foreign Studies, Japan.\n\nThe PLES Engineering team (supporting ESA Green Solutions Division, EOP-SG) developed the blending algorithm with the current Notebook implementation and data ingestion on the dashboard (contacts: Federico Rondoni, \n\nf​.rondoni@stariongroup​.eu, Diego Moglioni, \n\nd​.moglioni@stariongroup​.eu).\n\n\nExample of a nighttime light map covering Northeastern United States during 2019-2022, representing areas where a decrease in nighttime light level occurred (indicating a presumed reduction in social activity) in red, and areas where an increase occurred (indicating a presumed increase in social activity) in blue.\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#case-study-creating-nighttime-light-maps-with-color-blending","position":3},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Input data:"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#input-data","position":4},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Input data:"},"content":"This product was developed by JAXA by aggregating the data from the Visible Infrared Imaging Radiometer Suite (VIIRS, onboard the Suomi NPP satellite) on a semi-annual basis (using median image generation) with 10-degree lat/lon (geographic) grid h-v tile as Geo Tiff files.\n\nThe tiles are 2400 x 2400 pixels, with pixel size of 0.004166 degrees (~464 m at the equator).\n\nMetric: nighttime radiance (measured in watts per square centimeter per steradian, [W/cm²/sr]), which represents the brightness of artificial lighting.\n\nVIIRS 10-degree tile scheme\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#input-data","position":5},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Running environment:"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#running-environment","position":6},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Running environment:"},"content":"This notebook can be run by installing the provided Anaconda Python environment (data/Nightlights/nightlights-env.yml).\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#running-environment","position":7},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Importing Python libraries"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#importing-python-libraries","position":8},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Importing Python libraries"},"content":"\n\n#Import libraries\nimport os\nimport sys\nimport re\nimport numpy as np\nimport rasterio\nimport rioxarray as rxr\nimport subprocess\nfrom subprocess import Popen, PIPE\nimport tempfile\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom PIL import Image\nimport json\nfrom ipyleaflet import Map, ImageOverlay, basemaps\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#importing-python-libraries","position":9},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Defining working folders"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#defining-working-folders","position":10},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Defining working folders"},"content":"\n\ninput_dir = \"input\"\ninput_path = os.path.join(os.getcwd(), \"data\", \"Nightlights\", input_dir)\n\noutput_urban = \"output\"\nurban_path = os.path.join(os.getcwd(), \"data\", \"Nightlights\", output_urban)\n\n# Create output dir\nos.makedirs(urban_path, exist_ok=True)\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#defining-working-folders","position":11},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Visualizing input data"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#visualizing-input-data","position":12},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Visualizing input data"},"content":"\n\npattern = re.compile(r\"h(\\d+)v(\\d+)_(\\d{4})_(\\d)H_median\\.tif\")\n\nfor root, _, files in os.walk(input_path):\n    grouped_files = {}\n    \n    # Grouping files by h and v\n    for file in files:\n        match = pattern.match(file)\n        if match:\n            h, v, year, H = match.groups()\n            key = (h, v)\n            if key not in grouped_files:\n                grouped_files[key] = []\n            grouped_files[key].append((year, H, os.path.join(root, file))) \n    \n    # Process files for plotting\n    for (h, v), file_group in grouped_files.items():\n        file_group\n\ntuplelist2dict = {c:{'year':a,'half':b} for a,b,c in file_group}\nsorted_dict = {}\n\ngrid_tile = None\nfor item in sorted(tuplelist2dict, key = lambda k: (tuplelist2dict[k]['year'], tuplelist2dict[k]['half'])):\n    sorted_dict.update({item:tuplelist2dict[item]})\n    grid_tile = item.split('/')[-1].split('_')[0]\n\n\ndef plot_figures(figures, nrows = 1, ncols=1, factor = 1., clip_range = None, **kwargs):\n    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, figsize=(15, 15))\n    for idx,file_name in enumerate(figures):\n        title = file_name.split('/')[-1]\n        title = title.replace(\"_median.tif\", \"\")\n        axeslist.ravel()[idx].imshow(np.clip(mpimg.imread(file_name)*factor, *clip_range), **kwargs) # cmap=plt.gray(), cmap='Greys'\n        axeslist.ravel()[idx].set_title(title)\n        axeslist.ravel()[idx].set_axis_off()\n    fig.suptitle(r'Median nighttime light level [$Wcm^{-2}sr^{-1}$]', fontsize=20)\n    #plt.tight_layout() \n\n    \n\nplot_figures(sorted_dict, 4, 2, clip_range=(0,1), factor=100./255.)\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#visualizing-input-data","position":13},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Applying color blending"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#applying-color-blending","position":14},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Applying color blending"},"content":"\n\nAdditive color blending involves mixing the primary colors of light, red (R), green (G), and blue (B), while adjusting their luminance levels. By manipulating the luminance of these colors, a wide range of hues can be achieved, with the key characteristic being that combining all three colors results in white.\n\nTechnique\n\nmaximum pixel value of images for 2019 (brightest pixel values) is assigned to red (R)\n\nminimum pixel value of images for 2020-2021 (darkest pixel values) is assigned to green (G)\n\nmaximum pixel value of images for 2022 (brightest pixel values) is assigned to blue (B)\n\nOutput\n\nregions where a decrease in nighttime light level occurred are displayed in red\n\nareas that experienced an increase (presumed to indicate an increase in social activity) are shown in blue\n\nregions where there was no significant change throughout the pandemic are displayed in a gradient from gray to white.\n\npattern = re.compile(r\"h(\\d+)v(\\d+)_(\\d{4})_(\\d)H_median\\.tif\")\n\n\ndef read_and_preprocess(file):\n    with rasterio.open(file) as src:\n        img = src.read(1)\n        img = np.nan_to_num(img, nan=0)  # Replace NaNs with zeros\n        return img, src.profile\n\n    \ndef additive_blending(grouped_files):\n    # Process each group of files for blending\n    for (h, v), file_group in grouped_files.items():\n        # Initialize arrays to store the maximum and minimum values for each year\n        max_2019 = None\n        min_2020_2021 = None\n        max_2022 = None\n        \n        for year, H, file in file_group:\n            img, profile = read_and_preprocess(file)\n            \n            if year == '2019':\n                if max_2019 is None:\n                    max_2019 = img\n                else:\n                    max_2019 = np.maximum(max_2019, img)\n            elif year in ['2020', '2021']:\n                if min_2020_2021 is None:\n                    min_2020_2021 = img\n                else:\n                    min_2020_2021 = np.minimum(min_2020_2021, img)\n            elif year == '2022':\n                if max_2022 is None:\n                    max_2022 = img\n                else:\n                    max_2022 = np.maximum(max_2022, img)\n                                  \n    # Create the blended image using the specified blending technique\n    blended_img = np.zeros((max_2019.shape[0], max_2019.shape[1], 3), dtype=np.float32)\n    blended_img[:, :, 0] = max_2019.astype(np.float32)  # Red band: maximum of 2019\n    blended_img[:, :, 1] = min_2020_2021.astype(np.float32)  # Green band: minimum of 2020-2021 compared\n    blended_img[:, :, 2] = max_2022.astype(np.float32)  # Blue band: maximum of 2022\n    \n    return blended_img, profile        \n\n# Grouping files per (h,v) tiles and years span\ngrouped_files = {}\nfor root, _, files in os.walk(input_path):\n    \n    \n    # Group files by h and v\n    for file in files:\n        match = pattern.match(file)\n        if match:\n            h, v, year, H = match.groups()\n            key = (h, v)\n            if key not in grouped_files:\n                grouped_files[key] = []\n            grouped_files[key].append((year, H, os.path.join(root, file)))\n\n\n# blending           \nblended_img, profile = additive_blending(grouped_files)\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#applying-color-blending","position":15},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Employing “urban” stretch processing"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#employing-urban-stretch-processing","position":16},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Employing “urban” stretch processing"},"content":"\n\nThe purpose of the stretch processing is to emphasize the nighttime light level of each band (corresponding to 2019, 2020-21, and 2022), focusing on:\n\n“urban” nighttime light levels: the display range of each band is adjusted to 25-1000 [watts·cm-2·sr-1], emphasizing brighter areas\n\n# Urban stretch processing: Emphasize brighter areas\ndef urban_stretch_processing(band):\n    min_val = 25\n    max_val = 1000\n    band = np.clip(band, min_val, max_val)\n    band = (band - min_val) / (max_val - min_val) * 255\n    return band.astype(np.uint8)\n\n# Apply urban stretch processing to each band\nblended_img[:, :, 0] = urban_stretch_processing(blended_img[:, :, 0])\nblended_img[:, :, 1] = urban_stretch_processing(blended_img[:, :, 1])\nblended_img[:, :, 2] = urban_stretch_processing(blended_img[:, :, 2])\n        \n# Update the profile for a 3-band image and set nodata value to None\nprofile.update(count=3, dtype=rasterio.uint8, nodata=None)\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#employing-urban-stretch-processing","position":17},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Plotting blended image"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#plotting-blended-image","position":18},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Plotting blended image"},"content":"\n\ndef plot_image(image, factor=1.0, clip_range = None, **kwargs):\n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n    if clip_range is not None:\n        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n    else:\n        ax.imshow(image * factor, **kwargs)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n\nplot_image(blended_img, factor=1.5/255., clip_range=(0,1))\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#plotting-blended-image","position":19},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Overlaying with an interactive map"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#overlaying-with-an-interactive-map","position":20},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Overlaying with an interactive map"},"content":"\n\nSaving blended image as Cloud Optimized GeoTIFF\n\n# Exporting output as COG file \nres_name = f\"Nighttimelevel_Urban_{grid_tile}_2019-2022.tif\"\noutput_cog = os.path.join(urban_path, res_name)\n\n\n# Write the blended image directly to a temporary file\nwith tempfile.NamedTemporaryFile(suffix=\".tif\") as temp_file:\n    with rasterio.open(temp_file.name, \"w\", **profile) as dst:\n        dst.write(blended_img[:, :, 0], 1)\n        dst.write(blended_img[:, :, 1], 2)\n        dst.write(blended_img[:, :, 2], 3)\n\n    subprocess.run([\n        \"gdal_translate\", \"-of\", \"COG\",\n        \"-co\", \"COMPRESS=DEFLATE\",\n        \"-co\", \"BLOCKSIZE=512\",\n        \"-co\", \"RESAMPLING=NEAREST\",\n        \"-co\", \"OVERVIEWS=IGNORE_EXISTING\",\n        temp_file.name,\n        output_cog\n    ])\n\nprint(f\"COG file saved as {output_cog}\")\n\nExtracting bounding-box coordinates\n\np1 = Popen([\"gdalinfo\", \"-json\", output_cog, \"-mm\"], stdout=PIPE)\noutput = p1.communicate()[0]\ndec_out = output.decode('utf-8')\nj_str = json.loads(dec_out)\nbbox = j_str['cornerCoordinates']\nll = bbox['lowerLeft']  # SW coo\nur = bbox['upperRight'] # NE coo\ncenter = bbox['center']\n\nAdding alpha channel to the blended image\n\ndef almostEquals(a,b,thres=50):\n    return all(abs(a[i]-b[i])<thres for i in range(len(a)))\n\n\nimage = Image.open(output_cog).convert('RGBA')\npixeldata = list(image.getdata())\n\n\nfor i,pixel in enumerate(pixeldata):\n    if almostEquals(pixel[:3], (0,0,0)):\n        pixeldata[i] = (0,0,0,0)\n\n\nimage.putdata(pixeldata)\npng_path = os.path.join(urban_path, res_name.replace(\".tif\",\".png\"))\nres = image.save(png_path)\n#os.path.abspath(res)\nabs_path = os.path.abspath(png_path)\nwork_dir = os.getcwd()\nid_ = work_dir.split('/')[2]\nbase_url = os.path.join('https://hub-otc-sc.eox.at/user',id_,'files')\n#base_url\nabs_path = '/'.join(abs_path.split('/')[3:])\n#abs_path\n#os.path.join(base_url,abs_path)\n\nOverlay with OpenStreetMap\n\nm = Map(basemap=basemaps.CartoDB.DarkMatter, center=(center[1], center[0]), zoom=6)\nimage = ImageOverlay(\n        url=os.path.join(base_url,abs_path), #url=\"https://hub-otc-sc.eox.at/user/<id>/files/<path_to_png>\n        bounds=((ll[1], ll[0]), (ur[1], ur[0])) # SW and NE corners\n                    )\nm.add_layer(image);\nm\n\nUsing additive color blending images to focus on urban areas in the northeastern United States, particularly the southern part of the Boston-Washington Corridor comprising major cities like New York, Philadelphia, Baltimore, and Washington, D.C., revealed relatively little variation in nighttime lights before and after the COVID-19 pandemic, as indicated by the images appearing white. However, significant reductions in nighttime lights during the COVID-19 pandemic (subsequently recovering to pre-pandemic levels) were evident in other medium to large cities, including Boston and Toronto, among others, as indicated by the images appearing pink to reddish.\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#overlaying-with-an-interactive-map","position":21},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Alternative stretch processing approaches"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#alternative-stretch-processing-approaches","position":22},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Alternative stretch processing approaches"},"content":"\n\n“Rural” nighttime light levels: setting each band’s display range to 0-50 [Watts·cm-2·sr-1] to emphasize darker areas\n\nFor a broader focus (from rural to urban areas): applying a log10 transformation to the values of each band with a display range set to 0-3.6 (equivalent to 0-3981 [Watts·cm-2·sr-1])\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#alternative-stretch-processing-approaches","position":23},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Final remarks"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#final-remarks","position":24},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Final remarks"},"content":"\n\nThis product has been specifically designed for utilization by researchers in applied scientific fields.\nPotential applications are being explored in environmental and social issue studies, such as disaster recovery, energy, urban land use changes, conflicts, migration, and monitoring of illegal, unreported activities.\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#final-remarks","position":25},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"To learn more"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#to-learn-more","position":26},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"To learn more"},"content":"\n\nThe presented approach is often referenced in scientific and public health research. For example, Bunpei Tojo (2021) used Nightlights data in the study “Application of Earth observation satellite data to public health: Comparison of night light (VIIRS) and solar radiation (SGLI) and domestic COVID-19 epidemic,” presented at the 12th Federation of Science and Technology conference, to analyze the relationship between nighttime light intensity and public health factors.\n\n\n東城 (2021).","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#to-learn-more","position":27},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI"},"type":"lvl1","url":"/notebooks/veda-api-bids-2023","position":0},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI"},"content":"This notebook is divided into two parts, each demonstrating the functionalities of the VEDA EOAPI.\n\nReading and visualizing one of the datasets from the VEDA data catalog.\n\nUsing the EOAPI to generate a time-series of OMI (Ozone Monitoring Instrument) NO₂ and SO₂ datasets\n\nAuthor: Slesa Adhikari\n\n","type":"content","url":"/notebooks/veda-api-bids-2023","position":1},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI","lvl2":"1. Reading and visualizing one of the datasets from the VEDA data catalog"},"type":"lvl2","url":"/notebooks/veda-api-bids-2023#id-1-reading-and-visualizing-one-of-the-datasets-from-the-veda-data-catalog","position":2},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI","lvl2":"1. Reading and visualizing one of the datasets from the VEDA data catalog"},"content":"\n\nImport all the necesssary libraries\n\nMake sure you install these first using:pip install pystac_client folium seaborn pandas\n\n# imports\nimport requests\nfrom pystac_client import Client\nimport folium\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nDefine the API endpoints\n\nThe EOAPI is a combination of two components.\n\nData catalog - the \n\nSpatioTemporal Asset Catalog (STAC) specification is used to catalog the available datasets\n\nDynamic tile server - \n\nTiTiler is used to dynamically serve cloud optimized geotiff (raster) data files\n\nSTAC_API_URL = \"https://staging-stac.delta-backend.com/\"\nRASTER_API_URL = \"https://staging-raster.delta-backend.com\"\n\nUse the pystac_client library to interact with the STAC data catalog\n\ncatalog = Client.open(STAC_API_URL)\n\nList all the datasets (collections) in the catalog\n\nfor collection in list(catalog.get_collections()):\n    print(f\"{collection.id} - {collection.title}\")\n\nChoose a collection to work with\n\nSearch all the items in the collection\n\ncollection_id = \"no2-monthly\"\nsearch = catalog.search(collections=[collection_id])\nitems = list(search.items())\nitems\n\nLoad and inspect one of the items\n\ns3_uri = items[0].assets[\"cog_default\"].href\n\nstats = requests.get(\n    f\"{RASTER_API_URL}/cog/statistics\",\n    params={\"url\": s3_uri}\n).json()\nstats\n\nDisplay the COG in a map\n\nGet the tiles endpoint for the file\n\nrescale = f\"{stats['b1']['min']},{stats['b1']['max']}\"\n\ntiles = requests.get(\n    f\"{RASTER_API_URL}/stac/tilejson.json?collection={collection_id}&item={items[0].id}&assets=cog_default&colormap_name=rdbu_r&rescale={rescale}\"\n).json()\n\ntiles\n\nUse the tiles to visualize the file in a map\n\nm = folium.Map(\n    zoom_start=6,\n    scroll_wheel_zoom=True, \n    tiles=tiles[\"tiles\"][0], \n    attr=\"VEDA\", \n    minzoom=0, \n    maxzoom=18,\n)\n\nm\n\nMake this map slightly more insightful\n\nUsing the minimum and maximum values for the colorscale may not be the most useful. Dynamic tiling to the rescue!\nTiTiler comes with a \n\nlarge amount of options to style the map. Here we’ll do a quick a dirty adjustment of the max value.\n\nrescale_limited_max = f\"{stats['b1']['min']},{stats['b1']['max']/2}\"\n\ntiles_limited_max = requests.get(\n    f\"{RASTER_API_URL}/stac/tilejson.json?collection={collection_id}&item={items[0].id}&assets=cog_default&colormap_name=rdbu_r&rescale={rescale_limited_max}\"\n).json()\ntiles_limited_max\n\nm_limited_max = folium.Map(\n    zoom_start=6,\n    scroll_wheel_zoom=True, \n    tiles=tiles_limited_max[\"tiles\"][0], \n    attr=\"VEDA\", \n    minzoom=0, \n    maxzoom=18,\n)\nm_limited_max\n\n","type":"content","url":"/notebooks/veda-api-bids-2023#id-1-reading-and-visualizing-one-of-the-datasets-from-the-veda-data-catalog","position":3},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI","lvl2":"2. Using the EOAPI to generate a time-series of OMI (Ozone Monitoring Instrument) NO₂ and SO₂ datasets"},"type":"lvl2","url":"/notebooks/veda-api-bids-2023#id-2-using-the-eoapi-to-generate-a-time-series-of-omi-ozone-monitoring-instrument-no-and-so-datasets","position":4},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI","lvl2":"2. Using the EOAPI to generate a time-series of OMI (Ozone Monitoring Instrument) NO₂ and SO₂ datasets"},"content":"\n\nThere’s a story published in the EODashboard with the following title:\n\nAir pollution in India, China and the U.S. have changed significantly over the past two decades\n\nLink: \n\nhttps://​eodashboard​.org​/story​?id​=​air​-pollution​-us​-india​-china\n\nThe story talks about the trend of air pollution in India, China and the U.S. using the NO2 and SO2 readings grabbed from the OMI instrument\n\nHere, we’ll recreate the analysis using the EOAPI\n\n# Here, we find the relevant collection ID for the dataset\ncollections = {\n    \"no2\": \"OMI_trno2-COG\",\n    \"so2\": \"OMSO2PCA-COG\",\n}\n\nDefine the roughly similar Area of Interest (AOI) for each of the country as seen in the story\n\naois = {\n    \"india\": {\n      \"type\": \"Feature\",\n      \"properties\": {},\n      \"geometry\": {\n        \"coordinates\": [\n          [\n            [\n              84.44227371801799,\n              25.276852788244952\n            ],\n            [\n              81.73331688510166,\n              25.379576397063317\n            ],\n            [\n              81.40290450746915,\n              20.640781701865322\n            ],\n            [\n              84.09079123546121,\n              20.59296261766137\n            ],\n            [\n              84.44227371801799,\n              25.276852788244952\n            ]\n          ]\n        ],\n        \"type\": \"Polygon\"\n      }\n    },\n    \"china\": {\n      \"type\": \"Feature\",\n      \"properties\": {},\n      \"geometry\": {\n        \"coordinates\": [\n          [\n            [\n              118.14487188674968,\n              40.38237805885373\n            ],\n            [\n              112.59679754686567,\n              40.39197699341523\n            ],\n            [\n              112.78712023622006,\n              32.015052150835814\n            ],\n            [\n              117.937454307721,\n              32.102440507249895\n            ],\n            [\n              118.14487188674968,\n              40.38237805885373\n            ]\n          ]\n        ],\n        \"type\": \"Polygon\"\n      }\n    },\n    \"usa\": {\n        \"type\": \"Feature\",\n        \"properties\": {},\n        \"geometry\": {\n            \"coordinates\": [\n            [\n                [\n                -80.16702521343733,\n                41.73420113945659\n                ],\n                [\n                -83.56446680395005,\n                38.599369254919566\n                ],\n                [\n                -82.00280661075571,\n                37.54658260550103\n                ],\n                [\n                -78.28140359718638,\n                40.450899619800595\n                ],\n                [\n                -80.16702521343733,\n                41.73420113945659\n                ]\n            ]\n            ],\n            \"type\": \"Polygon\"\n        }\n    },\n}\n\nDefine a function that takes the following params:\n\nitem: a STAC item\n\ngeojson: the geojson of the AOI\n\nUsing the /cog/statistics/ endpoint of the raster API, we get back the statistics of the item (which corresponds to one COG file) within the given geojson AOI.\n\nThe statistics includes min, max, mean, std, etc.\n\n# the bounding box should be passed to the geojson param as a geojson Feature or FeatureCollection\ndef generate_stats(item, geojson):\n    result = requests.post(\n        f\"{RASTER_API_URL}/cog/statistics\", \n        params={\n            \"url\": item.assets[\"cog_default\"].href\n        },\n        json=geojson\n    ).json()\n    return {\n        **result[\"properties\"],\n        \"start_datetime\": str(item.properties.get(\"datetime\", item.properties.get(\"start_datetime\")))[:4],\n        \"collection\": item.collection_id\n    }\n\nLet’s start out with the US 🇺🇸 !\n\nWe’ll get all the items in the NO2 and SO2 collections and generate the statistics from them for the Ohio River Valley region of the United States.\n\nusa_aoi = aois[\"usa\"]\nitems = list(catalog.search(collections=[collections[\"no2\"], collections[\"so2\"]]).items())\nusa_stats = [\n    generate_stats(item, usa_aoi)\n    for item in items\n]\n\nCreate a function that takes the statistics (which is a json) and converts it to a pandas dataframe in a format that’ll make it easy to read and visualize.\n\nWe’re only concerned with the mean statistics for this example. Specifically the change from the year 2005 in percentage. We’ll use pandas to calculate this change percentage and assign it to the change column.\n\ndef clean_stats(stats_json) -> pd.DataFrame:\n    # convert the stats_json as is to pandas dataframe\n    df = pd.json_normalize(stats_json)\n    # simple renaming for readability\n    df.columns = [col.replace(\"statistics.b1.\", \"\") for col in df.columns]\n    # create a date column from the start_datetime column\n    df[\"date\"] = pd.to_datetime(df[\"start_datetime\"], format=\"%Y\")\n    # sort the dataframe by the date column\n    df = df.sort_values(by=[\"date\"])\n    # create a change column that calculates the change of the mean values from the value in 2005\n    df[\"change\"] = df.groupby(\"collection\", group_keys=False)[\"mean\"].apply(lambda x: x.div(x.iloc[0]).subtract(1).mul(100))\n    return df\n\ncleaned_stats_df = clean_stats(usa_stats)\n\nWe’ll now create a time-series of the change in mean values for NO2 and SO2 for the area in the US.\n\nplt.xticks([i for i in range(0, 21, 2)])\nsns.set_style(\"darkgrid\")\nax = sns.lineplot(\n    x=\"start_datetime\",\n    y=\"change\",\n    hue=\"collection\",\n    data=cleaned_stats_df,\n    palette=[\"#2196f3\", \"#ff5722\"],\n    style=\"collection\",\n    markers=[\"*\", \"d\"]\n)\nax.set_title(\"US - Ohio River Valley\")\nax.set_xlabel(\"Years\")\nax.set_ylabel(\"Change from 2005 (%)\")\nplt.legend(frameon=False, ncol=3)\nplt.show()\n\nNow, let’s create a function that creates this trend graph, given the country.\n\ndef create_chart(country):\n    stats = [generate_stats(item, aois[country]) for item in list(catalog.search(collections=[collections[\"no2\"], collections[\"so2\"]]).items())]\n    df = clean_stats(stats)\n\n    # Create a chart using Seaborn\n    plt.xticks([i for i in range(0, 21, 2)])\n    sns.set_style(\"darkgrid\")\n    ax = sns.lineplot(\n        x=\"start_datetime\",\n        y=\"change\",\n        hue=\"collection\",\n        data=df,\n        palette=[\"#2196f3\", \"#ff5722\"],\n        style=\"collection\",\n        markers=[\"*\", \"d\"]\n    )\n    ax.set_title(country.title())\n    ax.set_xlabel(\"Years\")\n    ax.set_ylabel(\"Change from 2005 (%)\")\n    plt.legend(frameon=False, ncol=3)\n    plt.show()\n\nWe can use this function to create charts for the rest of the AOIs.\n\nIndia 🇮🇳\n\ncreate_chart(\"india\")\n\nChina 🇨🇳\n\ncreate_chart(\"china\")","type":"content","url":"/notebooks/veda-api-bids-2023#id-2-using-the-eoapi-to-generate-a-time-series-of-omi-ozone-monitoring-instrument-no-and-so-datasets","position":5}]}