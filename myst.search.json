{"version":"1","records":[{"hierarchy":{"lvl1":"Example Viewer Template"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Example Viewer Template"},"content":"This template repository is intended to allow easy instantiation of an example viewer for jupyterlab notebooks.\nExternal repositories can be added via git submodules to the external_notebooks folder.\nThe github action will traverse available notebooks and try to extract metadata information as well as build them with Jupyterbook (v2 and MYST).\nThe build package is then deployed on github pages.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"2025-BiDS-EODashboard"},"type":"lvl1","url":"/external-notebooks/group1/2025-bids-eodashboard/readme","position":0},{"hierarchy":{"lvl1":"2025-BiDS-EODashboard"},"content":"Materials for Tutorial Hands-On with EO: Creating Indicators and Stories from Open Satellite Data on Big Data From Space 2025 in Riga","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/readme","position":1},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI"},"type":"lvl1","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities","position":0},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI"},"content":"","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities","position":1},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl2":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI"},"type":"lvl2","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#urban-health-and-megacities-the-case-of-new-delhi","position":2},{"hierarchy":{"lvl1":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI","lvl2":"URBAN HEALTH AND MEGACITIES: THE CASE OF NEW DELHI"},"content":"\n\n\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#urban-health-and-megacities-the-case-of-new-delhi","position":3},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights"},"type":"lvl1","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-case-1-nighttime-lights","position":4},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights"},"content":"","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-case-1-nighttime-lights","position":5},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl2":"Creating nighttime light maps with color blending"},"type":"lvl2","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#creating-nighttime-light-maps-with-color-blending","position":6},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl2":"Creating nighttime light maps with color blending"},"content":"\n\nThis use case demonstrates how to create nighttime light variation maps over a time interval (from 2019 to 2022) with additive color blending for studying the distribution of artificial lighting in urban and rural regions, offering insights into urbanization, infrastructure development, and socio-economic activity.\nThe Nighttime Light Levels indicator can be explored on the EO Dashboard by selecting the EXPLORE DATASETS mode and choosing \n\nNight lights indicators.\n\nThe study has been carried out by Bumpei Tojo PhD (Associate Professor), School of International and Area Studies, Tokyo University of Foreign Studies, Japan.\n\nThe PLES Engineering team (supporting ESA Green Solutions Division, EOP-SG) developed the blending algorithm with the current Notebook implementation and data ingestion on the dashboard (contacts: Federico Rondoni, \n\nf‚Äã.rondoni@stariongroup‚Äã.eu, Diego Moglioni, \n\nd‚Äã.moglioni@stariongroup‚Äã.eu).\n\n\n\nExample of a nighttime light map covering India during 2019-2022, representing areas where a decrease in nighttime light level occurred (indicating a presumed reduction in social activity) in red, and areas where an increase occurred (indicating a presumed increase in social activity) in blue.\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#creating-nighttime-light-maps-with-color-blending","position":7},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Input data:","lvl2":"Creating nighttime light maps with color blending"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#input-data","position":8},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Input data:","lvl2":"Creating nighttime light maps with color blending"},"content":"This product was developed by JAXA by aggregating the data from the Visible Infrared Imaging Radiometer Suite (VIIRS, onboard the Suomi NPP satellite) on a semi-annual basis (using median image generation) with 10-degree lat/lon (geographic) grid h-v tile as Geo Tiff files.\n\nThe tiles are 2400 x 2400 pixels, with pixel size of 0.004166 degrees (~464 m at the equator).\n\nMetric: nighttime radiance (measured in watts per square centimeter per steradian, [W/cm¬≤/sr]), which represents the brightness of artificial lighting.\n\nVIIRS 10-degree tile scheme\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#input-data","position":9},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Running environment:","lvl2":"Creating nighttime light maps with color blending"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#running-environment","position":10},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Running environment:","lvl2":"Creating nighttime light maps with color blending"},"content":"This notebook can be run by installing the provided Anaconda Python environment (notebook-env.yml).\n\n\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#running-environment","position":11},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Importing Python libraries","lvl2":"Creating nighttime light maps with color blending"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#importing-python-libraries","position":12},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Importing Python libraries","lvl2":"Creating nighttime light maps with color blending"},"content":"\n\n#Import libraries\nimport os\nimport sys\nimport re\nimport numpy as np\nimport rasterio\nimport rioxarray as rxr\nimport subprocess\nfrom subprocess import Popen, PIPE\nimport tempfile\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom PIL import Image\nimport json\nfrom ipyleaflet import Map, ImageOverlay, basemaps\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#importing-python-libraries","position":13},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Defining working folders","lvl2":"Creating nighttime light maps with color blending"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#defining-working-folders","position":14},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Defining working folders","lvl2":"Creating nighttime light maps with color blending"},"content":"\n\ninput_dir = \"input\"\ninput_path = os.path.join(os.getcwd(), \"Nightlights\", input_dir)\n\noutput_urban = \"output\"\nurban_path = os.path.join(os.getcwd(), \"Nightlights\", output_urban)\n\n# Create output dir\nos.makedirs(urban_path, exist_ok=True)\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#defining-working-folders","position":15},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Visualizing input data","lvl2":"Creating nighttime light maps with color blending"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#visualizing-input-data","position":16},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Visualizing input data","lvl2":"Creating nighttime light maps with color blending"},"content":"\n\npattern = re.compile(r\"h(\\d+)v(\\d+)_(\\d{4})_(\\d)H_median\\.tif\")\n\nfor root, _, files in os.walk(input_path):\n    grouped_files = {}\n    \n    # Grouping files by h and v\n    for file in files:\n        match = pattern.match(file)\n        if match:\n            h, v, year, H = match.groups()\n            key = (h, v)\n            if key not in grouped_files:\n                grouped_files[key] = []\n            grouped_files[key].append((year, H, os.path.join(root, file))) \n    \n    # Process files for plotting\n    for (h, v), file_group in grouped_files.items():\n        file_group\n\ntuplelist2dict = {c:{'year':a,'half':b} for a,b,c in file_group}\nsorted_dict = {}\n\ngrid_tile = None\nfor item in sorted(tuplelist2dict, key = lambda k: (tuplelist2dict[k]['year'], tuplelist2dict[k]['half'])):\n    sorted_dict.update({item:tuplelist2dict[item]})\n    grid_tile = item.split('/')[-1].split('_')[0]\n#print(sorted_dict)\n\ndef plot_figures(figures, nrows = 1, ncols=1, factor = 1., clip_range = None, **kwargs):\n    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, figsize=(15, 15))\n    for idx,file_name in enumerate(figures):\n        title = file_name.split('/')[-1]\n        title = title.replace(\"_median.tif\", \"\")\n        axeslist.ravel()[idx].imshow(np.clip(mpimg.imread(file_name)*factor, *clip_range), **kwargs) # cmap=plt.gray(), cmap='Greys'\n        axeslist.ravel()[idx].set_title(title)\n        axeslist.ravel()[idx].set_axis_off()\n    fig.suptitle(r'Median nighttime light level [$Wcm^{-2}sr^{-1}$]', fontsize=20)\n    #plt.tight_layout() \n\n    \n\nplot_figures(sorted_dict, 4, 2, clip_range=(0,1), factor=100./255.)\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#visualizing-input-data","position":17},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Applying color blending","lvl2":"Creating nighttime light maps with color blending"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#applying-color-blending","position":18},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Applying color blending","lvl2":"Creating nighttime light maps with color blending"},"content":"\n\nAdditive color blending involves mixing the primary colors of light, red (R), green (G), and blue (B), while adjusting their luminance levels. By manipulating the luminance of these colors, a wide range of hues can be achieved, with the key characteristic being that combining all three colors results in white.\n\nTechnique\n\nmaximum pixel value of images for 2019 (brightest pixel values) is assigned to red (R)\n\nminimum pixel value of images for 2020-2021 (darkest pixel values) is assigned to green (G)\n\nmaximum pixel value of images for 2022 (brightest pixel values) is assigned to blue (B)\n\nOutput\n\nregions where a decrease in nighttime light level occurred are displayed in red\n\nareas that experienced an increase (presumed to indicate an increase in social activity) are shown in blue\n\nregions where there was no significant change throughout the pandemic are displayed in a gradient from gray to white.\n\npattern = re.compile(r\"h(\\d+)v(\\d+)_(\\d{4})_(\\d)H_median\\.tif\")\n\n\ndef read_and_preprocess(file):\n    with rasterio.open(file) as src:\n        img = src.read(1)\n        img = np.nan_to_num(img, nan=0)  # Replace NaNs with zeros\n        return img, src.profile\n\n    \ndef additive_blending(grouped_files):\n    # Process each group of files for blending\n    for (h, v), file_group in grouped_files.items():\n        # Initialize arrays to store the maximum and minimum values for each year\n        max_2019 = None\n        min_2020_2021 = None\n        max_2022 = None\n        \n        for year, H, file in file_group:\n            img, profile = read_and_preprocess(file)\n            \n            if year == '2019':\n                if max_2019 is None:\n                    max_2019 = img\n                else:\n                    max_2019 = np.maximum(max_2019, img)\n            elif year in ['2020', '2021']:\n                if min_2020_2021 is None:\n                    min_2020_2021 = img\n                else:\n                    min_2020_2021 = np.minimum(min_2020_2021, img)\n            elif year == '2022':\n                if max_2022 is None:\n                    max_2022 = img\n                else:\n                    max_2022 = np.maximum(max_2022, img)\n                                  \n    # Create the blended image using the specified blending technique\n    blended_img = np.zeros((max_2019.shape[0], max_2019.shape[1], 3), dtype=np.float32)\n    blended_img[:, :, 0] = max_2019.astype(np.float32)  # Red band: maximum of 2019\n    blended_img[:, :, 1] = min_2020_2021.astype(np.float32)  # Green band: minimum of 2020-2021 compared\n    blended_img[:, :, 2] = max_2022.astype(np.float32)  # Blue band: maximum of 2022\n    \n    return blended_img, profile        \n\n# Grouping files per (h,v) tiles and years span\ngrouped_files = {}\nfor root, _, files in os.walk(input_path):\n    \n    \n    # Group files by h and v\n    for file in files:\n        match = pattern.match(file)\n        if match:\n            h, v, year, H = match.groups()\n            key = (h, v)\n            if key not in grouped_files:\n                grouped_files[key] = []\n            grouped_files[key].append((year, H, os.path.join(root, file)))\n\n\n# blending           \nblended_img, profile = additive_blending(grouped_files)\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#applying-color-blending","position":19},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Employing ‚Äúurban‚Äù stretch processing","lvl2":"Creating nighttime light maps with color blending"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#employing-urban-stretch-processing","position":20},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Employing ‚Äúurban‚Äù stretch processing","lvl2":"Creating nighttime light maps with color blending"},"content":"\n\nThe purpose of the stretch processing is to emphasize the nighttime light level of each band (corresponding to 2019, 2020-21, and 2022), focusing on:\n\n‚Äúurban‚Äù nighttime light levels: the display range of each band is adjusted to 25-1000 [watts¬∑cm-2¬∑sr-1], emphasizing brighter areas\n\n# Urban stretch processing: Emphasize brighter areas\ndef urban_stretch_processing(band):\n    min_val = 25\n    max_val = 1000\n    band = np.clip(band, min_val, max_val)\n    band = (band - min_val) / (max_val - min_val) * 255\n    return band.astype(np.uint8)\n\n# Apply urban stretch processing to each band\nblended_img[:, :, 0] = urban_stretch_processing(blended_img[:, :, 0])\nblended_img[:, :, 1] = urban_stretch_processing(blended_img[:, :, 1])\nblended_img[:, :, 2] = urban_stretch_processing(blended_img[:, :, 2])\n        \n# Update the profile for a 3-band image and set nodata value to None\nprofile.update(count=3, dtype=rasterio.uint8, nodata=None)\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#employing-urban-stretch-processing","position":21},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Plotting blended image","lvl2":"Creating nighttime light maps with color blending"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#plotting-blended-image","position":22},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Plotting blended image","lvl2":"Creating nighttime light maps with color blending"},"content":"\n\ndef plot_image(image, factor=1.0, clip_range = None, **kwargs):\n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n    if clip_range is not None:\n        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n    else:\n        ax.imshow(image * factor, **kwargs)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n\nplot_image(blended_img, factor=1.5/255., clip_range=(0,1))\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#plotting-blended-image","position":23},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Overlaying with an interactive map","lvl2":"Creating nighttime light maps with color blending"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#overlaying-with-an-interactive-map","position":24},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Overlaying with an interactive map","lvl2":"Creating nighttime light maps with color blending"},"content":"\n\nSaving blended image as Cloud Optimized GeoTIFF\n\n# Exporting output as COG file \nres_name = f\"Nighttimelevel_Urban_{grid_tile}_2019-2022.tif\"\noutput_cog = os.path.join(urban_path, res_name)\n\n\n# Write the blended image directly to a temporary file\nwith tempfile.NamedTemporaryFile(suffix=\".tif\") as temp_file:\n    with rasterio.open(temp_file.name, \"w\", **profile) as dst:\n        dst.write(blended_img[:, :, 0], 1)\n        dst.write(blended_img[:, :, 1], 2)\n        dst.write(blended_img[:, :, 2], 3)\n\n    subprocess.run([\n        \"gdal_translate\", \"-of\", \"COG\",\n        \"-co\", \"COMPRESS=DEFLATE\",\n        \"-co\", \"BLOCKSIZE=512\",\n        \"-co\", \"RESAMPLING=NEAREST\",\n        \"-co\", \"OVERVIEWS=IGNORE_EXISTING\",\n        temp_file.name,\n        output_cog\n    ])\n\nprint(f\"COG file saved as {output_cog}\")\n\nExtracting bounding-box coordinates\n\np1 = Popen([\"gdalinfo\", \"-json\", output_cog, \"-mm\"], stdout=PIPE)\noutput = p1.communicate()[0]\ndec_out = output.decode('utf-8')\nj_str = json.loads(dec_out)\nbbox = j_str['cornerCoordinates']\nll = bbox['lowerLeft']  # SW coo\nur = bbox['upperRight'] # NE coo\ncenter = bbox['center']\n\nAdding alpha channel to the blended image\n\ndef almostEquals(a,b,thres=50):\n    return all(abs(a[i]-b[i])<thres for i in range(len(a)))\n\n\nimage = Image.open(output_cog).convert('RGBA')\npixeldata = list(image.getdata())\n\n\nfor i,pixel in enumerate(pixeldata):\n    if almostEquals(pixel[:3], (0,0,0)):\n        pixeldata[i] = (0,0,0,0)\n\n\nimage.putdata(pixeldata)\npng_path = os.path.join(urban_path, res_name.replace(\".tif\",\".png\"))\nres = image.save(png_path)\n#os.path.abspath(res)\nabs_path = os.path.abspath(png_path)\nwork_dir = os.getcwd()\nid_ = work_dir.split('/')[2]\nbase_url = os.path.join('https://hub.eox.at/user',id_,'files')\n#base_url\nabs_path = '/'.join(abs_path.split('/')[3:])\nprint(abs_path)\nprint(base_url)\n#abs_path\nprint(os.path.join(base_url,abs_path))\n\n\nOverlay with OpenStreetMap\n\nm = Map(basemap=basemaps.CartoDB.DarkMatter, center=(center[1], center[0]), zoom=6)\nosm_url = os.path.join(base_url,abs_path)\nimage = ImageOverlay(\n        url=osm_url, #url=\"https://hub.eox.at/user/<id>/files/<path_to_png>\n        bounds=((ll[1], ll[0]), (ur[1], ur[0])) # SW and NE corners\n                    )\nm.add_layer(image);\nm\n\nUsing additive color blending images to focus on urban areas in India, in particular the North-West part comprising New Delhi, Jaipur, Agra, Gwalior, ...\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#overlaying-with-an-interactive-map","position":25},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Alternative stretch processing approaches","lvl2":"Creating nighttime light maps with color blending"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#alternative-stretch-processing-approaches","position":26},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Alternative stretch processing approaches","lvl2":"Creating nighttime light maps with color blending"},"content":"\n\n‚ÄúRural‚Äù nighttime light levels: setting each band‚Äôs display range to 0-50 [Watts¬∑cm-2¬∑sr-1] to emphasize darker areas\n\nFor a broader focus (from rural to urban areas): applying a log10 transformation to the values of each band with a display range set to 0-3.6 (equivalent to 0-3981 [Watts¬∑cm-2¬∑sr-1])\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#alternative-stretch-processing-approaches","position":27},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Final remarks","lvl2":"Creating nighttime light maps with color blending"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#final-remarks","position":28},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"Final remarks","lvl2":"Creating nighttime light maps with color blending"},"content":"\n\nThis product has been specifically designed for utilization by researchers in applied scientific fields.\nPotential applications are being explored in environmental and social issue studies, such as:\n\ndisaster recovery\n\nenergy\n\nurban land use changes\n\nconflicts\n\nmigration\n\nmonitoring of illegal, unreported activities\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#final-remarks","position":29},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"To learn more","lvl2":"Creating nighttime light maps with color blending"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#to-learn-more","position":30},{"hierarchy":{"lvl1":"USE CASE 1: Nighttime Lights","lvl3":"To learn more","lvl2":"Creating nighttime light maps with color blending"},"content":"\n\nThe presented approach is often referenced in scientific and public health research. For example, Bunpei Tojo (2021) used Nightlights data in the study ‚ÄúApplication of Earth observation satellite data to public health: Comparison of night light (VIIRS) and solar radiation (SGLI) and domestic COVID-19 epidemic,‚Äù presented at the 12th Federation of Science and Technology conference, to analyze the relationship between nighttime light intensity and public health factors.\n\n\nÊù±Âüé (2021).\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#to-learn-more","position":31},{"hierarchy":{"lvl1":"USE CASE 2: Air Pollution"},"type":"lvl1","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-case-2-air-pollution","position":32},{"hierarchy":{"lvl1":"USE CASE 2: Air Pollution"},"content":"","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-case-2-air-pollution","position":33},{"hierarchy":{"lvl1":"USE CASE 2: Air Pollution","lvl2":"Monitoring NO2 concentrations over Northern India"},"type":"lvl2","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#monitoring-no2-concentrations-over-northern-india","position":34},{"hierarchy":{"lvl1":"USE CASE 2: Air Pollution","lvl2":"Monitoring NO2 concentrations over Northern India"},"content":"\n\nAir quality is poor across India, but especially poor in Northern India due to a mix of human activity and seasonal weather conditions:\n\nVehicle emissions: The city‚Äôs high population density results in heavy traffic and significant pollution from older and poorly maintained vehicles. Increased investment in mass transportation and stricter fuel efficiency enforcement could help mitigate these issues in future.\n\nIndustrial and construction dust: Industrial operations and ongoing construction projects release fine particulate matter into the air.\n\nHome heating: Coal, firewood, and diesel generator use can contribute to poor air quality.\n\nWeather patterns: Chillier temperatures, low wind speeds, and heavy air trap pollutants close to the ground during colder months, worsening smog.\n\nCrop stubble burning: Farmers in neighboring states including Bihar, Haryana, and Uttar Pradesh burn agricultural waste, contributing to particulate pollution\n\nCombined, these factors create a toxic atmosphere. Air quality is particularly dangerous during the winter months, when weather conditions exacerbate pollution.\n\n\n\nIn particular, Delhi and large parts of North India experienced a significant air quality crisis towards the end of 2024, with air quality reaching the ‚ÄúSevere‚Äù and ‚ÄúHazardous‚Äù categories, leading to the implementation of pollution control measures like Graded Response Action Plan 3 (GRAP 3). The air quality deterioration was caused by factors like high humidity, low wind speeds, and continued agricultural burning, which trapped fine particulate matter (PM2.5) in the atmosphere. This resulted in a public health emergency, with extreme pollution posing serious health risks, especially to children and the elderly, and leading to health advisories, school closures, and even flight diversions.\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#monitoring-no2-concentrations-over-northern-india","position":35},{"hierarchy":{"lvl1":"USE CASE 2: Air Pollution","lvl3":"Visualizing the AoI (Gurugram, South-West of New Delhi)","lvl2":"Monitoring NO2 concentrations over Northern India"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#visualizing-the-aoi-gurugram-south-west-of-new-delhi","position":36},{"hierarchy":{"lvl1":"USE CASE 2: Air Pollution","lvl3":"Visualizing the AoI (Gurugram, South-West of New Delhi)","lvl2":"Monitoring NO2 concentrations over Northern India"},"content":"\n\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\nimport subprocess\nimport json\nimport requests\nimport pandas as pd\nimport os \nimport IPython.display\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\n# Sentinel Hub\nfrom sentinelhub import (SHConfig, DataCollection, Geometry, BBox, CRS, SentinelHubCatalog,\n                         SentinelHubRequest, filter_times, bbox_to_dimensions, MimeType, \n                         SentinelHubBYOC, ByocCollection, ByocTile, ByocCollectionAdditionalData,\n                         DownloadFailedException, CRS, SentinelHubStatistical)\n\n# Gurugram coordinates\ntop_left_x =  76.9602268594042\ntop_left_y = 28.5355222251629\nbottom_right_x = 77.11128887112295 \nbottom_right_y = 28.394875392026698\n\nbbox = [   \n  top_left_x,\n  bottom_right_y,\n  bottom_right_x,\n  top_left_y\n        ]\n\n# Bbox EPSG\nbbox_epsg = 4326\n\n# Plotting the bounding box on a map\n\nIPython.display.GeoJSON(BBox(bbox,crs=bbox_epsg).get_geojson())\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#visualizing-the-aoi-gurugram-south-west-of-new-delhi","position":37},{"hierarchy":{"lvl1":"USE CASE 2: Air Pollution","lvl3":"Use SH statistical API request to access NO2 data for the selected AoI","lvl2":"Monitoring NO2 concentrations over Northern India"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-sh-statistical-api-request-to-access-no2-data-for-the-selected-aoi","position":38},{"hierarchy":{"lvl1":"USE CASE 2: Air Pollution","lvl3":"Use SH statistical API request to access NO2 data for the selected AoI","lvl2":"Monitoring NO2 concentrations over Northern India"},"content":"\n\nThe Statistical API (or shortly ‚ÄúStats API‚Äù) enables you to get statistics calculated based on satellite imagery without having to download images.\nIn your Statistical API request, you can specify:\n\narea of interest (AoI)\n\ntime period\n\nevalscript\n\ndata collection\n\nstatistics to be calculated\n\nThe requested statistics are returned in the API response. Further details are to be found on the corresponding \n\nSH documentation.\n\nbbox = [   \n  top_left_x,\n  top_left_y,\n  bottom_right_x,\n  bottom_right_y,\n        ]\n\ndata_collection = \"byoc-972e67a7-2ca8-4bf6-964a-11fe772e3ac2\"\ndate_from = \"2024-11-01T00:00:00.000Z\"\ndate_to = \"2025-02-28T00:00:00.000Z\"\n\ndata_req = {\n  \"input\": {\n    \"bounds\": {\n      \"bbox\": bbox\n    },\n    \"data\": [\n      {\n        \"dataFilter\": {},\n        \"type\": data_collection\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"evalscript\": \"//VERSION=3\\nfunction setup() {\\n    return {\\n      input: [{\\n        bands: [\\n          \\\"tropno2\\\",\\n          \\\"dataMask\\\"\\n        ]\\n      }],\\n      output: [\\n        {\\n          id: \\\"data\\\",\\n          bands: 1,\\n          sampleType: \\\"FLOAT32\\\"\\n        },\\n        {\\n          id: \\\"dataMask\\\",\\n          bands: 1\\n        }\\n      ]\\n    }\\n  }\\n  function evaluatePixel(samples) {\\n    let validValue = 1\\n    // data sanitation\\n    if (samples.tropno2 >= 1e20 ){\\n        validValue = 0\\n    }\\n    let index = samples.tropno2;\\n    return {\\n      data:  [index],\\n      dataMask: [samples.dataMask * validValue]\\n    }\\n  }\\n\",\n    \"timeRange\": {\n      \"from\": date_from,\n      \"to\": date_to\n    },\n    \"aggregationInterval\": {\n      \"of\": \"P1D\"\n    },\n    \"width\": 100,\n    \"height\": 100\n  },\n  \"calculations\": {\n    \"default\": {}\n  }\n}\n\n\n# Creating a session\n\n# OAuth Client configuration\nclient_id = os.environ.get(\"SH_CLIENT_ID\")\nclient_secret = os.environ.get(\"SH_CLIENT_SECRET\") \n\nclient = BackendApplicationClient(client_id=client_id)\noauth = OAuth2Session(client=client)\n\n# Get token for the session\ntoken = oauth.fetch_token(token_url='https://services.sentinel-hub.com/oauth/token',\n                          client_secret=client_secret)\n\nresp = oauth.post(\"https://services.sentinel-hub.com/api/v1/statistics\",\n                  headers={\"Accept\":\"application/json\",\"Content-Type\":\"application/json\"},\n                  json=data_req)\n#print(resp.status_code, resp.text)\n\n\n# Extracting stats from timeseries within the specified time interval\ndata_r = resp.json() # parsing response to json\ntime_axis = [datetime.strptime(entry[\"interval\"][\"from\"], \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y/%m/%d\") for entry in data_r[\"data\"]]\nmeans = [float(entry['outputs']['data']['bands']['B0']['stats']['mean']) for entry in data_r[\"data\"]]\nstd_devs = [float(entry['outputs']['data']['bands']['B0']['stats']['stDev']) for entry in data_r[\"data\"]]\nstd_upper = [m+s for (m,s) in zip(means, std_devs)]\nstd_lower = [m-s for (m,s) in zip(means, std_devs)]\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-sh-statistical-api-request-to-access-no2-data-for-the-selected-aoi","position":39},{"hierarchy":{"lvl1":"USE CASE 2: Air Pollution","lvl3":"Plotting the statistics for the NO2 timeseries","lvl2":"Monitoring NO2 concentrations over Northern India"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#plotting-the-statistics-for-the-no2-timeseries","position":40},{"hierarchy":{"lvl1":"USE CASE 2: Air Pollution","lvl3":"Plotting the statistics for the NO2 timeseries","lvl2":"Monitoring NO2 concentrations over Northern India"},"content":"\n\nfig = plt.figure(figsize=(20,10))\n# plot mean values \nplt.plot(time_axis, means, linestyle='solid', linewidth=2, color=\"black\", label=\"Mean Tropospheric NO2 values [umol/ m^2]\")\n\n# plot standard deviation error bars\nplt.errorbar(time_axis, means, yerr=std_devs, linestyle=\"-\")\n\nplt.title('Tropospheric NO2 Values over the AOI')\nplt.legend()\nfig.autofmt_xdate()\n\n# Saving plot\noutput_no2 = \"output\"\noutput_no2_path = os.path.join(os.getcwd(), \"Air_pollution\", output_no2)\nos.makedirs(output_no2_path, exist_ok=True)\nplt.savefig(os.path.join(output_no2_path, 'NO2_Gurugram.png'))\n\nplt.show()\n\nThe plot shows a spike in NO2 concentration over Gurugram in December 2024, when the significant air quality crisis in Northern India has been reported.\nIn particular, it can be noticed that the standard deviation starts increasing over this month with respect to the preceding and subsequent  time interval.\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#plotting-the-statistics-for-the-no2-timeseries","position":41},{"hierarchy":{"lvl1":"USE CASE 3: HEATWAVES"},"type":"lvl1","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-case-3-heatwaves","position":42},{"hierarchy":{"lvl1":"USE CASE 3: HEATWAVES"},"content":"","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-case-3-heatwaves","position":43},{"hierarchy":{"lvl1":"USE CASE 3: HEATWAVES","lvl2":"Analyzing Land Surface Temperature with GCOM-C ‚ÄòShikisai‚Äô Satellite Data"},"type":"lvl2","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#analyzing-land-surface-temperature-with-gcom-c-shikisai-satellite-data","position":44},{"hierarchy":{"lvl1":"USE CASE 3: HEATWAVES","lvl2":"Analyzing Land Surface Temperature with GCOM-C ‚ÄòShikisai‚Äô Satellite Data"},"content":"In this use case, we will explore GCOM (Global Change Observation Mission) satellite data to analyze Land Surface Temperature (LST). Specifically, we‚Äôll look at data from the GCOM-C satellite, which is part of the Japan Aerospace Exploration Agency‚Äôs (JAXA) efforts to monitor global climate change. GCOM-C provides valuable information on various environmental factors, including temperature, vegetation, and water bodies, through its thermal infrared sensors.\n\nOur focus will be on studying the heatwave that occurred in New Delhi, India, in 2024. In particular, the city experienced a significant temperature surge during the peak summer months. The temperature exceeded 45¬∞C (113¬∞F), causing severe disruptions to daily life, and raising concerns about the increasing frequency and intensity of heatwaves due to climate change.\n\nBy analyzing GCOM-C‚Äôs satellite data, we can better understand the spatial distribution of land surface temperature during that period, as well as any emerging patterns that might indicate more frequent or severe heat events in the future.\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#analyzing-land-surface-temperature-with-gcom-c-shikisai-satellite-data","position":45},{"hierarchy":{"lvl1":"USE CASE 3: HEATWAVES","lvl3":"3.1 Import libraries","lvl2":"Analyzing Land Surface Temperature with GCOM-C ‚ÄòShikisai‚Äô Satellite Data"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-1-import-libraries","position":46},{"hierarchy":{"lvl1":"USE CASE 3: HEATWAVES","lvl3":"3.1 Import libraries","lvl2":"Analyzing Land Surface Temperature with GCOM-C ‚ÄòShikisai‚Äô Satellite Data"},"content":"\n\nimport geopandas as gpd\nimport rasterio\nfrom rasterio.mask import mask\nimport matplotlib.pyplot as plt\nfrom osgeo import gdal\nimport requests\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom osgeo import gdal\nfrom matplotlib.colors import LinearSegmentedColormap\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-1-import-libraries","position":47},{"hierarchy":{"lvl1":"USE CASE 3: HEATWAVES","lvl3":"3.2 About the data: storage and access","lvl2":"Analyzing Land Surface Temperature with GCOM-C ‚ÄòShikisai‚Äô Satellite Data"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-2-about-the-data-storage-and-access","position":48},{"hierarchy":{"lvl1":"USE CASE 3: HEATWAVES","lvl3":"3.2 About the data: storage and access","lvl2":"Analyzing Land Surface Temperature with GCOM-C ‚ÄòShikisai‚Äô Satellite Data"},"content":"FIND DATA LOCATION: To find where a data is stored, one can search throught the EODash \n\nhttps://‚Äãgithub‚Äã.com‚Äã/ESA‚Äã-eodashboards‚Äã/eodashboard‚Äã-catalog‚Äã/tree‚Äã/80bde3aac691e00edb963b785385056709dd18b4‚Äã/collections\n\nDATA STORED AT WASABI:  Our data is located at the following url \n\nhttps://‚Äãs3‚Äã.ap‚Äã-northeast‚Äã-1‚Äã.wasabisys‚Äã.com‚Äã/je‚Äã-pds‚Äã/cog‚Äã/v1‚Äã/JAXA‚Äã.G‚Äã-Portal‚Äã_GCOM‚Äã-C‚Äã.SGLI‚Äã_standard‚Äã.L3‚Äã-LST‚Äã.daytime‚Äã.v3‚Äã_global‚Äã_monthly‚Äã/2024‚Äã-07‚Äã/1‚Äã/E000‚Äã.00‚Äã-E090‚Äã.00‚Äã/E000‚Äã.00‚Äã-N00‚Äã.00‚Äã-E090‚Äã.00‚Äã-N90‚Äã.00‚Äã-LST‚Äã.tiff\". This URL is hosted on Wasabi, a cloud storage service, which is known for providing affordable, high-performance cloud storage for large datasets, often used in scientific research or data-heavy projects. Wasabi is not affiliated to JAXA, provides does not charge for API requests. Wasabi‚Äôs object storage service is built to be 100% bit-compatible with AWS S3.\n\n\n\nABOUT DATASET: The LST (Land Surface Temperature) data file corresponds to the daytime measurements taken by the SGLI sensor. It‚Äôs a monthly global dataset for July 2024, indicating this is a time-series observation over a large area. To interpret the naming convention of the data: it contains the name of the variable, the month/year it is averaging and the represent the spatial coordinates of the bounding box it covers (0¬∞ to 90¬∞ East and 0¬∞ to 90¬∞ North).\n\n\n\nGCOM-C 'Shikisai'. Credit: JAXA\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-2-about-the-data-storage-and-access","position":49},{"hierarchy":{"lvl1":"USE CASE 3: HEATWAVES","lvl3":"3.3 A first look at the dataset","lvl2":"Analyzing Land Surface Temperature with GCOM-C ‚ÄòShikisai‚Äô Satellite Data"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-3-a-first-look-at-the-dataset","position":50},{"hierarchy":{"lvl1":"USE CASE 3: HEATWAVES","lvl3":"3.3 A first look at the dataset","lvl2":"Analyzing Land Surface Temperature with GCOM-C ‚ÄòShikisai‚Äô Satellite Data"},"content":"\n\n# Location of URL stored on Wasabi \nurl = \"https://s3.ap-northeast-1.wasabisys.com/je-pds/cog/v1/JAXA.G-Portal_GCOM-C.SGLI_standard.L3-LST.daytime.v3_global_monthly/2024-07/1/E000.00-E090.00/E000.00-N00.00-E090.00-N90.00-LST.tiff\"\n# Downloads the file from the URL\nresponse = requests.get(url)\n# Saves file locally \nwith open(\"Heatwaves/LST.tiff\", \"wb\") as f:\n    f.write(response.content)\n\n# Opening the file with GDAL (library for geospatial raster data)\nds = gdal.Open(\"Heatwaves/LST.tiff\")\n# Gests the first (and in this case) only band refering to LST.\nband = ds.GetRasterBand(1)\n#Reads the raster into a NumPy array (a sort of matrix)\narr = band.ReadAsArray().astype(float)\n\n# Plotting\nimport matplotlib.pyplot as plt\nplt.imshow(arr, cmap=\"viridis\")\nplt.colorbar()\nplt.title(\"LST\")\nplt.show()\n\nprint(' - - - ')\nprint('More information about the dataset:')\nprint(' - - - ')\nprint(ds.GetProjection(), ds.GetGeoTransform())\n\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-3-a-first-look-at-the-dataset","position":51},{"hierarchy":{"lvl1":"USE CASE 3: HEATWAVES","lvl3":"3.4 Cropping to Area of Interest (Northern India) and converting to Celcisus Degrees","lvl2":"Analyzing Land Surface Temperature with GCOM-C ‚ÄòShikisai‚Äô Satellite Data"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-4-cropping-to-area-of-interest-northern-india-and-converting-to-celcisus-degrees","position":52},{"hierarchy":{"lvl1":"USE CASE 3: HEATWAVES","lvl3":"3.4 Cropping to Area of Interest (Northern India) and converting to Celcisus Degrees","lvl2":"Analyzing Land Surface Temperature with GCOM-C ‚ÄòShikisai‚Äô Satellite Data"},"content":"The JAXA GCOM-C SGLI L3 LST had a 0.02 scalling factor and was in Kelvin.\n\nSo, we will convert it to degree celcius and ‚Äòcrop‚Äô the whole image to Northern India\n\n# Now we mask invalid or unrealistic values (sometimes satellite have artifacts or other issues that render the value of a pixel wrong)\narr[(arr <= 0) | (arr > 35000)] = np.nan\n\n# Re-scale and convert from Kelvin to Celsius\narr_c = arr * 0.02 - 273.15  \n\n# GeoTransform is a GDAL function that helps map between the raster coordinates and georeference coordinates\n# In other words it is converting geographic coordinates (lat, lon) into pixel coordinates of our matrix (X, y)\ngt = ds.GetGeoTransform()\ndef latlon_to_pixel(lat, lon, gt):\n    px = int((lon - gt[0]) / gt[1])\n    py = int((lat - gt[3]) / gt[5])\n    return px, py\n\n# Now we use this function to get the pixel coordinates of an area around Northern India \nlon_min, lon_max = 70, 90\nlat_min, lat_max = 20, 37\npx_min, py_max = latlon_to_pixel(lat_min, lon_min, gt)\npx_max, py_min = latlon_to_pixel(lat_max, lon_max, gt)\n# 'Bounding box of northern India'\narr_crop_india = arr_c[py_min:py_max, px_min:px_max]\n\n# We do the same for New Dehli\nlon_min, lon_max = 76.8, 77.5\nlat_min, lat_max = 28.4, 28.9\npx_min2, py_max2 = latlon_to_pixel(lat_min, lon_min, gt)\npx_max2, py_min2 = latlon_to_pixel(lat_max, lon_max, gt)\narr_crop_delhi = arr_c[py_min2:py_max2, px_min2:px_max2]\n\n# Selecting the color scheme \ncmap = \"plasma\"  # üî¥Change to other color schemes: 'inferno', 'cividis', 'jet'\n\n# Settlings to ensure we have 2 plots, side by side\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\nvmin, vmax = 27, 50  #üî¥can change here the max and min values for improved interpration\n\n# \nim1 = axes[0].imshow(arr_crop_india, cmap=cmap, vmin=vmin, vmax=vmax)\naxes[0].set_title(\"LST (¬∞C) - Northern India\")\ncbar1 = fig.colorbar(im1, ax=axes[0], orientation=\"horizontal\", fraction=0.046, pad=0.08)\ncbar1.set_label(\"LST (¬∞C)\")\n\n# Mark New Delhi on Northern India map\ndelhi_lat, delhi_lon = 28.61, 77.21\npx_delhi, py_delhi = latlon_to_pixel(delhi_lat, delhi_lon, gt)\npx_delhi_rel = px_delhi - px_min\npy_delhi_rel = py_delhi - py_min\naxes[0].scatter(px_delhi_rel, py_delhi_rel, color=\"red\", s=40, marker=\"o\")\naxes[0].text(px_delhi_rel + 5, py_delhi_rel - 5, \"New Delhi\", color=\"white\",\n             fontsize=10, weight=\"bold\", backgroundcolor=\"black\")\n\n# Plot now \nim2 = axes[1].imshow(arr_crop_delhi, cmap=cmap, vmin=vmin, vmax=vmax)\naxes[1].set_title(\"LST (¬∞C) - New Delhi (Cropped and zoomed it)\")\ncbar2 = fig.colorbar(im2, ax=axes[1], orientation=\"horizontal\", fraction=0.046, pad=0.08)\ncbar2.set_label(\"LST (¬∞C)\")\n\nplt.tight_layout()\nplt.show()\n\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-4-cropping-to-area-of-interest-northern-india-and-converting-to-celcisus-degrees","position":53},{"hierarchy":{"lvl1":"USE CASE 3: HEATWAVES","lvl3":"3.5 Identifying locations where Heatwave has occured in June 2024","lvl2":"Analyzing Land Surface Temperature with GCOM-C ‚ÄòShikisai‚Äô Satellite Data"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-5-identifying-locations-where-heatwave-has-occured-in-june-2024","position":54},{"hierarchy":{"lvl1":"USE CASE 3: HEATWAVES","lvl3":"3.5 Identifying locations where Heatwave has occured in June 2024","lvl2":"Analyzing Land Surface Temperature with GCOM-C ‚ÄòShikisai‚Äô Satellite Data"},"content":"Applying a threshold (temperature limit from which it‚Äôs considered to be a ‚Äòheatwave‚Äô)\n\nimport matplotlib.patches as patches\nimport matplotlib.colors as mcolors\n\n# Start with the plasma colormap\nbase_cmap = plt.cm.plasma\nnewcolors = base_cmap(np.linspace(0, 1, 256))\n\n# Make the last part of the colormap black (for >45 ¬∞C)\nnewcolors[-1, :] = [0, 0, 0, 1]  \ncmap = mcolors.ListedColormap(newcolors)\n\n# Setting the figure plot specifications \nfig, ax = plt.subplots(figsize=(12, 9)) \nvmin, vmax = 27, 40  # we extend vmax to allow space for black (>45 ¬∞C)\nim = ax.imshow(arr_crop_india, cmap=cmap, vmin=vmin, vmax=vmax)\n\n# Add colorbar\ncbar = fig.colorbar(im, ax=ax, orientation=\"horizontal\", fraction=0.046, pad=0.08)\ncbar.set_label(\"LST (¬∞C)\")\n\n# Label explaining the threshold\ncbar.ax.text(0.5, -0.5, \">45¬∞C = black\", color=\"black\",\n             fontsize=12, ha='center', va='center', transform=cbar.ax.transAxes)\n\nax.set_title(\"LST (¬∞C) July Average Land Surface Temperates in Northern India\", fontsize=16)\n\n# Adding the coordinates of New Delhi again\ndelhi_lat, delhi_lon = 28.61, 77.21\npx_delhi, py_delhi = latlon_to_pixel(delhi_lat, delhi_lon, gt)\npx_delhi_rel = px_delhi - px_min\npy_delhi_rel = py_delhi - py_min\n\n# Adding a red X at New Delhi\nax.scatter(px_delhi_rel, py_delhi_rel, color=\"red\", s=100, marker=\"X\")\n\n# Adding a big red circle around New Delhi\ncircle = patches.Circle((px_delhi_rel, py_delhi_rel), radius=40,\n                        edgecolor='red', facecolor='none', linewidth=2.5)\nax.add_patch(circle)\n\n# Label for New Delhi\nax.text(px_delhi_rel + 50, py_delhi_rel - 15, \"New Delhi\",\n        color=\"white\", fontsize=10, weight=\"bold\", backgroundcolor=\"black\")\n\nplt.tight_layout()\nplt.show()\n\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-3-5-identifying-locations-where-heatwave-has-occured-in-june-2024","position":55},{"hierarchy":{"lvl1":"USE CASE 4: URBAN HEALTH"},"type":"lvl1","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-case-4-urban-health","position":56},{"hierarchy":{"lvl1":"USE CASE 4: URBAN HEALTH"},"content":"\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#use-case-4-urban-health","position":57},{"hierarchy":{"lvl1":"USE CASE 4: URBAN HEALTH","lvl3":"4.1. Import libraries"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-1-import-libraries","position":58},{"hierarchy":{"lvl1":"USE CASE 4: URBAN HEALTH","lvl3":"4.1. Import libraries"},"content":"\n\n!pip install fastkml shapely\n!pip install pykml\n\nimport requests\nfrom IPython.display import Image\nimport mercantile\n\nfrom io import BytesIO\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\n\nimport mercantile\nimport numpy as np\nfrom shapely.geometry import Polygon, Point\nfrom pykml import parser\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-1-import-libraries","position":59},{"hierarchy":{"lvl1":"USE CASE 4: URBAN HEALTH","lvl3":"4.2. About the data: storage and access"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-2-about-the-data-storage-and-access","position":60},{"hierarchy":{"lvl1":"USE CASE 4: URBAN HEALTH","lvl3":"4.2. About the data: storage and access"},"content":"DATA LOCATION: Since this is on \n\nNASA VEDA data - which is a open-source cyberinfrascture for data processing, visualization, exploration, and geographic information system (GIS) capabilties allows researchs to explore and analyze Earth science data in the cloud. This dataset, is physically stored in the veda-data-store S3 bucket.\n\n\n\nABOUT DATA METADATA & ACCESS: It is STAC (SpatioTemporal Asset Catalog) wich is a specification aimed to standardize the way geospatial asset metadata is strucutred and queried, estalbishing a standadd scheme and queryable. It is a metadata/catalog layer describing the dataset, making it easier to search and access. The access itself can be done through multiple ways:\n\n\n\nBrowsed via STAC Browser (web-based browsing interface) - (aceess at \n\nhttps://‚Äãradiantearth‚Äã.github‚Äã.io‚Äã/stac‚Äã-browser‚Äã/‚Äã#‚Äã/‚Äã?‚Äã.language‚Äã=en)\n\nUset STAC API (programmatic access) - STAC API allows to programmatically searcg/filter, and access STAC using code, rather than clicking through a web interface.\n\nDiect S3 access (for AWS-hostet data) - this means you can access the actuall files directly stored in S3 buckets withouth going through STAC browser or API interfaces\n\nDownloading it locally (if there is no need of authenticatio via S3)\n\n5)...or\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-2-about-the-data-storage-and-access","position":61},{"hierarchy":{"lvl1":"USE CASE 4: URBAN HEALTH","lvl3":"4.2. Query the collection"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-2-query-the-collection","position":62},{"hierarchy":{"lvl1":"USE CASE 4: URBAN HEALTH","lvl3":"4.2. Query the collection"},"content":"Before Processing, we can do some ‚Äòreconnaissance‚Äô: understanding what data is available before you start working with it.\n\nfrom PIL import Image\n# Get all items in the GRDI STAC Collection\nitems_url = \"https://openveda.cloud/api/stac/collections/grdi-v1-raster/items\"\nresponse = requests.get(items_url)\nitems = response.json()\n\nprint(f\"Found {len(items['features'])} item(s)\")\n\n# Preview the first item\nfirst_item = items[\"features\"][0]\nprint(\"Item ID:\", first_item[\"id\"])\nprint(\"Available assets:\")\nfor asset_name, asset in first_item[\"assets\"].items():\n    print(f\"  - {asset_name}: {asset['href']}\")\n\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\n\nthumbnail_url = \"https://thumbnails.openveda.cloud/grdi--dataset-cover.jpg\"\nresponse = requests.get(thumbnail_url)\nimg = Image.open(BytesIO(response.content))\nimg.show()  # Opens in image viewer\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-2-query-the-collection","position":63},{"hierarchy":{"lvl1":"USE CASE 4: URBAN HEALTH","lvl3":"4.3. Query the collection"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-3-query-the-collection","position":64},{"hierarchy":{"lvl1":"USE CASE 4: URBAN HEALTH","lvl3":"4.3. Query the collection"},"content":"Some datasets may need registration or have usage agreements, so it might not be a straightforward process to access S3 AWS buckets - which can lead to error 403.\n\nIn this case if we do not have permission we can convert the COG available on the link we descovered earlier into web map tiles, so it means VEDA API handles S3 authentication.\n\nThe tile URL requests a small square of the GRDI map from Veda‚Äôs server, using zoom (z) and grid (x, y) coordinates in Web Mercator. Veda reads only the needed pixels from the large Cloud Optimized GeoTIFF (COG), applies the colormap, and sends it as an image‚ÄîCOG makes this efficient by allowing partial reads without loading the entire dataset.\n\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport mercantile\n\n# Coordinates over India\nlon, lat = 78.96, 20.59\nzoom = 3   ## üî¥Change here zoom\ntile = mercantile.tile(lon, lat, zoom)\n\n# Generate tile URL\nbase_url = \"https://openveda.cloud/api/raster/cog/tiles/WebMercatorQuad\"\ncog_path = \"s3://veda-data-store/grdi-v1-raster/povmap-grdi-v1_2010-01-01_2021-12-31.tif\"  # üü¢COG of GRDI\n\ncog_path = \"s3://veda-data-store-staging/grdi-vnl-slope-raster/povmap-grdi-v1_VNL-slope_2012-01-01_2020-12-31.tif\"  # üü¢COG of VNL slope\n\ntile_url = (\n    f\"{base_url}/{tile.z}/{tile.x}/{tile.y}\"\n    f\"?url={cog_path}&resampling_method=nearest&bidx=1\"\n    f\"&colormap_name=viridis&rescale=0,100\"\n)\n\n# Request and plot the tile\nresponse = requests.get(tile_url)\nimg = Image.open(BytesIO(response.content))\n\nplt.imshow(img)\nplt.axis(\"off\")\nplt.title(f\"GRDI - Zoomed to India (Zoom level: {zoom})\")\nplt.show()\n\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-3-query-the-collection","position":65},{"hierarchy":{"lvl1":"USE CASE 4: URBAN HEALTH","lvl3":"4.4. Comparing values between two cities: New Delhi vs Gurugram"},"type":"lvl3","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-4-comparing-values-between-two-cities-new-delhi-vs-gurugram","position":66},{"hierarchy":{"lvl1":"USE CASE 4: URBAN HEALTH","lvl3":"4.4. Comparing values between two cities: New Delhi vs Gurugram"},"content":"\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-4-comparing-values-between-two-cities-new-delhi-vs-gurugram","position":67},{"hierarchy":{"lvl1":"USE CASE 4: URBAN HEALTH","lvl4":"4.4.1 Load the KML","lvl3":"4.4. Comparing values between two cities: New Delhi vs Gurugram"},"type":"lvl4","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-4-1-load-the-kml","position":68},{"hierarchy":{"lvl1":"USE CASE 4: URBAN HEALTH","lvl4":"4.4.1 Load the KML","lvl3":"4.4. Comparing values between two cities: New Delhi vs Gurugram"},"content":"\n\nimport matplotlib.pyplot as plt\nfrom shapely.geometry import Polygon\nfrom pykml import parser\n\n# --- Helper to read polygon from KML ---\ndef load_polygon(path):\n    with open(path) as f:\n        root = parser.parse(f).getroot()\n    coords_text = root.Document.Placemark.Polygon.outerBoundaryIs.LinearRing.coordinates.text\n    polygon_coords = [tuple(map(float, c.split(\",\")[:2])) for c in coords_text.strip().split()]\n    return Polygon(polygon_coords)\n\n# Load polygons\npolygon_nd = load_polygon(\"Cities/NewDehli_2.kml\")\npolygon_gg = load_polygon(\"Cities/Gurugram.kml\")\n\n# --- Plot both polygons ---\nfig, ax = plt.subplots(figsize=(8, 8))\n\n# New Delhi in red\nx_nd, y_nd = polygon_nd.exterior.xy\nax.plot(x_nd, y_nd, color=\"skyblue\", linewidth=2, label=\"New Delhi boundary\")\nax.fill(x_nd, y_nd, color=\"skyblue\", alpha=0.2)\n\n# Gurugram in green\nx_gg, y_gg = polygon_gg.exterior.xy\nax.plot(x_gg, y_gg, color=\"orange\", linewidth=2, label=\"Gurugram boundary\")\nax.fill(x_gg, y_gg, color=\"orange\", alpha=0.2)\n\nax.set_xlabel(\"Longitude\")\nax.set_ylabel(\"Latitude\")\nax.set_title(\"KML Polygons - New Delhi & Gurugram\")\nax.legend()\n\nplt.show()\n\n\nimport IPython.display\nfrom shapely.geometry import Polygon\nfrom pykml import parser\nfrom sentinelhub import Geometry, CRS\n\n# Loading the polygon from KML\ndef load_polygon_from_kml(kml_path):\n    with open(kml_path) as f:\n        root = parser.parse(f).getroot()\n    coords_text = root.Document.Placemark.Polygon.outerBoundaryIs.LinearRing.coordinates.text\n    polygon_coords = [tuple(map(float, c.split(\",\")[:2])) for c in coords_text.strip().split()]\n    return Polygon(polygon_coords)\n\n# Load polygons\npolygon_gg = load_polygon_from_kml(\"Cities/Gurugram.kml\")\npolygon_nd = load_polygon_from_kml(\"Cities/NewDehli_2.kml\")\n\n# Convert to Sentinel Hub Geometry\ngeometry_gg = Geometry(polygon_gg, crs=CRS.WGS84)\ngeometry_nd = Geometry(polygon_nd, crs=CRS.WGS84)\n\n# Display both as GeoJSON\nIPython.display.GeoJSON({\n    \"type\": \"FeatureCollection\",\n    \"features\": [\n        {\"type\": \"Feature\", \"geometry\": geometry_gg.get_geojson(), \"properties\": {\"name\": \"Gurugram\"}},\n        {\"type\": \"Feature\", \"geometry\": geometry_nd.get_geojson(), \"properties\": {\"name\": \"New Delhi\"}}\n    ]\n})\n\n\nimport requests\nfrom io import BytesIO\nfrom PIL import Image\nimport numpy as np\nimport mercantile\nfrom shapely.geometry import Point, Polygon, mapping\nimport folium\nfrom folium.raster_layers import ImageOverlay\nfrom pykml import parser\n\n# Loading polygons\ndef load_polygon_from_kml(kml_path):\n    with open(kml_path) as f:\n        root = parser.parse(f).getroot()\n    coords_text = root.Document.Placemark.Polygon.outerBoundaryIs.LinearRing.coordinates.text\n    polygon_coords = [tuple(map(float, c.split(\",\")[:2])) for c in coords_text.strip().split()]\n    return Polygon(polygon_coords)\n\n# Fetch the COG into tile\ndef get_tile_image(lon, lat, zoom, cog_path, base_url):\n    tile = mercantile.tile(lon, lat, zoom)\n    url = (\n        f\"{base_url}/{tile.z}/{tile.x}/{tile.y}\"\n        f\"?url={cog_path}&resampling_method=nearest&bidx=1\"\n        f\"&colormap_name=viridis&rescale=0,100\"\n    )\n    response = requests.get(url)\n    img = Image.open(BytesIO(response.content)).convert(\"RGBA\")\n    return np.array(img), tile\n\n# Cropping tile to polyong of each city\ndef crop_to_polygon(img_array, tile, polygon):\n    height, width = img_array.shape[:2]\n    lon_ul, lat_ul = mercantile.ul(tile.x, tile.y, tile.z).lng, mercantile.ul(tile.x, tile.y, tile.z).lat\n    lon_lr, lat_lr = mercantile.ul(tile.x+1, tile.y+1, tile.z).lng, mercantile.ul(tile.x+1, tile.y+1, tile.z).lat\n    res_lon = (lon_lr - lon_ul) / width\n    res_lat = (lat_lr - lat_ul) / height\n\n    mask = np.zeros((height, width), dtype=bool)\n    for i in range(height):\n        for j in range(width):\n            lon_p = lon_ul + j * res_lon\n            lat_p = lat_ul + i * res_lat\n            if polygon.contains(Point(lon_p, lat_p)):\n                mask[i, j] = True\n    img_array[~mask] = [0, 0, 0, 0]\n    return img_array\n\n\nzoom = 8\nbase_url = \"https://openveda.cloud/api/raster/cog/tiles/WebMercatorQuad\"\ncog_path = \"s3://veda-data-store/grdi-v1-raster/povmap-grdi-v1_2010-01-01_2021-12-31.tif\"\n\n#Loading polygons \npolygon_nd = load_polygon_from_kml(\"Cities/NewDehli_2.kml\")\npolygon_gg = load_polygon_from_kml(\"Cities/Gurugram.kml\")\n\n# Fetch and crop tiles ---\nlon_nd, lat_nd = 77.209581, 28.646138\nimg_nd, tile_nd = get_tile_image(lon_nd, lat_nd, zoom, cog_path, base_url)\nimg_nd = crop_to_polygon(img_nd, tile_nd, polygon_nd)\n\nlon_gg, lat_gg = 77.054362, 28.453160\nimg_gg, tile_gg = get_tile_image(lon_gg, lat_gg, zoom, cog_path, base_url)\nimg_gg = crop_to_polygon(img_gg, tile_gg, polygon_gg)\n\n# Creating interactive map \ncenter_lat, center_lon = 28.55, 77.13\nm = folium.Map(location=[center_lat, center_lon], zoom_start=11)\n\n# Add New Delhi overlay\nul_lat, ul_lon = mercantile.ul(tile_nd.x, tile_nd.y, tile_nd.z).lat, mercantile.ul(tile_nd.x, tile_nd.y, tile_nd.z).lng\nlr_lat, lr_lon = mercantile.ul(tile_nd.x+1, tile_nd.y+1, tile_nd.z).lat, mercantile.ul(tile_nd.x+1, tile_nd.y+1, tile_nd.z).lng\nImageOverlay(image=img_nd, bounds=[[lr_lat, ul_lon], [ul_lat, lr_lon]], opacity=0.6).add_to(m)\n\n# Add Gurugram overlay\nul_lat, ul_lon = mercantile.ul(tile_gg.x, tile_gg.y, tile_gg.z).lat, mercantile.ul(tile_gg.x, tile_gg.y, tile_gg.z).lng\nlr_lat, lr_lon = mercantile.ul(tile_gg.x+1, tile_gg.y+1, tile_gg.z).lat, mercantile.ul(tile_gg.x+1, tile_gg.y+1, tile_gg.z).lng\nImageOverlay(image=img_gg, bounds=[[lr_lat, ul_lon], [ul_lat, lr_lon]], opacity=0.6).add_to(m)\n\n# --- Add borders on top of raster overlays ---\n# New Delhi border (skyblue)\nfolium.Polygon(\n    locations=[(lat, lon) for lon, lat in polygon_nd.exterior.coords],\n    color='skyblue',\n    weight=3,\n    fill=False\n).add_to(m)\n\n# Gurugram border (orange)\nfolium.Polygon(\n    locations=[(lat, lon) for lon, lat in polygon_gg.exterior.coords],\n    color='orange',\n    weight=3,\n    fill=False\n).add_to(m)\n\n# Display map\nm\n\n\n\n\n\n# Loading polyong from KML\ndef load_polygon(kml_path):\n    with open(kml_path) as f:\n        root = parser.parse(f).getroot()\n    coords_text = root.Document.Placemark.Polygon.outerBoundaryIs.LinearRing.coordinates.text\n    polygon_coords = [tuple(map(float, c.split(\",\")[:2])) for c in coords_text.strip().split()]\n    return Polygon(polygon_coords)\n\n# --- Helper: fetch one tile ---\nbase_url = \"https://openveda.cloud/api/raster/cog/tiles/WebMercatorQuad\"\ncog_path = \"s3://veda-data-store/grdi-v1-raster/povmap-grdi-v1_2010-01-01_2021-12-31.tif\"\n\ndef fetch_tile(tile):\n    url = (\n        f\"{base_url}/{tile.z}/{tile.x}/{tile.y}\"\n        f\"?url={cog_path}&resampling_method=nearest&bidx=1\"\n        f\"&colormap_name=viridis&rescale=0,100\"\n    )\n    response = requests.get(url)\n    return Image.open(BytesIO(response.content))\n\n# --- Function: compute masked average for a polygon ---\ndef compute_average_grdi(polygon, zoom=12):\n    min_lon, min_lat, max_lon, max_lat = polygon.bounds\n    tiles_to_fetch = list(mercantile.tiles(min_lon, min_lat, max_lon, max_lat, zoom))\n    all_values = []\n\n    for tile in tiles_to_fetch:\n        img = fetch_tile(tile)\n        img_array = np.array(img.convert(\"L\"))\n        \n        mask = np.zeros(img_array.shape, dtype=bool)\n        width, height = img.size\n\n        # Upper-left corner of the tile\n        lon_ul, lat_ul = mercantile.ul(tile.x, tile.y, tile.z).lng, mercantile.ul(tile.x, tile.y, tile.z).lat\n        # Lower-right corner\n        lon_lr, lat_lr = mercantile.ul(tile.x+1, tile.y+1, tile.z).lng, mercantile.ul(tile.x+1, tile.y+1, tile.z).lat\n        # Resolution\n        res_lon = (lon_lr - lon_ul) / width\n        res_lat = (lat_lr - lat_ul) / height\n\n        for i in range(height):\n            for j in range(width):\n                lon = lon_ul + j * res_lon\n                lat = lat_ul + i * res_lat\n                if polygon.contains(Point(lon, lat)):\n                    mask[i, j] = True\n\n        values = img_array[mask]\n        all_values.extend(values)\n\n    return np.mean(all_values) if all_values else np.nan\n\n# --- Run for New Delhi and Gurugram ---\npolygon_nd = load_polygon(\"Cities/NewDehli_2.kml\")\npolygon_gg = load_polygon(\"Cities/Gurugram.kml\")\n\navg_nd = compute_average_grdi(polygon_nd, zoom=12)\navg_gg = compute_average_grdi(polygon_gg, zoom=12)\n\nprint(\"Average GRDI for New Delhi:\", avg_nd)\nprint(\"Average GRDI for Gurugram:\", avg_gg)\n\n\n# --- Plot bar chart of masked GRDI averages ---\nimport matplotlib.pyplot as plt\n\naverages = {\n    \"New Delhi\": avg_nd,\n    \"Gurugram\": avg_gg\n}\n\nplt.figure(figsize=(6, 4))\nplt.bar(averages.keys(), averages.values(), color=['skyblue', 'orange'])\nplt.ylabel(\"Average GRDI Value\")\nplt.title(\"Average GRDI (Masked by KML Polygons)\")\nfor i, v in enumerate(averages.values()):\n    plt.text(i, v + 0.5, f\"{v:.1f}\", ha='center', fontsize=10, fontweight='bold')\nplt.ylim(0, max(averages.values()) * 1.2)\nplt.show()\n\n\n\n\n\n\n\n\n# Loading polyong from KML\ndef load_polygon(kml_path):\n    with open(kml_path) as f:\n        root = parser.parse(f).getroot()\n    coords_text = root.Document.Placemark.Polygon.outerBoundaryIs.LinearRing.coordinates.text\n    polygon_coords = [tuple(map(float, c.split(\",\")[:2])) for c in coords_text.strip().split()]\n    return Polygon(polygon_coords)\n\n# --- Helper: fetch one tile ---\nbase_url = \"https://openveda.cloud/api/raster/cog/tiles/WebMercatorQuad\"\n#cog_path = \"s3://veda-data-store/grdi-v1-raster/povmap-grdi-v1_2010-01-01_2021-12-31.tif\"\ncog_path = \"s3://veda-data-store-staging/grdi-vnl-slope-raster/povmap-grdi-v1_VNL-slope_2012-01-01_2020-12-31.tif\"\n\ndef fetch_tile(tile):\n    url = (\n        f\"{base_url}/{tile.z}/{tile.x}/{tile.y}\"\n        f\"?url={cog_path}&resampling_method=nearest&bidx=1\"\n        f\"&colormap_name=viridis&rescale=0,100\"\n    )\n    response = requests.get(url)\n    return Image.open(BytesIO(response.content))\n\n# --- Function: compute masked average for a polygon ---\ndef compute_average_grdi(polygon, zoom=12):\n    min_lon, min_lat, max_lon, max_lat = polygon.bounds\n    tiles_to_fetch = list(mercantile.tiles(min_lon, min_lat, max_lon, max_lat, zoom))\n    all_values = []\n\n    for tile in tiles_to_fetch:\n        img = fetch_tile(tile)\n        img_array = np.array(img.convert(\"L\"))\n        \n        mask = np.zeros(img_array.shape, dtype=bool)\n        width, height = img.size\n\n        # Upper-left corner of the tile\n        lon_ul, lat_ul = mercantile.ul(tile.x, tile.y, tile.z).lng, mercantile.ul(tile.x, tile.y, tile.z).lat\n        # Lower-right corner\n        lon_lr, lat_lr = mercantile.ul(tile.x+1, tile.y+1, tile.z).lng, mercantile.ul(tile.x+1, tile.y+1, tile.z).lat\n        # Resolution\n        res_lon = (lon_lr - lon_ul) / width\n        res_lat = (lat_lr - lat_ul) / height\n\n        for i in range(height):\n            for j in range(width):\n                lon = lon_ul + j * res_lon\n                lat = lat_ul + i * res_lat\n                if polygon.contains(Point(lon, lat)):\n                    mask[i, j] = True\n\n        values = img_array[mask]\n        all_values.extend(values)\n\n    return np.mean(all_values) if all_values else np.nan\n\n# --- Run for New Delhi and Gurugram ---\npolygon_nd = load_polygon(\"Cities/NewDehli_2.kml\")\npolygon_gg = load_polygon(\"Cities/Gurugram.kml\")\n\navg_nd = compute_average_grdi(polygon_nd, zoom=12)\navg_gg = compute_average_grdi(polygon_gg, zoom=12)\n\nprint(\"Average GRDI for New Delhi:\", avg_nd)\nprint(\"Average GRDI for Gurugram:\", avg_gg)\n\n\n# --- Plot bar chart of masked GRDI averages ---\nimport matplotlib.pyplot as plt\n\naverages = {\n    \"New Delhi\": avg_nd,\n    \"Gurugram\": avg_gg\n}\n\nplt.figure(figsize=(6, 4))\nplt.bar(averages.keys(), averages.values(), color=['skyblue', 'orange'])\nplt.ylabel(\"Average GRDI Value\")\nplt.title(\"Average GRDI (Masked by KML Polygons)\")\nfor i, v in enumerate(averages.values()):\n    plt.text(i, v + 0.5, f\"{v:.1f}\", ha='center', fontsize=10, fontweight='bold')\nplt.ylim(0, max(averages.values()) * 1.2)\nplt.show()\n\n\n\n\n","type":"content","url":"/external-notebooks/group1/2025-bids-eodashboard/notebook/urban-health-and-megacities#id-4-4-1-load-the-kml","position":69},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site"},"type":"lvl1","url":"/notebooks/fire-impact-analysis","position":0},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site"},"content":"","type":"content","url":"/notebooks/fire-impact-analysis","position":1},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Geo-storytelling with RACE, EO Dashboard and the Euro Data Cube"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#geo-storytelling-with-race-eo-dashboard-and-the-euro-data-cube","position":2},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Geo-storytelling with RACE, EO Dashboard and the Euro Data Cube"},"content":"\n\nThis notebook demonstates how to access and analyse data found on the \n\nRapid Action for Citizens with Earth Observation (RACE) and \n\nEarth Observation Dashboard. It uses the EC-JRC‚Äôs Global Human Settlement (GHS) Layer which contains global data about the total built-up surface from 1975 to 2030 and was derived from Sentinel2 composite and Landsat imagery. The data is openly available and can be downloaded \n\nhere. It was ingested in EDC and provided as a layer, check out the documentation \n\nhere for further information about the data properties in EDC.\nThe GHS indicator can be explored on the EO Dashboard by selecting the \n\nEXPLORE DATASETS mode.\n\n","type":"content","url":"/notebooks/fire-impact-analysis#geo-storytelling-with-race-eo-dashboard-and-the-euro-data-cube","position":3},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Euro Data Cube - EDC Platform presentation"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#euro-data-cube-edc-platform-presentation","position":4},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Euro Data Cube - EDC Platform presentation"},"content":"\n\n\n\n","type":"content","url":"/notebooks/fire-impact-analysis#euro-data-cube-edc-platform-presentation","position":5},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"EDC - cloud-optimized platform offering:"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#edc-cloud-optimized-platform-offering","position":6},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"EDC - cloud-optimized platform offering:"},"content":"Access to EO archives from main all open missions (e.g. Sentinel, Landsat, MODIS, etc.), commercial satellites (PlanetScope, Pleiades, SPOT, WorldView, etc.) as well as Level 3 products (Copernicus Land Monitoring Services, C3S, etc.)\n\nAnalyse, compare and correlate EO data through Xcube and operational tools (Sentinel Hub)\n\nManage different data formats and type in a transparent way (raster, vector, COGs, Zarr, etc.)\n\nBring and store your own data and algorithm for real-time and batch processing operations\n\nComputational resources and storage to run Jupyter Notebooks and your deployed Applications within your Kubernetes-powered workspace\n\nExpose your apps on the EDC marketplace to third-parties and provide easy access to your managed API service to customers\n\n\n\n","type":"content","url":"/notebooks/fire-impact-analysis#edc-cloud-optimized-platform-offering","position":7},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"EDC - Market Place"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#edc-market-place","position":8},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"EDC - Market Place"},"content":"\n\nData Products: e.g. \n\nSentinel Hub\n\nPlatform Services: e.g. \n\nEOxHub\n\nAPI Services: e.g. \n\nGeoDB, \n\nSH-Statistical API\n\n","type":"content","url":"/notebooks/fire-impact-analysis#edc-market-place","position":9},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"Content of this notebook:"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#content-of-this-notebook","position":10},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"Content of this notebook:"},"content":"Visualizing wildfire events with Sentinel-2 imagery\n\nQuerying data via Statistical API for the chosen Area of Interest\n\nTransforming the output of the API request into a geoJSON polygon that contains the extent of the built up area in the AOI\n\nAccessing Sentinel-5p Carbon monoxide data from SentinelHub\n\nDisplaying the time series of the CO concentration over the populated area to evaluate the possible impact of the fire emissions\n\nThis notebook runs with the python environment users-edc-2023.07-01 and was prepared by Leah Sturm (University of Trier, Germany).\n\n#import necessary libraries\nimport os\nimport numpy as np\nimport geopandas as gpd\nimport rasterio\nfrom rasterio.features import shapes\nimport requests\nimport geojson\nfrom shapely.geometry import shape\nfrom rasterio.transform import from_origin\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\n\n# Sentinel Hub requirements\nfrom sentinelhub import (SHConfig, DataCollection, Geometry, BBox, Geometry,\n                         SentinelHubRequest, filter_times, bbox_to_dimensions, MimeType, \n                         SentinelHubBYOC, ByocCollection, ByocTile, ByocCollectionAdditionalData,\n                         DownloadFailedException, CRS, SentinelHubStatistical)\n\n# Pass Sentinel Hub credentials to SHConfig\nconfig = SHConfig()\nconfig.sh_client_id = os.environ[\"SH_CLIENT_ID\"]\nconfig.sh_client_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\nclient_id = os.environ[\"SH_CLIENT_ID\"]\nclient_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\n\n# config\n\n","type":"content","url":"/notebooks/fire-impact-analysis#content-of-this-notebook","position":11},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Create a folder for the session in which all files will be stored","lvl2":"Content of this notebook:"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#create-a-folder-for-the-session-in-which-all-files-will-be-stored","position":12},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Create a folder for the session in which all files will be stored","lvl2":"Content of this notebook:"},"content":"\n\n# Get the current date and format it as a string\ncurrent_date = datetime.now().strftime(\"%Y-%m-%d\")\n\n# Define the folder name and path\nfolder_name = f\"folder_{current_date}\"\nfolder_path = os.path.join(os.getcwd(), folder_name)\n\n# Check if the folder already exists, and create it if not\nif not os.path.exists(folder_path):\n    os.mkdir(folder_path)\n    print(f\"Folder '{folder_name}' created at: {folder_path}\")\nelse:\n    print(f\"Folder '{folder_name}' already exists at: {folder_path}\")\n\n","type":"content","url":"/notebooks/fire-impact-analysis#create-a-folder-for-the-session-in-which-all-files-will-be-stored","position":13},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"Wildfire Impacts and Carbon Emissions"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#wildfire-impacts-and-carbon-emissions","position":14},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"Wildfire Impacts and Carbon Emissions"},"content":"The wildfire season during the summer of 2022 in Europe was exceptional, marked by a high number of observed fires, a large extent of burned area, and remarkably high atmospheric emissions linked to these fires. According to data from the European Forest Fire Information System (EFFIS), fires were reported in 26 out of the 27 European countries, collectively burning 837,212 hectares. A significant portion of these wildfires happened in July, with Spain, Portugal, France, and Italy experiencing the most damages.\n\nThe selected wildfire incident for this notebook occurred in the Gironde region of southwestern France, near the city of Bordeaux, in 2022. The significant fire event started on July 17, 2022, lasted for two weeks while burning approximately 7,000 hectares of land. Notably, the Copernicus Atmosphere Monitoring Service (CAMS) recorded exceptionally elevated levels of carbon monoxide emissions throughout the duration of this event.\n\nRelated articles about the event and the wildfire occurrence in 2022:\n\nEuropean Space Agency\n\nEU ScienceHub\n\nEFFIS\n\nCopernicus Atmosphere Monitoring Service\n\nEUMETSAT\n\n","type":"content","url":"/notebooks/fire-impact-analysis#wildfire-impacts-and-carbon-emissions","position":15},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#id-1-visualize-wildfire-event-with-sentinel-2","position":16},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"In this first part we are going to visualize the fire event to get an overview of the location and the occuring emissions. In the following cells we will access Sentinel-2 imagery from \n\nSentinel Hub. Sentinel Hub is a multi-spectral and multi-temporal big data satellite imagery service, capable of fully automated archiving, real-time processing and distribution of remote sensing data and related EO products. Users can use APIs to retrieve satellite data over their AOI and specific time range from full archives in a matter of seconds. The following cells to access Sentinel-2 data are based on the example notebook ‚ÄúAustralian Bushfires‚Äù which is available in the \n\nEuro Data Cube Marketplace.\n\nTo get a first overview of the fire event we are going to look at the true colour image captured on the day of the start of the fire.\n\n","type":"content","url":"/notebooks/fire-impact-analysis#id-1-visualize-wildfire-event-with-sentinel-2","position":17},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Define Area of Interest","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#define-area-of-interest","position":18},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Define Area of Interest","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"\n\nbbox_coords =[\n  -1.006524,\n  44.318762,\n  -0.406214,\n  44.586411\n]\n\nresolution = 20\nArea_of_interest_bbox = BBox(bbox=bbox_coords, crs=CRS.WGS84)\nArea_of_interest_size = bbox_to_dimensions(Area_of_interest_bbox, resolution=resolution)\n\n# Bbox EPSG\nbbox_epsg = 4326\n\n# Utilities\nimport IPython.display\nfrom IPython.display import display, GeoJSON\n\n# Plot the bounding box on a map\nIPython.display.GeoJSON(BBox(bbox_coords,crs=bbox_epsg).get_geojson())\n\n","type":"content","url":"/notebooks/fire-impact-analysis#define-area-of-interest","position":19},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Access Sentinel-2 data","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#access-sentinel-2-data","position":20},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Access Sentinel-2 data","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"We build the request according to the \n\nAPI Reference, using the SentinelHubRequest class. Each Process API request also needs an \n\nevalscript.\n\nThe information that we specify in the SentinelHubRequest object is:\n\nan evalscript,\n\na list of input data collections with time interval,\n\na format of the response,\n\na bounding box and it‚Äôs size (size or resolution).\n\nThe evalscript is used to select the appropriate bands. We return the RGB (B04, B03, B02) Sentinel-2 L2A bands.\n\n# define the evalscript \n\nevalscript_true_color = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B02\", \"B03\", \"B04\"]\n            }],\n            output: {\n                bands: 3\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B04, sample.B03, sample.B02];\n    }\n\"\"\"\n\n# we nned to specify the collection and the time interval\n# for a list of collections available in the Sentinel Hub visit https://docs.sentinel-hub.com/api/latest/data/ \n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_true_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L2A, \n            time_interval=('2022-07-16', '2022-07-18'),\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.PNG)\n    ],\n    bbox=Area_of_interest_bbox,\n    size=Area_of_interest_size,\n    config=config\n)\n\n","type":"content","url":"/notebooks/fire-impact-analysis#access-sentinel-2-data","position":21},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Visualize the requested Sentinel image","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#visualize-the-requested-sentinel-image","position":22},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Visualize the requested Sentinel image","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"\n\n# send the request to Sentinel Hub\n#true_color_imgs = request_true_color.get_data()\n\nmax_retries = 3\nretry_count = 0\nwhile retry_count < max_retries:\n    try:\n        true_color_imgs = request_true_color.get_data()\n        break  # Image displayed successfully, exit the loop\n    except Exception as e:\n        print(f\"Failed to display image: {e}\")\n        retry_count += 1\n        if retry_count < max_retries:\n            print(f\"Retrying (Attempt {retry_count})...\")\n \nif retry_count >= max_retries:\n    print(\"Maximum retries reached. Unable to retrieve the image.\")\n    \n# Define the plot_image function\n\ndef plot_image(image, factor=1.0, clip_range = None, **kwargs):\n    \"\"\"\n    Utility function for plotting RGB images.\n    \"\"\"\n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n    if clip_range is not None:\n        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n    else:\n        ax.imshow(image * factor, **kwargs)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nimage = true_color_imgs[0]\nprint(f'Image type: {image.dtype}')\n    \n# plot function\n# factor 1/255 to scale between 0-1\n# factor 3.5 to increase brightness\n\n# Maximum number of retry attempts\n\nplot_image(image, factor=3.5/255, clip_range=(0,1))\n\nThe visualized image captures the start of the  wildfire event which is prominently visible in the top right corner. The plume and emissions from the fire event extend westwards. Consequently, the analysis within this notebook will center around urban areas within those western regions.\n\n","type":"content","url":"/notebooks/fire-impact-analysis#visualize-the-requested-sentinel-image","position":23},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Define and visualize AOI for the analysis","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#define-and-visualize-aoi-for-the-analysis","position":24},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Define and visualize AOI for the analysis","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"\n\n# define the coordinates\ntop_left_x =  -1.26747\ntop_left_y = 44.674299\nbottom_right_x = -0.962647\nbottom_right_y = 44.508045\n\nbbox = [   \n  top_left_x,\n  bottom_right_y,\n  bottom_right_x,\n  top_left_y\n        ]\n\n# Bbox EPSG\nbbox_epsg = 4326\n\n# Plot the bounding box on a map\nIPython.display.GeoJSON(BBox(bbox,crs=bbox_epsg).get_geojson())\n\n","type":"content","url":"/notebooks/fire-impact-analysis#define-and-visualize-aoi-for-the-analysis","position":25},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Check the resolution and size of the AOI","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#check-the-resolution-and-size-of-the-aoi","position":26},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Check the resolution and size of the AOI","lvl2":"1. Visualize Wildfire Event with Sentinel-2"},"content":"\n\n# Check the resolution and pixels constrains (they have to be maximal 2500x2500)\nresolution = 10\naoi = BBox(bbox=bbox, crs=CRS.WGS84)\naoi_size = bbox_to_dimensions(aoi, resolution=resolution)\n\n# These values are needed to set the right dimensions for saving the request as tiff file later\nwidth = aoi_size[0]  \nheight = aoi_size[1] \n\nprint(f\"Image shape at {resolution} m resolution: {aoi_size} pixels\")\n\n","type":"content","url":"/notebooks/fire-impact-analysis#check-the-resolution-and-size-of-the-aoi","position":27},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#id-2-query-ghs-population-density-layer-with-sentinelhub-api-request","position":28},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"The \n\nStatistical API empowers users to derive insightful statistics from satellite imagery, eliminating the need to download large image files. When making a Statistical API request,it is possible to define an AOI, time frame, evalscript, and the specific statistical measures you wish to compute. The resulting statistics are conveniently included in the API response. With the Statistical API, the user can compute statistics such as cloud pixel percentages within a defined area and timeframe or calculate metrics like mean, standard deviation, and histogram of band values for a specific parcel over a given time frame.\n\nTo access the population density layer, we need to use the designated BYOC ID: 0c7aa265-50f9-4947-9980-2ee5ae204803 found on EDC. To query the GHS layer effectively, we need to provide the BYOC ID, the coordinates from the created GeoJSON file as AOI, the desired timeframe, and the necessary user credentials as inputs. The GHS layer contains data from 1975 to 2030 in 5 years intervals. We are going to query the data for 2020 because it is temporally closest to the chosen wildfire event in 2022.\n\nSource for EC-JRC‚Äôs GHS layer: Pesaresi, Martino; Politis, Panagiotis (2023): GHS-BUILT-S R2023A - GHS built-up surface grid, derived from Sentinel2 composite and Landsat, multitemporal (1975-2030). European Commission, Joint Research Centre (JRC) [Dataset] doi: 10.2905/9F06F36F-4B11-47EC-ABB0-4F8B7B1D72EA\n\nThe evalscript in this request creates a new output image where the ‚ÄúdataMask‚Äù band is modified based on the values in the GHS layer. If the GHS value is 0, it masks the pixel in the ‚ÄúdataMask‚Äù band by setting it to zero. Otherwise, it retains the original GHS value.\n\npopulation_dens = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\"BUILT\", \"dataMask\"], // this sets which bands to use\n    }],\n    output: { // this defines the output image type\n      bands: 1,\n      sampleType: \"UINT8\"\n    }\n  };\n}\n \nfunction evaluatePixel(sample) {\n    let pixelMask = 1\n    \n    if (sample.BUILT == 0){\n        pixelMask = 0\n    }\n  return {\n    default: [sample.BUILT],\n    dataMask: [sample.dataMask * pixelMask]\n  };\n}\n\"\"\"\n\nrequest_data = SentinelHubRequest(\n    evalscript=population_dens,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.define_byoc('0c7aa265-50f9-4947-9980-2ee5ae204803'),\n            time_interval=(\"2020-01-01\", \"2020-01-01\"),\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=aoi,\n    size=aoi_size,\n    config=config,\n)\n\npopulation_density = request_data.get_data()\n\n","type":"content","url":"/notebooks/fire-impact-analysis#id-2-query-ghs-population-density-layer-with-sentinelhub-api-request","position":29},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Extract the population density extent as GeoTiff file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#extract-the-population-density-extent-as-geotiff-file","position":30},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Extract the population density extent as GeoTiff file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"The GHS layer contains \n\nvalues ranging from 0 to 10,000, where higher values indicate greater population density. In this notebook, we only exclude pixels with zero values, but I would be possible to add a threshold to the script below to pinpoint areas of exceptionally high population density.\n\n# the final geotiff is a binary mask with values of 1 representing built-up pixels\nimage_data_list = population_density\n\n# Calculate pixel width and height based on image shape\npixel_width = (bottom_right_x - top_left_x) /  width \npixel_height = (top_left_y - bottom_right_y) / height\n\n# Specify the path to the directory where GeoTIFF files will be saved\noutput_directory = f\"./{folder_name}\"\n# Loop through the list of image arrays\nfor i, image_data in enumerate(image_data_list):\n    # Extract the pixel values (assuming single-band data)\n    pixel_values = image_data[:, :]\n\n    # Set values equal to zero to zero, and all other values to 1\n    pixel_values = np.where(pixel_values == 0, 0, 1)\n\n    # Specify the output path for each GeoTIFF file with the current time\n    output_path = os.path.join(output_directory, f\"output_{current_date}.tif\")\n\n    # Create a transformation for the GeoTIFF\n    transform = from_origin(top_left_x, top_left_y, pixel_width, pixel_height)\n\n    # Open a new GeoTIFF file for writing with NoData value set to NaN\n    with rasterio.open(\n        output_path,\n        'w',\n        driver='GTiff',\n        height=pixel_values.shape[0],\n        width=pixel_values.shape[1],\n        count=1,  # Only one band for pixel values\n        dtype=rasterio.float32,  # Use float32 for NaN values\n        crs='EPSG:4326',\n        transform=transform,\n        nodata=np.nan  # Set NoData value to NaN\n    ) as dst:\n        # Write the pixel values to the GeoTIFF\n        dst.write(pixel_values, 1)  # Use band 1\n\n\n","type":"content","url":"/notebooks/fire-impact-analysis#extract-the-population-density-extent-as-geotiff-file","position":31},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Visualize the extent of the population density layer","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#visualize-the-extent-of-the-population-density-layer","position":32},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Visualize the extent of the population density layer","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"\n\n# Specify the path to the GeoTIFF file\ngeotiff_path = f\"./{folder_name}/output_{current_date}.tif\"\n\n# Open the GeoTIFF file using rasterio\nwith rasterio.open(geotiff_path) as src:\n    # Read the raster data\n    raster_data = src.read(1)  # Assuming you have a single band GeoTIFF\n\n    # Get the spatial transformation information\n    transform = src.transform\n\n# Calculate the bounds based on the width and height of the raster\nleft, bottom, right, top = src.bounds\n\n# Plot the GeoTIFF data using matplotlib\nplt.figure(figsize=(8, 8))\nplt.imshow(raster_data, cmap='gray', extent=(left, right, bottom, top), origin='upper')\nplt.title('Population density in AOI')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.grid(True)\nplt.show()\n\nAll non populated areas are displayed in black in the plot while the populated areas are colored white. From this binary mask we can now create a GeoJSON file that contains only the populated areas.\n\n","type":"content","url":"/notebooks/fire-impact-analysis#visualize-the-extent-of-the-population-density-layer","position":33},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"3. Convert the binary raster mask into a GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#id-3-convert-the-binary-raster-mask-into-a-geojson-file","position":34},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"3. Convert the binary raster mask into a GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"The resulting GeoJSON will only contain polygons for built up areas and will be used as spatial extend to query the Sentinel-5p data later.\n\n# Specify the path to the GeoTIFF file\ngeotiff_path = f\"./{folder_name}/output_{current_date}.tif\"\n\n# Open the GeoTIFF file\nwith rasterio.open(geotiff_path) as src:\n    # Read the binary mask data\n    mask = src.read(1)\n\n# Convert the binary mask to vector polygons\ngeoms = list(shapes(mask, transform=src.transform, connectivity=4))  # Specify connectivity=4 for 4-connected pixels\n\n# Filter the polygons to include only those corresponding to pixels with a value of 1\nfiltered_geoms = [geom for geom, value in geoms if value == 1]\n\n# Create a GeoDataFrame from the filtered polygons\ngdf = gpd.GeoDataFrame({'geometry': [shape(geom) for geom in filtered_geoms]})\n\n# Merge all the geometries into a single MultiPolygon\nmulti_polygon = gdf.unary_union\n\n# Create a GeoDataFrame with the MultiPolygon geometry\nmulti_polygon_gdf = gpd.GeoDataFrame(geometry=[multi_polygon], crs=gdf.crs)\n\n# Specify the path to save the MultiPolygon GeoJSON file\noutput_geojson_file = f\"./{folder_name}/multi_polygon_{current_date}.geojson\"\n\n# Save the GeoDataFrame with the MultiPolygon to a GeoJSON file\nmulti_polygon_gdf.to_file(output_geojson_file, driver='GeoJSON')\n\n","type":"content","url":"/notebooks/fire-impact-analysis#id-3-convert-the-binary-raster-mask-into-a-geojson-file","position":35},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Plot the GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#plot-the-geojson-file","position":36},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Plot the GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"\n\ndisplay(GeoJSON(data=f\"./{folder_name}/multi_polygon_{current_date}.geojson\", crs=bbox_epsg))\n\nWe can see that now only the built-up areas are stored in the GeoJSON file and we can extract the coordinates from this and use them as an input for the Sentinel-5p data\n\n","type":"content","url":"/notebooks/fire-impact-analysis#plot-the-geojson-file","position":37},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Extract the coordinates of the created GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#extract-the-coordinates-of-the-created-geojson-file","position":38},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Extract the coordinates of the created GeoJSON file","lvl2":"2. Query GHS population density layer with SentinelHub API request"},"content":"\n\nwith open(f\"./{folder_name}/multi_polygon_{current_date}.geojson\") as f:\n    gj = geojson.load(f)\ndata_coordinates = gj['features'][0]['geometry']['coordinates']\n\n#print(data_coordinates)\n\n","type":"content","url":"/notebooks/fire-impact-analysis#extract-the-coordinates-of-the-created-geojson-file","position":39},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"4. Use Statistical API request to access Sentinel-5p CO data for the extracted populated areas"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#id-4-use-statistical-api-request-to-access-sentinel-5p-co-data-for-the-extracted-populated-areas","position":40},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"4. Use Statistical API request to access Sentinel-5p CO data for the extracted populated areas"},"content":"\n\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\n\n# Create a session\nclient = BackendApplicationClient(client_id=client_id)\noauth = OAuth2Session(client=client)\n\n# Get token for the session\ntoken = oauth.fetch_token(token_url='https://services.sentinel-hub.com/oauth/token',\n                          client_secret=client_secret)\n\n# All requests using this session will have an access token automatically added\nresp = oauth.get(\"https://services.sentinel-hub.com/oauth/tokeninfo\")\n\nurl = \"https://creodias.sentinel-hub.com/api/v1/statistics\"\nheaders = {\n  \"Accept\": \"application/json\",\n  \"Content-Type\": \"application/json\"\n}\ndata = {\n  \"input\": {\n    \"bounds\": {\n      \"geometry\": {\n        \"type\": \"MultiPolygon\",\n        \"coordinates\": data_coordinates\n                 }\n              },\n    \"data\": [\n      {\n        \"dataFilter\": {},\n        \"type\": \"sentinel-5p-l2\"\n      }\n    ]\n  },\n  \"aggregation\": {\n    \"timeRange\": {\n      \"from\": \"2022-07-01T00:00:00Z\",\n      \"to\": \"2022-08-09T23:59:59Z\"\n    },\n    \"aggregationInterval\": {\n      \"of\": \"P1D\"\n    },\n    \"width\": 512,\n    \"height\": 402.581,\n    \"evalscript\": \"//VERSION=3\\nfunction setup() {\\n  return {\\n    input: [{\\n      bands: [\\\"CO\\\", \\\"dataMask\\\"], // this sets which bands to use\\n    }],\\n    output: [\\n      { id:\\\"default\\\", bands: 1, sampleType: \\\"FLOAT32\\\" },\\n      { id: \\\"dataMask\\\", bands: 1 }\\n    ]\\n  };\\n}\\n \\n\\n\\nfunction evaluatePixel(sample) {\\n  return {\\n    default: [sample.CO],\\n    dataMask: [sample.dataMask]\\n  };\\n}\"\n  },\n  \"calculations\": {\n    \"default\": {}\n  }\n}\n\nresponse = oauth.post(url, headers=headers, json=data)\n\n","type":"content","url":"/notebooks/fire-impact-analysis#id-4-use-statistical-api-request-to-access-sentinel-5p-co-data-for-the-extracted-populated-areas","position":41},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Save the extracted statistics","lvl2":"4. Use Statistical API request to access Sentinel-5p CO data for the extracted populated areas"},"type":"lvl3","url":"/notebooks/fire-impact-analysis#save-the-extracted-statistics","position":42},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl3":"Save the extracted statistics","lvl2":"4. Use Statistical API request to access Sentinel-5p CO data for the extracted populated areas"},"content":"\n\nresponse_data = response.json()\n#print(response_data)\n\n","type":"content","url":"/notebooks/fire-impact-analysis#save-the-extracted-statistics","position":43},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"5. Plot the statistics for the S5p CO data"},"type":"lvl2","url":"/notebooks/fire-impact-analysis#id-5-plot-the-statistics-for-the-s5p-co-data","position":44},{"hierarchy":{"lvl1":"Evaluation of Fire Impact on Populated Areas on a European Site","lvl2":"5. Plot the statistics for the S5p CO data"},"content":"\n\ntime_axis = [datetime.strptime(entry[\"interval\"][\"from\"], \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y/%m/%d\") for entry in response_data[\"data\"]]\nmeans = [float(entry['outputs']['default']['bands']['B0']['stats']['mean']) for entry in response_data[\"data\"]]\nstd_devs = [float(entry['outputs']['default']['bands']['B0']['stats']['stDev']) for entry in response_data[\"data\"]]\nstd_upper = [m+s for (m,s) in zip(means, std_devs)]\nstd_lower = [m-s for (m,s) in zip(means, std_devs)]\n\nfig = plt.figure(figsize=(20,10))\n# plot mean values \nplt.plot_date(time_axis, means, linestyle='solid', linewidth=2, color=\"black\", label=\"Mean CO values [mol/ m^2]\")\n\n# plot standard deviation error bars\nplt.errorbar(time_axis, means, yerr=std_devs, linestyle=\"-\")\n\nplt.title('CO Values over the AOI (07/2022 - 08/2022)')\nplt.legend()\nfig.autofmt_xdate()\nplt.show()\n\nThe graph illustrates a noticeable increase in CO concentration across populated areas on July 17th, when the fire event started. Additionally, the Standard Deviation on this day and the following days is increased in comparison to the days before the fire. The highest \n\ncarbon emissions in France were recorded from June to August in 2022 which aligns well with the result of this analysis. To learn more about the carbon emissions resulting from wildfires check out this \n\nstory on the EO Dashboard that also incorporates further indicators to analyse wildfires.","type":"content","url":"/notebooks/fire-impact-analysis#id-5-plot-the-statistics-for-the-s5p-co-data","position":45},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC"},"type":"lvl1","url":"/notebooks/inland-water-with-edc","position":0},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.03-02\", dependencies=[\"SH\"])\n\n\n\nauthor: Anca Anghelea, based on a \n\nnotebook by: William Ray\n\nSeveral lakes and other inland water bodies are featured on EO Dashboard. The datasets supporting the various geo-stories are accessible by means similar to what you will learn in this notebook.\n\nExplore EO Dashboard Stories on Oceans and Inland Water.","type":"content","url":"/notebooks/inland-water-with-edc","position":1},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"In this notebook"},"type":"lvl2","url":"/notebooks/inland-water-with-edc#in-this-notebook","position":2},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"In this notebook"},"content":"In this demonstration Jupyter Notebook, we will be visualising and analysing inland water bodies using Sentinel data, demonstrating the use of EDC.\n\nWe are going to use the EDC and its associated libaries and APIs to do this. In this notebook we will learn how to:\n\nBuild a cube\n\nVisualise a variable in your data cube\n\nCreate a new variable\n\nCreate a new variable using a threshold\n\nVisualise a spatial subset of a variable over time\n\nCreate a new variable based upon space and time.\n\n","type":"content","url":"/notebooks/inland-water-with-edc#in-this-notebook","position":3},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"Configuration"},"type":"lvl2","url":"/notebooks/inland-water-with-edc#configuration","position":4},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"Configuration"},"content":"Before acccessing the data, we will start by importing the necessary Python libraries (already configured in your EDC workspace), and generate credentials automatically to access the services.\n\n# EDC libraries\nfrom edc import setup_environment_variables\nfrom xcube_sh.config import CubeConfig\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.sentinelhub import SentinelHub\nfrom xcube.core.gen2.local.combiner import CubesCombiner\nfrom xcube.core.geom import mask_dataset_by_geometry\n\n# Sentinel Hub\nfrom sentinelhub import BBox, SentinelHubRequest, bbox_to_dimensions, DataCollection, MimeType, SHConfig, geometry\n\n# Utilities\nimport IPython.display\nfrom os import environ\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport geopandas\nimport rioxarray\n\n# Numerical computation\nimport xarray as xr\nimport numpy as np\n\n# Fetch credentials as environement variables\nsetup_environment_variables()\n\n# Pass Sentinel Hub credentials to dictionnary\nsh_credentials = dict(client_id=environ[\"SH_CLIENT_ID\"],\n                      client_secret=environ[\"SH_CLIENT_SECRET\"])\n\nDefine an AOI\n\nNext, we will define our area of interest using a bounding box. This must be provided in WGS84 coordinates to build the cube.\n\nWe have chosen an AOI covering the natural park ‚ÄúValli di Comacchio‚Äù in Italy.\n\n# Define the coordinates of the bounding box\nlake_bbox = [12.09, 44.54, 12.27, 44.70]\n\n# Bbox EPSG\nbbox_epsg = 4326\n\n\n# Plot the bounding box on a map\nIPython.display.GeoJSON(BBox(lake_bbox,crs=bbox_epsg).get_geojson())\n\n","type":"content","url":"/notebooks/inland-water-with-edc#configuration","position":5},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"How to build a data cube","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#how-to-build-a-data-cube","position":6},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"How to build a data cube","lvl2":"Configuration"},"content":"Firstly, we will go through how to build a data cube.\n\nWe are going to visualise the floods using Sentinel-2 imagery. Sentinel-2 is part of the Copernicus programme and collects multispectral data globally with a revisit time of 5 days. The satellite‚Äôs multispectral imager provides collects data in 13 spectral bands spanning from the visible and near infrared to the shortwave infrared. The visible and near infrared data we will use in this example is collected at 10m resolution.\n\nCheck Sentinel-2 L2A available bands\n\nUsing EDC inbuilt functions that query Sentinel Hub services, we can easily list the available bands for a given dataset to help us build the cube!\n\n# Create a Sentinel Hub class, using our Sentinel Hub credentials\nSH = SentinelHub(**sh_credentials)\n\n# List bands for S2-L2A\nSH.band_names('S2L2A')\n\nBuild an xcube\n\nIn the following cell we will specify the input parameters needed to build an xcube array. The following parameters are specified:\n\ndataset_name: the Sentinel Hub identification of the dataset. Here we will call S2L2A for Sentinel-2 L2A. All available datasets can be listed with SH.dataset_names\n\nband_names: the band names to be used in the xcube array (see previous code cell). Here, we will call the B02, B03, B04, B08, CLM (Blue, Green, Red, NIR, Cloud Mask) bands.\n\nbbox: the bounding box that sets the extent of the AOI. Because we are using the default WGS84 coordinate system here, the CRS parameter doesn‚Äôt need to be set.\n\nspatial_res: the spatial resolution of the rasters contained in the xcube array. The spatial resolution is expressed in the units of the coordinate system used. Therefore, in this example, the spatial resolution is set in degrees. For an approximate pixel size of 10 meters, we set the resolution to 0.000089 degrees.\n\ntime_range: a list of two dates [start_date, end_date] forming a time period for which all acquisitions will be returned. Sentinel-2 L2A data is available from October 2016 onwards. In this example, we will fetch data for June 2023 - mid July 2023.\n\ntime_tolerance: The tolerance used to identify whether a dataset should still be included within a time period. Here, 30m corresponds to 30 minutes, thus avoiding duplicate datasets.\n\n# Setup xcube\ns2_cube_config = CubeConfig(dataset_name='S2L2A',\n                         band_names=['B02', 'B03', 'B04', 'B08', 'CLM'],\n                         bbox=lake_bbox,\n                         spatial_res=0.000089,\n                         time_range=['2023-06-01', '2023-07-16'],\n                         time_tolerance='30m')\n\nOpen the xcube\n\nIn the following cell we open the cube and display its contents. The automatically generated credentials obtained earlier in this Jupyter Notebook are specified as a parameter when opening the cube. It‚Äôs important to note that at this stage, we‚Äôre not processing anything, just generating a cube on the fly with data ready to be called when needed for analysis.\n\nOnce you open the cube, you can visualise the contents. You can view the number of timestamps and a list of them all too in the Coordinates tab. You can also visualise the seperate variables, with information on the size of the variables and their data type too.\n\n# Open cube (on the fly)\ns2_cube = open_cube(s2_cube_config, **sh_credentials)\n\n# Display contents\ns2_cube\n\n","type":"content","url":"/notebooks/inland-water-with-edc#how-to-build-a-data-cube","position":7},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"How to visualise your datacube","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#how-to-visualise-your-datacube","position":8},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"How to visualise your datacube","lvl2":"Configuration"},"content":"Now we have built our cube, let‚Äôs visualise the data! We are going to visualise a True Color image and an NDWI image in the same plot. In the below cell you can see we are selecting each band for 10:00:00 16th June 2023, and selecting the nearest acquisition to this date and time. We then stack the three bands and plot this using Matplotlib. We will call the three bands in the visible spectrum. In addition we will multiply the reflectance values by 5 to brighten the image.\n\nAnother way to visualise the extent of surface water is to use the Normalised Difference Water Index (NDWI). This is an index that can be used to extract surface water using multispectral imagery such as Sentinel-2. We can calculate the index with the Green and NIR bands as stated below, and add it into the data cube as a new variable.\n\nNDWI = Green - NIR / Green + NIR\n\nFor this we are going to create a new variable in the next cell. To create the new variable we are using two existing variables defined as s2_cube.B03 and s2_cube.B08. We then insert these variables into an index formula to create NDWI. Once ndwi has been calculated it‚Äôs attributed a long_name and units before being defined as ndwi so that we can call it as a definition later in the notebook.\n\n# Define NDWI in visualisation\nndwi = ((s2_cube.B03-s2_cube.B08)/(s2_cube.B03+s2_cube.B08))\n\nndwi.attrs['long_name']='NDWI'\nndwi.attrs['units']='unitless'\n\ns2_cube['NDWI']= ndwi  \n\nNext we want to plot both the True Color image and the NDWI in the same plot. We will use Matplotlib to achieve this.\n\n# Select the bands and stack them.\nRed = s2_cube.B04.sel(time='2023-06-17 10:00:00', method='nearest')\nGreen = s2_cube.B03.sel(time='2023-06-17 10:00:00', method='nearest')\nBlue = s2_cube.B02.sel(time='2023-06-17 10:00:00', method='nearest')\n\nrgb = np.dstack((Red,Green,Blue)) #Stack the three arrays\n\nndwi = s2_cube.NDWI.sel(time='2023-06-17 10:00:00', method='nearest')\n\n# Plot \nf = plt.figure(figsize=[10, 15])\nf.add_subplot(1, 2, 1)\nplt.title(f\"True Color: {str(s2_cube.time.sel(time='2023-06-17 10:00:00', method='nearest').data).split('T')[0]}\")\nplt.imshow(5 * rgb)  # We multiply the rgb by 5 to make the image brighter\nf.add_subplot(1, 2, 2)\nplt.title(f\"NDWI: {str(s2_cube.time.sel(time='2023-06-17 10:00:00', method='nearest').data).split('T')[0]}\")\nplt.imshow(ndwi, vmin=-1, vmax=1, cmap='GnBu')\nplt.show()\n\nThis looks good, and the extent of the flood waters is visualised really nicely here. The 10m resolution also enables us to see individual fields around the lake with the linear boundaries of the fields highlighted nicely in the high resolution image provided by the 10m Sentinel 2 bands.\n\nLet‚Äôs try and visualise some more dates in the time period that we are examining;\n\n# Select timestamps\nndwi1 = s2_cube.NDWI.sel(time='2023-06-17 10:00:00', method='nearest')\nndwi2 = s2_cube.NDWI.sel(time='2023-06-24 10:00:00', method='nearest')\nndwi3 = s2_cube.NDWI.sel(time='2023-06-29 10:00:00', method='nearest')\nndwi4 = s2_cube.NDWI.sel(time='2023-07-04 10:00:00', method='nearest')\nndwi5 = s2_cube.NDWI.sel(time='2023-07-07 10:00:00', method='nearest')\nndwi6 = s2_cube.NDWI.sel(time='2023-07-09 10:00:00', method='nearest')\n\n\n# Plot \nf = plt.figure(figsize=[15,11])\nax1 = f.add_subplot(2,3, 1)\nax2 = f.add_subplot(2,3, 2)\nax3 = f.add_subplot(2,3, 3)\nax4 = f.add_subplot(2,3, 4)\nax5 = f.add_subplot(2,3, 5)\nax6 = f.add_subplot(2,3, 6)\n\naxlist=[ax1,ax2,ax3,ax4,ax5,ax6]\n\nt = ndwi1.plot.imshow(ax=ax1, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi2.plot.imshow(ax=ax2, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi3.plot.imshow(ax=ax3, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi4.plot.imshow(ax=ax4, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi5.plot.imshow(ax=ax5, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi6.plot.imshow(ax=ax6, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\n\ncbar_ax = f.add_axes([1, 0.15, 0.05, 0.7])\nf.colorbar(t, cax=cbar_ax, label=\"NDWI\")\n\n#we will save the output image so we need to ensure that it is fully rendered \nplt.tight_layout() \n\n# Save the figure to a PNG file\nplt.savefig('NDWI.png')\n\nplt.show()\n\nWe could use the NDWI to estimate the surface water extent. The more images we have available, the more reliable the estimate can be. Examining the satellite images above we observe that not all of the images would be useful, as some of the lake area is covered with clouds. To overcome this limitation and have a denser time series we could rely on synthetic aperture radar observations, for example from the Copernicus Sentinel-1 platform.\n\n","type":"content","url":"/notebooks/inland-water-with-edc#how-to-visualise-your-datacube","position":9},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Sentinel-1 description","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#sentinel-1-description","position":10},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Sentinel-1 description","lvl2":"Configuration"},"content":"Like Sentinel-2, Sentinel-1 is also part of the Copernicus programme and collects data globally with a revisit time of 5 days. In contrast to Sentinel-2, Sentinel-1 SAR is an active sensor using SAR signals recording the backscatter. Due to the wavelengths used, SAR is not hindered by clouds and can be operated day and night.\n\n","type":"content","url":"/notebooks/inland-water-with-edc#sentinel-1-description","position":11},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Check Sentinel-1 GRD available bands","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#check-sentinel-1-grd-available-bands","position":12},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Check Sentinel-1 GRD available bands","lvl2":"Configuration"},"content":"Using EDC inbuilt functions that query Sentinel Hub services, we can easily list the available bands for a given dataset.\n\n# List bands for S1-GRD\nSH.band_names('S1GRD')\n\n","type":"content","url":"/notebooks/inland-water-with-edc#check-sentinel-1-grd-available-bands","position":13},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Build an xcube","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#build-an-xcube","position":14},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Build an xcube","lvl2":"Configuration"},"content":"In the following cell we will specify the input parameters needed to build an xcube array. The following parameters are specified:\n\ndataset_name: the Sentinel Hub identification of the dataset. Here we will call S1GRD for Sentinel-1 GRD. All available datasets can be listed with SH.dataset_names\n\nband_names: the band names to be used in the xcube array (see previous code cell). Here, we will call just the VV polarisation band.\n\nbbox: the bounding box that sets the extent of the AOI. Because we are using the default WGS84 coordinate system here, the CRS parameter doesn‚Äôt need to be set.\n\nspatial_res: the spatial resolution of the rasters contained in the xcube array. The spatial resolution is expressed in the units of the coordinate system used. Therefore, in this example, the spatial resolution is set in degrees. For an approximate pixel size of 10 meters, we set the resolution to 0.000089 degrees.\n\ntime_range: a list of two dates [start_date, end_date] forming a time period for which all acquisitions will be returned. Sentinel-1 GRD data is available from February 2015 onwards. In this example, we will fetch data for June 2023 - mid July 2023.\n\ntime_tolerance: The tolerance used to identify whether a dataset should still be included within a time period. Here, 30m corresponds to 30 minutes, thus avoiding duplicate datasets.\n\n# Setup xcube\ns1_cube_config = CubeConfig(dataset_name='S1GRD',\n                         band_names=['VV'],\n                         bbox=lake_bbox,\n                         spatial_res=0.000089,\n                         time_range=['2023-06-01', '2023-07-16'],\n                         time_tolerance='30m')\n\n","type":"content","url":"/notebooks/inland-water-with-edc#build-an-xcube","position":15},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Open the xcube","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#open-the-xcube","position":16},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Open the xcube","lvl2":"Configuration"},"content":"In the following cell we open the cube and display its contents. The automatically generated credentials obtained earlier in this Jupyter Notebook are specified as a parameter when opening the cube.\n\n# Open cube (on the fly)\ns1_cube = open_cube(s1_cube_config, **sh_credentials)\n\n# Display contents\ns1_cube\n\n","type":"content","url":"/notebooks/inland-water-with-edc#open-the-xcube","position":17},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Visualising the water areas using SAR","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#visualising-the-water-areas-using-sar","position":18},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Visualising the water areas using SAR","lvl2":"Configuration"},"content":"We are going to use the VV band to visualise the flooding. From our earlier visualisation, we know that the area had some cloud coverage around the date 2023-07-04. We will search for Sentinel-1 acquisitions around that date in order to obtain a denser time series.\n\nRadar data has very large dynamic range a very imbalanced histogram (>95% of all values are smaller than 1, but the remaining 5 % can be impractically large). Thus, to obtain a visualisation with a better contrast in which the water bodies would be darker and the land pixels would be brighter, it is recommended to convert the data to log-scale.\nTo convert the pixel values from Digital Number to decibels we can mutiply the log10 of each DN pixel by 10. Secondly, as there will be pixels with a value of -inf after this operation, we need to account for this with the second function which will automatically assign 0 to these pixels.\n\n# Convert VV Digital numbers to Decibels\nvv_dn = s1_cube.VV\nvv_db = 10 * (np.log10(vv_dn))\n\nvv_db = vv_db.where(np.isfinite(vv_db), 0)\n\nvv_db.attrs['long_name']='VV_dB'\nvv_db.attrs['units']='decibels'\n\ns1_cube['VV_dB']= vv_db\n\nLike previously, we are going to visualise the VV_dB variable we have just generated for our AOI.\n\n# select and define the timestamp you want to visualise \nVV_dB_timestamp = s1_cube.VV_dB.sel(time='2023-07-09 10:00:00', method='nearest')\n\n# plot the timestamp\nVV_dB_timestamp.plot.imshow(vmin=-40, vmax=0, cmap='winter', figsize=(10, 10))\n\n# save and display the plot\nplt.show()\n\nThis looks very similar to the NDWI we derived earlier showing the water extent fairly clearly (the blue areas). Let‚Äôs visualise it over several timestamps to confirm that this is a good variable to use to generate a lake mask.\n\n#### Timestamp selection\nvv1 = s1_cube.VV_dB.sel(time='2023-06-03 10:00:00', method='nearest')\nvv2 = s1_cube.VV_dB.sel(time='2023-06-04 10:00:00', method='nearest')\nvv3 = s1_cube.VV_dB.sel(time='2023-06-15 10:00:00', method='nearest')\nvv4 = s1_cube.VV_dB.sel(time='2023-06-27 10:00:00', method='nearest')\nvv5 = s1_cube.VV_dB.sel(time='2023-07-09 10:00:00', method='nearest')\nvv6 = s1_cube.VV_dB.sel(time='2023-07-10 10:00:00', method='nearest')\n\n# Plot \nf = plt.figure(figsize=[16,11])\nax1 = f.add_subplot(2,3, 1)\nax2 = f.add_subplot(2,3, 2)\nax3 = f.add_subplot(2,3, 3)\nax4 = f.add_subplot(2,3, 4)\nax5 = f.add_subplot(2,3, 5)\nax6 = f.add_subplot(2,3, 6)\n\naxlist=[ax1,ax2,ax3,ax4,ax5,ax6]\n\nt = vv1.plot.imshow(ax=ax1, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv2.plot.imshow(ax=ax2, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv3.plot.imshow(ax=ax3, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv4.plot.imshow(ax=ax4, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv5.plot.imshow(ax=ax5, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv6.plot.imshow(ax=ax6, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\n\ncbar_ax = f.add_axes([1, 0.15, 0.05, 0.7])\nf.colorbar(t, cax=cbar_ax, label=\"VV dB\")\n\nplt.show()\n\nDepending on the local conditions (e.g. terrain orientation, slope) and weather conditions, optical or radar imagery may be more useful. In this case both types of observations seem to provide a good view of the water surface area extent.\n\nNext we will generate a flood mask using a threshold.\n\nfor SAR images, generally, as a good rule of thumb, in the VV band, values below -20 dB are usually surface water. We will try this value first, but we will also look to visualise how the flood mask changes if we adjust the threshold value.\n\nobserving the NDWI range of values, we can chose values above 0.25 to correspond to the water class.\n\nFirst, let‚Äôs generate the new variable using the .where function in xarray.\n\nAt first glance, the below cell may not make much sense. It may read that the step 1 function as assigning a value of 1 to pixels in VV_dB that are equal or more than -20. However, what is actually happening is that the¬†.where function preserves all the pixel values in the variable that are below -20 and assigns everything else a value of 1. More can be found in the xarray documentation \n\nhttp://‚Äãxarray‚Äã.pydata‚Äã.org‚Äã/en‚Äã/stable‚Äã/generated‚Äã/xarray‚Äã.DataArray‚Äã.where‚Äã.html\n\n# mask the Sentinel-1 data\n\n# Assign all pixels equal or smaller than -20 a value of 1 and preserve the values of all other pixels \nstep1 = s1_cube.VV_dB.where(s1_cube.VV_dB > -20, 1)\n\n# Assign all other pixels a value of 0. \nwater = step1.where(step1 == 1, 0)\n\nwater.attrs['long_name'] ='water'\nwater.attrs['units'] ='nounits'\n\ns1_cube['water'] = water\n\nNext let‚Äôs see what happens to the mask extent if we change the threshold to -15 dB and -25dB:\n\n# Sentinel-1\nwater_threshold1_step1 = s1_cube.VV_dB.where(s1_cube.VV_dB > -15, 1)\nwater_threshold2_step1 = s1_cube.VV_dB.where(s1_cube.VV_dB > -20, 1)\nwater_threshold3_step1 = s1_cube.VV_dB.where(s1_cube.VV_dB > -25, 1)\n\nwater_threshold1_step2 = water_threshold1_step1.where(water_threshold1_step1 == 1, 0)\nwater_threshold2_step2 = water_threshold2_step1.where(water_threshold2_step1 == 1, 0)\nwater_threshold3_step2 = water_threshold3_step1.where(water_threshold3_step1 == 1, 0)\n\nwater_threshold1 = water_threshold1_step2.sel(time='2023-06-15 10:00:00', method='nearest')\nwater_threshold2 = water_threshold2_step2.sel(time='2023-06-15 10:00:00', method='nearest')\nwater_threshold3 = water_threshold3_step2.sel(time='2023-06-15 10:00:00', method='nearest')\n\nNext we will plot the new thresholds we want to test:\n\n# Plot \nf = plt.figure(figsize=[20,12])\nax1 = f.add_subplot(2,3, 1)\nax2 = f.add_subplot(2,3, 2)\nax3 = f.add_subplot(2,3, 3)\n\nwater_threshold1.plot.imshow(ax=ax1, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nwater_threshold2.plot.imshow(ax=ax2, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nwater_threshold3.plot.imshow(ax=ax3, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\n\nplt.show()\n\n# mask the Sentinel-2 data\n\n# Assign all pixels equal or larger than 0.25 a value of 1 and preserve the values of pixels \nstep11 = ndwi1.where(ndwi1 < 0.25, 1)\n\n# Assign all other pixels a value of 0. \nwater1 = step1.where(step1 == 1, 0)\n\nwater1.attrs['long_name'] ='water'\nwater1.attrs['units'] ='nounits'\n\ns2_cube['water'] = water1\n\n# Sentinel-2\nwater_threshold1_step11 = ndwi1.where(ndwi1 < 0.15, 1)\nwater_threshold2_step11 = ndwi1.where(ndwi1 < 0.25, 1)\nwater_threshold3_step11 = ndwi1.where(ndwi1 < 0.30, 1)\n\nwater_threshold1_step21 = water_threshold1_step11.where(water_threshold1_step11 == 1, 0)\nwater_threshold2_step21 = water_threshold2_step11.where(water_threshold2_step11 == 1, 0)\nwater_threshold3_step21 = water_threshold3_step11.where(water_threshold3_step11 == 1, 0)\n\nwater_threshold11 = water_threshold1_step21\nwater_threshold21 = water_threshold2_step21\nwater_threshold31 = water_threshold3_step21\n\n# Plot \nf = plt.figure(figsize=[20,12])\nax1 = f.add_subplot(2,3, 1)\nax2 = f.add_subplot(2,3, 2)\nax3 = f.add_subplot(2,3, 3)\n\nwater_threshold11.plot.imshow(ax=ax1, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nwater_threshold21.plot.imshow(ax=ax2, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nwater_threshold31.plot.imshow(ax=ax3, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\n\nplt.show()\n\nObserve the differences in the water mask due to the threshold.\n\n","type":"content","url":"/notebooks/inland-water-with-edc#visualising-the-water-areas-using-sar","position":19},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Estimating the surface water area extent","lvl2":"Configuration"},"type":"lvl3","url":"/notebooks/inland-water-with-edc#estimating-the-surface-water-area-extent","position":20},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl3":"Estimating the surface water area extent","lvl2":"Configuration"},"content":"Let‚Äôs estimate the area covered by water during the time period we are examining.\n\nWe can also estimate which is the area that is most covered by water by dividing the sum of the water pixels by the number of timesteps in the data cube (the count).\n\n# previously we only kept 1 time step when we selected ndwi1\n# now we want to keep the full datacube in order to average in time\n\n# Assign all pixels equal or larger than 0.25 a value of 1 and preserve the values of all other pixels \nstep1 = s2_cube.NDWI.where(s2_cube.NDWI < 0.25, 1)\n\n# Assign all other pixels a value of 0. \nwater = step1.where(step1 == 1, 0)\n\nwater.attrs['long_name'] ='water'\nwater.attrs['units'] ='nounits'\n\ns2_cube['water'] = water\n\n\nwater_sum = s2_cube.NDWI.sum(dim=\"time\")\nwater_count = s2_cube.NDWI.count(dim=\"time\")\nwater_average = water_sum / water_count\n\n\nwater_average.attrs['long_name']='water area'\nwater_average.attrs['units']='nounits'\n\nndwi['water_average']= water_average\n\nNow let‚Äôs plot the water_average into a plot:\n\nwater_average.plot.imshow(cmap='GnBu', vmin=0, vmax=0.5, figsize=(10, 10))\n\nplt.tight_layout()\n\n#expport to png\nplt.savefig('figure.png')\n\nplt.show()\n\nThis looks great, we have identified the lake area very clearly here and can also observe how the lake may change in size over time.\n\n","type":"content","url":"/notebooks/inland-water-with-edc#estimating-the-surface-water-area-extent","position":21},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"Access environmental variables and other datasets"},"type":"lvl2","url":"/notebooks/inland-water-with-edc#access-environmental-variables-and-other-datasets","position":22},{"hierarchy":{"lvl1":"Exploring Inland Water Bodies with Sentinel-2 data in EDC","lvl2":"Access environmental variables and other datasets"},"content":"This \n\nNotebook demonstrates how to:\n\nrequest data from selected Copernicus Services,\nrequest data from Copernicus Climate Data Store,\nrequest data from ESA Climate Change Initiative.","type":"content","url":"/notebooks/inland-water-with-edc#access-environmental-variables-and-other-datasets","position":23},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel"},"type":"lvl1","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel","position":0},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel"},"content":"\n\nThis concise notebook demonstrates guidelines for submission of your projects developed under the Earth System Science Open Challenge! Please use this notebook as a template for delivering your workflow with the code you used to produce the results! For more information, refer to Open Challenge website: \n\nhttps://‚Äãeo4society‚Äã.esa‚Äã.int‚Äã/event‚Äã/sciencehubchallengefeb2024/\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel","position":1},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"1. Title "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-1-title","position":2},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"1. Title "},"content":"Author(s): Lucas Jessel, Sabrine Hezzi, Marie-Laure Roussel  \nGroup name: Extreme precip  \nChallenge: 1 - ‚ÄúCevenols episodes‚Äù or rainfall extreme events in the South-East of France \n\nSubmission date: 01/03/2024 \n\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-1-title","position":3},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"2. Description "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-2-description","position":4},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"2. Description "},"content":"","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-2-description","position":5},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"Description of research approach","lvl2":"2. Description "},"type":"lvl4","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#description-of-research-approach","position":6},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"Description of research approach","lvl2":"2. Description "},"content":"Mediterranean events of intense rainfall can happen in late summer or in fall in the south-east of France (Cevennes, Rhone valley, Roussillon, Provence) due to warm and humid air coming from the heated sea, thanks to south-east flux mainly driven by any disturbance on France. It causes thunderstorms and heavy precipitation because of the cold air in altitude (that is explained in this region because of the topography : Massif Central, Alpes, Pyrenees). Flooding, runoff and landslides are the most important consequences of these events, due to blocked rainfall in the area.\n\nMonitoring this kind of extreme event is a massive challenge for weather forecasts models, that is why observations from space are a really great tool to help in that way.\n\nIn this study, the objective is to use observations products from space to try to detect massive rainfall events and evaluate the accuracy of the results in terms of caracteristics of the precipitation event (daily maximum value and location).\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#description-of-research-approach","position":7},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"3. Table of Contents "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-3-table-of-contents","position":8},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"3. Table of Contents "},"content":"Title\n\nDescription\n\nTable of Contents\n\nReferences\n\nKey Conclusions\n\nSocietal Context\n\nImport libraries\n\nAccess dataset\n\nAnalysis cells\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-3-table-of-contents","position":9},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"4. References "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-4-references","position":10},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"4. References "},"content":"Brocca et al. 2014. Soil as a natural rain gauge: Estimating global rainfall from satellite soil moisture data, \n\nBrocca et al. (2014).\n\nHuffman et al. 2001. Global Precipitation at One-Degree Daily Resolution from Multisatellite Observations, \n\nhttps://‚Äãdoi‚Äã.org‚Äã/10‚Äã.1175‚Äã/1525‚Äã-7541(2001)002<0036:GPAODD>\n\n2.0.CO;2\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-4-references","position":11},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"5. Key Conclusions "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-5-key-conclusions","position":12},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"5. Key Conclusions "},"content":"Among the two observational datasets compared to ERA5 reanalyses, which we have taken as a reference, it emerges as a conclusion that the GPM-CPC product provides a more accurate and faithful representation of an extreme Cevenol precipitation event, such as the one studied, both for the location and the value of the maximum of precipitation.\n\nOn the contrary, the GPCP product appears to produce too little precipitation for a Mediterranean episode day and fails to reproduce the maximum precipitation at the correct location.\n\nA more in-depth analysis could be considered to account for differences in spatial resolution between the datasets, as well as to study different days over a longer period of time.\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-5-key-conclusions","position":13},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"6. Societal Context "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-6-societal-context","position":14},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"6. Societal Context "},"content":"Mediterranean episodes can be dangerous for the population due to their significant and difficult-to-predict consequences such as floods and landslides. Numerous damages need to be considered during these sometimes dramatic events.\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-6-societal-context","position":15},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"PART 2: SCIENTIFIC EXPLOITATION AND ANALYSIS"},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#part-2-scientific-exploitation-and-analysis","position":16},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"PART 2: SCIENTIFIC EXPLOITATION AND ANALYSIS"},"content":"\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#part-2-scientific-exploitation-and-analysis","position":17},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"7. Import Libraries "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-7-import-libraries","position":18},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"7. Import Libraries "},"content":"This notebook runs with the python environment deepesdl-xcube-1.1.2, please checkout the documentation for \n\nhelp on changing the environment.\n\nimport xcube\nfrom xcube.core.store import find_data_store_extensions\nfrom xcube.core.store import get_data_store_params_schema\nfrom xcube.core.store import new_data_store\n\nimport boto3\nfrom botocore.exceptions import NoCredentialsError\n\nimport os\nimport shapely.geometry\nfrom IPython.display import JSON\nimport numpy as np\nimport xarray as xr\n\n# for the plots\nfrom cartopy import crs as ccrs, feature as cfeature\nprojPC = ccrs.PlateCarree(central_longitude=0)\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nimport matplotlib.ticker as ticker\n%matplotlib inline\nplt.rcParams[\"figure.figsize\"] = 16,8\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-7-import-libraries","position":19},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"8. Data sources "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-8-data-sources","position":20},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"8. Data sources "},"content":"\n\nDatacube name\n\nVariable name\n\nDescription\n\nReference*\n\nRegion\n\nTime range\n\nResolution\n\n(GPM-CPC) hydrology-1D-0.009deg-100x60x60-3.0.2.zarr\n\nprecip\n\nmetadata description\n\nlink to source\n\nsouth-east of France (40-45¬∞N, 0-10¬∞E)\n\ndaily\n\n0.01¬∞\n\n(GPCP) cube_GPCP_complete_nomissingvalue_lat_1996-2022.zarr\n\nprecip\n\nmetadata description\n\nlink to source\n\nsouth-east of France (40-45¬∞N, 0-10¬∞E)\n\ndaily\n\n1¬∞\n\n(ERA5) cube_tpsum.2015-2022.fs1e5.GLOBAL_025.zarr\n\ntp\n\nmetadata description\n\nlink to source\n\nsouth-east of France (40-45¬∞N, 0-10¬∞E)\n\ndaily\n\n0.25¬∞\n\n# CODE SECTION\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-8-data-sources","position":21},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"Setting stores variables","lvl2":"8. Data sources "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#setting-stores-variables","position":22},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"Setting stores variables","lvl2":"8. Data sources "},"content":"\n\n# PUBLIC STORE : for GPM-CPC dataset in the hydrology cube\npublic_store = new_data_store(\"s3\", root=\"deep-esdl-public\", storage_options=dict(anon=True))\n\n# USER/TEAM STORE : for GPCP and ERA5 datasets in the \"homemade\" cubes\nS3_USER_STORAGE_KEY = os.environ[\"S3_USER_STORAGE_KEY\"]\nS3_USER_STORAGE_SECRET = os.environ[\"S3_USER_STORAGE_SECRET\"]\nS3_USER_STORAGE_BUCKET = os.environ[\"endpoint\"]\nuser_store = new_data_store(\"s3\", max_depth=3, root=S3_USER_STORAGE_BUCKET,storage_options=dict(anon=False, key=S3_USER_STORAGE_KEY,secret=S3_USER_STORAGE_SECRET))\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#setting-stores-variables","position":23},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"Extracting GPM-CPC SM2RAIN ASCAT Dataset (from hydrology cube)","lvl2":"8. Data sources "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#extracting-gpm-cpc-sm2rain-ascat-dataset-from-hydrology-cube","position":24},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"Extracting GPM-CPC SM2RAIN ASCAT Dataset (from hydrology cube)","lvl2":"8. Data sources "},"content":"\n\nhydro_cube = public_store.open_data('hydrology-1D-0.009deg-100x60x60-3.0.2.zarr')\nprecip_data_hydro=hydro_cube['precip']\nprecip_data_hydro\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#extracting-gpm-cpc-sm2rain-ascat-dataset-from-hydrology-cube","position":25},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"Extracting GPCP Dataset","lvl2":"8. Data sources "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#extracting-gpcp-dataset","position":26},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"Extracting GPCP Dataset","lvl2":"8. Data sources "},"content":"\n\ngpcp_cube = user_store.open_data('cube_GPCP_complete_nomissingvalue_lat_1996-2022.zarr')\nprecip_data_gpcp = gpcp_cube['precip']\nprecip_data_gpcp\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#extracting-gpcp-dataset","position":27},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"Extracting ERA5 Dataset","lvl2":"8. Data sources "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#extracting-era5-dataset","position":28},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"Extracting ERA5 Dataset","lvl2":"8. Data sources "},"content":"\n\nera_cube = user_store.open_data('cube_tpsum.2015-2022.fs1e5.GLOBAL_025.zarr')\nprecip_data_era = era_cube['tp']*3600. # convert mm/s to mm/d \nprecip_data_era\n\n\n\n\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#extracting-era5-dataset","position":29},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"9. Analysis cells "},"type":"lvl2","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-analysis-cells","position":30},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl2":"9. Analysis cells "},"content":"\n\n# defining some coordinates inside the region of interest\n\nlat1=45 ; lon1=5\nlat2=45 ; lon2=7\nlat3=43 ; lon3=3\nlat4=44 ; lon4=7\nlat5=44 ; lon5=4\nlat6=44 ; lon6=5\nlat7=44 ; lon7=6\nlat8=44 ; lon8=3\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-analysis-cells","position":31},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.1) Plots of the long-term time-series","lvl2":"9. Analysis cells "},"type":"lvl4","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-1-plots-of-the-long-term-time-series","position":32},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.1) Plots of the long-term time-series","lvl2":"9. Analysis cells "},"content":"\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-1-plots-of-the-long-term-time-series","position":33},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.1.1) From the hydrology cube :","lvl4":"9.1) Plots of the long-term time-series","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-1-1-from-the-hydrology-cube","position":34},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.1.1) From the hydrology cube :","lvl4":"9.1) Plots of the long-term time-series","lvl2":"9. Analysis cells "},"content":"\n\n# selecting local precipitation data\n\nprecip_point1 = precip_data_hydro.sel(lat=lat1, lon=lon1, method='nearest')\nprecip_point2 = precip_data_hydro.sel(lat=lat2, lon=lon2, method='nearest')\nprecip_point3 = precip_data_hydro.sel(lat=lat3, lon=lon3, method='nearest')\nprecip_point4 = precip_data_hydro.sel(lat=lat4, lon=lon4, method='nearest')\nprecip_point5 = precip_data_hydro.sel(lat=lat5, lon=lon5, method='nearest')\nprecip_point6 = precip_data_hydro.sel(lat=lat6, lon=lon6, method='nearest')\nprecip_point7 = precip_data_hydro.sel(lat=lat7, lon=lon7, method='nearest')\nprecip_point8 = precip_data_hydro.sel(lat=lat8, lon=lon8, method='nearest')\n\nplt.figure(figsize=(20, 6))\nprecip_point1.plot(marker='o', linestyle='-',color='blue')\nprecip_point2.plot(marker='o', linestyle='-',color='red')\nprecip_point3.plot(marker='o', linestyle='-',color='green')\nprecip_point4.plot(marker='o', linestyle='-',color='yellow')\nprecip_point5.plot(marker='o', linestyle='-',color='purple')\nprecip_point6.plot(marker='o', linestyle='-',color='cyan')\nprecip_point7.plot(marker='o', linestyle='-',color='magenta')\nprecip_point8.plot(marker='o', linestyle='-',color='orange')\nplt.xlabel('Day')\nplt.ylabel('Daily rainfall (mm/d)')\nplt.title('Precipitation from GPM-CPC SM2RAIN-ASCAT (hydrology cube)')\nplt.grid(True)\nplt.show()\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-1-1-from-the-hydrology-cube","position":35},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.1.2) From the GPCP cube :","lvl4":"9.1) Plots of the long-term time-series","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-1-2-from-the-gpcp-cube","position":36},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.1.2) From the GPCP cube :","lvl4":"9.1) Plots of the long-term time-series","lvl2":"9. Analysis cells "},"content":"\n\n# selecting local precipitation data\nprecip_point1 = precip_data_gpcp.sel(latitude=lat1, longitude=lon1, method='nearest')\nprecip_point2 = precip_data_gpcp.sel(latitude=lat2, longitude=lon2, method='nearest')\nprecip_point3 = precip_data_gpcp.sel(latitude=lat3, longitude=lon3, method='nearest')\nprecip_point4 = precip_data_gpcp.sel(latitude=lat4, longitude=lon4, method='nearest')\nprecip_point5 = precip_data_gpcp.sel(latitude=lat5, longitude=lon5, method='nearest')\nprecip_point6 = precip_data_gpcp.sel(latitude=lat6, longitude=lon6, method='nearest')\nprecip_point7 = precip_data_gpcp.sel(latitude=lat7, longitude=lon7, method='nearest')\nprecip_point8 = precip_data_gpcp.sel(latitude=lat8, longitude=lon8, method='nearest')\n\nplt.figure(figsize=(20, 6))\nprecip_point1.plot(marker='o', linestyle='-',color='blue')\nprecip_point2.plot(marker='o', linestyle='-',color='red')\nprecip_point3.plot(marker='o', linestyle='-',color='green')\nprecip_point4.plot(marker='o', linestyle='-',color='yellow')\nprecip_point5.plot(marker='o', linestyle='-',color='purple')\nprecip_point6.plot(marker='o', linestyle='-',color='cyan')\nprecip_point7.plot(marker='o', linestyle='-',color='magenta')\nprecip_point8.plot(marker='o', linestyle='-',color='orange')\n\nplt.xlabel('Day')\nplt.ylabel('Daily rainfall (mm/d)')\nplt.ylim(0,80)\nplt.title('Precipitation from GPCP')\nplt.grid(True)\nplt.show()\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-1-2-from-the-gpcp-cube","position":37},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.1.3) From the ERA5 cube :","lvl4":"9.1) Plots of the long-term time-series","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-1-3-from-the-era5-cube","position":38},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.1.3) From the ERA5 cube :","lvl4":"9.1) Plots of the long-term time-series","lvl2":"9. Analysis cells "},"content":"\n\n# selecting local precipitation data\n\nprecip_point1 = precip_data_era.sel(latitude=lat1, longitude=lon1, method='nearest')\nprecip_point2 = precip_data_era.sel(latitude=lat2, longitude=lon2, method='nearest')\nprecip_point3 = precip_data_era.sel(latitude=lat3, longitude=lon3, method='nearest')\nprecip_point4 = precip_data_era.sel(latitude=lat4, longitude=lon4, method='nearest')\nprecip_point5 = precip_data_era.sel(latitude=lat5, longitude=lon5, method='nearest')\nprecip_point6 = precip_data_era.sel(latitude=lat6, longitude=lon6, method='nearest')\nprecip_point7 = precip_data_era.sel(latitude=lat7, longitude=lon7, method='nearest')\nprecip_point8 = precip_data_era.sel(latitude=lat8, longitude=lon8, method='nearest')\n\nplt.figure(figsize=(20, 6))\nprecip_point1.plot(marker='o', linestyle='-',color='blue')\nprecip_point2.plot(marker='o', linestyle='-',color='red')\nprecip_point3.plot(marker='o', linestyle='-',color='green')\nprecip_point4.plot(marker='o', linestyle='-',color='yellow')\nprecip_point5.plot(marker='o', linestyle='-',color='purple')\nprecip_point6.plot(marker='o', linestyle='-',color='cyan')\nprecip_point7.plot(marker='o', linestyle='-',color='magenta')\nprecip_point8.plot(marker='o', linestyle='-',color='orange')\n\nplt.xlabel('Day')\nplt.ylabel('Daily rainfall (mm/d)')\nplt.title('Precipitation from ERA5')\nplt.grid(True)\nplt.show()\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-1-3-from-the-era5-cube","position":39},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.2) Filtering => minicube selection on the studied region","lvl2":"9. Analysis cells "},"type":"lvl4","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-2-filtering-minicube-selection-on-the-studied-region","position":40},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.2) Filtering => minicube selection on the studied region","lvl2":"9. Analysis cells "},"content":"\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-2-filtering-minicube-selection-on-the-studied-region","position":41},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.2.1) On the hydrology cube","lvl4":"9.2) Filtering => minicube selection on the studied region","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-2-1-on-the-hydrology-cube","position":42},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.2.1) On the hydrology cube","lvl4":"9.2) Filtering => minicube selection on the studied region","lvl2":"9. Analysis cells "},"content":"\n\nlatm=43; latM=45; lonm=2.5; lonM=8  \n\nhydro_region_precip = hydro_cube['precip'].sel(lat=slice(latM,latm), lon = slice(lonm,lonM))\nhydro_region_precip\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-2-1-on-the-hydrology-cube","position":43},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.2.2) On the GPCP cube","lvl4":"9.2) Filtering => minicube selection on the studied region","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-2-2-on-the-gpcp-cube","position":44},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.2.2) On the GPCP cube","lvl4":"9.2) Filtering => minicube selection on the studied region","lvl2":"9. Analysis cells "},"content":"\n\ngpcp_region_precip = gpcp_cube['precip'].sel(latitude=slice(latm,latM), longitude= slice(lonm,lonM))\ngpcp_region_precip\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-2-2-on-the-gpcp-cube","position":45},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.2.3) On the ERA5 cube","lvl4":"9.2) Filtering => minicube selection on the studied region","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-2-3-on-the-era5-cube","position":46},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.2.3) On the ERA5 cube","lvl4":"9.2) Filtering => minicube selection on the studied region","lvl2":"9. Analysis cells "},"content":"\n\nera_region_precip = era_cube['tp'].sel(latitude=slice(latM,latm), longitude= slice(lonm,lonM))\nera_region_precip \n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-2-3-on-the-era5-cube","position":47},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.3) Searching the maximum values at each grid point for the whole time-serie","lvl2":"9. Analysis cells "},"type":"lvl4","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-3-searching-the-maximum-values-at-each-grid-point-for-the-whole-time-serie","position":48},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.3) Searching the maximum values at each grid point for the whole time-serie","lvl2":"9. Analysis cells "},"content":"\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-3-searching-the-maximum-values-at-each-grid-point-for-the-whole-time-serie","position":49},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.3.1) compute the maximum values on the region during the whole time-serie for each grid cell","lvl4":"9.3) Searching the maximum values at each grid point for the whole time-serie","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-3-1-compute-the-maximum-values-on-the-region-during-the-whole-time-serie-for-each-grid-cell","position":50},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.3.1) compute the maximum values on the region during the whole time-serie for each grid cell","lvl4":"9.3) Searching the maximum values at each grid point for the whole time-serie","lvl2":"9. Analysis cells "},"content":"\n\nhydro_region_precip_max = hydro_region_precip.max(dim = ['time'])\n\ngpcp_region_precip_max = gpcp_cube['precip'].max(dim = ['time'])\n\nera_region_precip_max = era_region_precip.max(dim = ['time'])\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-3-1-compute-the-maximum-values-on-the-region-during-the-whole-time-serie-for-each-grid-cell","position":51},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.3.2) Searching the days of massive precip events","lvl4":"9.3) Searching the maximum values at each grid point for the whole time-serie","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-3-2-searching-the-days-of-massive-precip-events","position":52},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.3.2) Searching the days of massive precip events","lvl4":"9.3) Searching the maximum values at each grid point for the whole time-serie","lvl2":"9. Analysis cells "},"content":"\n\n# defining the threshold matrix (maximum values to consider extreme events) \n# applying to datasets to find dates (where the daily precip > threshold)\n\nhydro_threshold = 0.99 * hydro_region_precip_max  \nhydro_dates_sup_threshold = hydro_region_precip['time'].where(hydro_region_precip >= hydro_threshold)\nhydro_tt = hydro_dates_sup_threshold.dropna(dim='time', how='all')\n\ngpcp_threshold = 0.99 * gpcp_region_precip_max  \ngpcp_dates_sup_threshold = gpcp_region_precip['time'].where(gpcp_cube['precip'] >= gpcp_threshold)\ngpcp_tt = gpcp_dates_sup_threshold.dropna(dim='time', how='all')\n\nera_threshold = 0.99 * era_region_precip_max \nera_dates_sup_threshold = era_region_precip['time'].where(era_cube['tp'] >= era_threshold)\nera_tt = era_dates_sup_threshold.dropna(dim='time', how='all')\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-3-2-searching-the-days-of-massive-precip-events","position":53},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"type":"lvl3","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-we-select-the-2nd-of-october-2020-detected-by-gpm-cpc-and-gpcp","position":54},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"content":"\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-we-select-the-2nd-of-october-2020-detected-by-gpm-cpc-and-gpcp","position":55},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.4) Maps of the daily precipitation for the three datasets on that particular day","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"type":"lvl4","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-4-maps-of-the-daily-precipitation-for-the-three-datasets-on-that-particular-day","position":56},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.4) Maps of the daily precipitation for the three datasets on that particular day","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"content":"\n\nhydro_xtrem_precip_20201002 = hydro_cube['precip'].sel(time='2020-10-02') \n\nfig = plt.figure()\nax = plt.axes(projection = projPC)\nim = ax.pcolormesh(hydro_xtrem_precip_20201002.lon, hydro_xtrem_precip_20201002.lat, hydro_xtrem_precip_20201002.values)\nax.set_extent([lonm, lonM, latm, latM], crs=projPC)\ngl = ax.gridlines(draw_labels=True, linewidth=0, alpha=0.5)\n\nax.coastlines()          \nax.add_feature(cfeature.LAND)\nax.add_feature(cfeature.COASTLINE)\nax.add_feature(cfeature.LAKES, alpha=0.5)\nax.add_feature(cfeature.RIVERS)\ncbar = plt.colorbar(im, label='precipitation (mm/d)',  extend='max', anchor=(0.2, 0.5), shrink=0.6, aspect=20)  # ajout de la colorbar\nax.set_title('Total precipitation (mm) on the south-east of France on the 02/10/2020 - from GPM-CPC dataset') \n\ngpcp_xtrem_precip_20201002 = gpcp_region_precip.sel(time='2020-10-02', latitude=slice(latm,latM)) \n\n# Define a normalization instance for the colorbar (not used here)\nnorm1 = mcolors.TwoSlopeNorm(vmin=0, vcenter=131.45/2, vmax=131.45)\n\nfig = plt.figure()\nax = plt.axes(projection = projPC)\nim = ax.pcolormesh(gpcp_xtrem_precip_20201002.longitude, gpcp_xtrem_precip_20201002.latitude, gpcp_xtrem_precip_20201002.values)#, norm=norm1)\nax.set_extent([lonm, lonM, latm, latM], crs=projPC)\ngl = ax.gridlines(draw_labels=True, linewidth=0, alpha=0.5)\n\nax.coastlines()          \nax.add_feature(cfeature.LAND)\nax.add_feature(cfeature.COASTLINE)\nax.add_feature(cfeature.LAKES, alpha=0.5)\nax.add_feature(cfeature.RIVERS)\ncbar = plt.colorbar(im, label='precipitation (mm/d)',  extend='max', anchor=(0.2, 0.5), shrink=0.6, aspect=20) \nax.set_title('Total precipitation (mm) on the south-east of France on the 02/10/2020 - from GPCP dataset')\n\nera_xtrem_precip_20201002 = 3600.*era_region_precip.sel(time='2020-10-02')[0] \n\n# Define a normalization instance for the colorbar (not used here)\nnorm2 = mcolors.TwoSlopeNorm(vmin=0, vcenter=131.45/2, vmax=131.45)\n\nfig = plt.figure()\nax = plt.axes(projection = projPC)\nim = ax.pcolormesh(era_xtrem_precip_20201002.longitude, era_xtrem_precip_20201002.latitude, era_xtrem_precip_20201002.values)#, norm=norm2)\nax.set_extent([lonm, lonM, latm, latM], crs=projPC)\ngl = ax.gridlines(draw_labels=True, linewidth=0, alpha=0.5)\n\nax.coastlines()          \nax.add_feature(cfeature.LAND)\nax.add_feature(cfeature.COASTLINE)\nax.add_feature(cfeature.LAKES, alpha=0.5)\nax.add_feature(cfeature.RIVERS)\ncbar = plt.colorbar(im, label='precipitation (mm/d)',  extend='max', anchor=(0.2, 0.5), shrink=0.6, aspect=20)  # ajout de la colorbar\nax.set_title('Total precipitation (mm) on the south-east of France on the 02/10/2020 - from ERA5 dataset')\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-4-maps-of-the-daily-precipitation-for-the-three-datasets-on-that-particular-day","position":57},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.5) Quantity and location of the maximum of precipitation (+ refined time-serie around the event)","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"type":"lvl4","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-5-quantity-and-location-of-the-maximum-of-precipitation-refined-time-serie-around-the-event","position":58},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl4":"9.5) Quantity and location of the maximum of precipitation (+ refined time-serie around the event)","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"content":"\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-5-quantity-and-location-of-the-maximum-of-precipitation-refined-time-serie-around-the-event","position":59},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.5.1) On the hydrology cube","lvl4":"9.5) Quantity and location of the maximum of precipitation (+ refined time-serie around the event)","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-5-1-on-the-hydrology-cube","position":60},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.5.1) On the hydrology cube","lvl4":"9.5) Quantity and location of the maximum of precipitation (+ refined time-serie around the event)","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"content":"\n\n# maximum value and index of latitude and longitude of the maximum\n\nprint('FOR GPM-CPC')\nprint('maximum value: (mm/d)', np.nanmax(hydro_xtrem_precip_20201002))\nprint('index for latitude and longitude of the maximum: ', np.where(hydro_xtrem_precip_20201002 == np.nanmax(hydro_xtrem_precip_20201002)))\nhydro_xtrem_precip_20201002.isel(lat=446, lon=1487) \n\n### time serie around the 2nd of october 2020, at the grid cell of the maximum value\n\nlat_hydro=44.16 ; lon_hydro=7.687\n\nprecip_point_hydro = precip_data_hydro.sel(lat=lat_hydro, lon=lon_hydro, method='nearest')\nprecip_point_hydro1 = precip_point_hydro.sel(time=slice('2020-09-30', '2020-10-06'))\n\nplt.figure(figsize=(8, 4))\nplt.bar(precip_point_hydro1.time.values, precip_point_hydro1.values, width=0.1, color='blue', align='center')\nplt.title('Precipitation from GPM CPC SM2RAIN-ASCAT (hydrology cube)')\nplt.xlabel('Day')\nplt.ylabel('Daily rainfall (mm/d)')\nplt.xticks(rotation=45, ha='right')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-5-1-on-the-hydrology-cube","position":61},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.5.2) On the GPCP cube","lvl4":"9.5) Quantity and location of the maximum of precipitation (+ refined time-serie around the event)","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-5-2-on-the-gpcp-cube","position":62},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.5.2) On the GPCP cube","lvl4":"9.5) Quantity and location of the maximum of precipitation (+ refined time-serie around the event)","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"content":"\n\n# maximum value and index of latitude and longitude of the maximum\n\nprint('FOR GPCP')\nprint('maximum value: (mm/d)', np.nanmax(gpcp_xtrem_precip_20201002))\nprint('index for latitude and longitude of the maximum: ', np.where(gpcp_xtrem_precip_20201002 == np.nanmax(gpcp_xtrem_precip_20201002)))\n\ngpcp_xtrem_precip_20201002.isel(latitude=2, longitude=5) \n\n### time serie around the 2nd of october 2020, at the grid cell of the maximum value\n\nlat_gpcp= 45 ; lon_gpcp= 8\n\nprecip_point_gpcp = precip_data_gpcp.sel(latitude=lat_gpcp, longitude=lon_gpcp, method='nearest')\nprecip_point_gpcp1 = precip_point_gpcp.sel(time=slice('2020-09-30', '2020-10-06'))\n\nplt.figure(figsize=(8, 4))\nplt.bar(precip_point_gpcp1.time.values, precip_point_gpcp1.values, width=0.1, color='blue', align='center')\nplt.title('Precipitation from GPCP')\nplt.xlabel('Day')\nplt.ylabel('Daily rainfall (mm/d)')\nplt.xticks(rotation=45, ha='right')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-5-2-on-the-gpcp-cube","position":63},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.5.3) On the ERA5 cube","lvl4":"9.5) Quantity and location of the maximum of precipitation (+ refined time-serie around the event)","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"type":"lvl5","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-5-3-on-the-era5-cube","position":64},{"hierarchy":{"lvl1":"Earth System Science Open Challenge 1: L. Jessel, S. Hezzi, M. Roussel","lvl5":"9.5.3) On the ERA5 cube","lvl4":"9.5) Quantity and location of the maximum of precipitation (+ refined time-serie around the event)","lvl3":">>> We select the 2nd of october 2020 (detected by GPM-CPC and GPCP)","lvl2":"9. Analysis cells "},"content":"\n\nprint('FOR ERA5')\nprint('maximum value: (mm/d)', np.nanmax(era_xtrem_precip_20201002))\nprint('index for latitude and longitude of the maximum: ', np.where(era_xtrem_precip_20201002 == np.nanmax(era_xtrem_precip_20201002)))\n\nlat_era= 44; lon_era= 7\n\nprecip_point_era = 3600.0*era_cube['tp'].sel(latitude=lat_era, longitude=lon_era, method='nearest')\nprecip_point_era1 = precip_point_era.sel(time=slice('2020-09-30', '2020-10-06'))\n\nplt.figure(figsize=(8, 4))\nplt.bar(precip_point_era1.time.values, precip_point_era1.values, width=0.1, color='blue', align='center')\nplt.title('Precipitation from ERA5')\nplt.xlabel('Day')\nplt.ylabel('Daily rainfall (mm/d)')\nplt.xticks(rotation=45, ha='right')\nplt.grid(True)\nplt.tight_layout()\nplt.show()","type":"content","url":"/notebooks/openchallengenotebook-c1-jessel-hezzi-roussel#id-9-5-3-on-the-era5-cube","position":65},{"hierarchy":{"lvl1":"EODashboard STAC access examples"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access","position":0},{"hierarchy":{"lvl1":"EODashboard STAC access examples"},"content":"","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access","position":1},{"hierarchy":{"lvl1":"EODashboard STAC access examples"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#eodashboard-stac-access-examples","position":2},{"hierarchy":{"lvl1":"EODashboard STAC access examples"},"content":"eodashboard.org uses a standard static STAC catalog\n\nThis example notebook outlines\n\naccessing eodashboard STAC catalog\n\ndiscovery of the collections\n\nchecking individual metadata fields\n\nbrowsing through items inside linked GeoParquet storage\n\nshowing linked XYZ service on an interactive map for a single date\n\ntime series analysis using referenced statistics endpoint\n\n","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#eodashboard-stac-access-examples","position":3},{"hierarchy":{"lvl1":"Step 1: Accessing the EODashboard STAC Catalog"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-1-accessing-the-eodashboard-stac-catalog","position":4},{"hierarchy":{"lvl1":"Step 1: Accessing the EODashboard STAC Catalog"},"content":"The \n\neodashboard.org platform provides a publicly accessible STAC catalog.In this step, we use the pystac library to load the root catalog from the provided URL to explore provided collections.\n\nThis root catalog serves as the entry point and provides metadata and links to collections and subcatalogs.\nWe‚Äôll inspect the catalog description, and check how many child collections are directly linked.","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-1-accessing-the-eodashboard-stac-catalog","position":5},{"hierarchy":{"lvl1":"Step 1: Accessing the EODashboard STAC Catalog","lvl2":"Structure"},"type":"lvl2","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#structure","position":6},{"hierarchy":{"lvl1":"Step 1: Accessing the EODashboard STAC Catalog","lvl2":"Structure"},"content":"eodash organizes its data in a two-level STAC structure:\n\nThe top level consists of ‚Äúindicators‚Äù, represented as STAC collections. Each indicator describes a derived environmental variable or theme (e.g. ‚ÄúSMOS Ocean Salinity‚Äù).\n\nEach indicator then groups one or more sub-collections, represented also as STAC collections. They group the actual datasets contributing to the indicator and each subcollection is shown as separate layer in the eodash client interface.\n\n# Step 1: Access the EODashboard STAC Catalog via PySTAC\n\nfrom pystac import Catalog\n\n# URL to the root STAC catalog (adjust if necessary)\ncatalog_url = \"https://ESA-eodashboards.github.io/eodashboard-catalog/trilateral/catalog.json\"\n\n# Load the catalog\ncatalog = Catalog.from_file(catalog_url)\n\n# Print basic information\nprint(f\"Catalog ID: {catalog.id}\")\nprint(f\"Description: {catalog.description}\")\nindicators = list(catalog.get_children())\n\nprint(f\"Number of child indicators: {len(indicators)}\")\n\n\n\n","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#structure","position":7},{"hierarchy":{"lvl1":"Step 2: Discovering and Filtering Indicators"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-2-discovering-and-filtering-indicators","position":8},{"hierarchy":{"lvl1":"Step 2: Discovering and Filtering Indicators"},"content":"The STAC catalog contains over 100 indicators.In this step, we retrieve all indicators and filter them to include only those relevant to Soil Moisture and Ocean Salinity satellite (SMOS).\n\nWe look for the keyword ‚ÄúSMOS‚Äù in the collection‚Äôs satellite metadata field.This helps us isolate datasets derived from or related to ESA‚Äôs SMOS mission.\n\n# Step 2: Filter indicators related to SMOS\n\n# Filter indicators that mention 'SMOS' in satellite property\nsmos_indicators = [\n    ind for ind in indicators\n    if \"satellite\" in ind.extra_fields and \"SMOS\" in [s.upper() for s in ind.extra_fields[\"satellite\"]]\n]\n\n# Show results\nprint(f\"Found {len(smos_indicators)} SMOS-related collections (strict filter):\")\nfor ind in smos_indicators:\n    print(f\"{ind.id}: {ind.title}\")\n\n","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-2-discovering-and-filtering-indicators","position":9},{"hierarchy":{"lvl1":"Step 3: Checking Individual Metadata Fields"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-3-checking-individual-metadata-fields","position":10},{"hierarchy":{"lvl1":"Step 3: Checking Individual Metadata Fields"},"content":"Now that we‚Äôve identified SMOS-related indicators, we‚Äôll examine one specific indicator in detail:smos_ocean_salinity, which shows the sea surface salinity globally acquired by the SMOS mission.\n\nWe‚Äôll print out the main metadata fields, including:\n\nBasic identification (title, description)\n\nSpatial and temporal extent\n\nLicensing and providers\n\nCustom fields such as satellite, region, and data_source if available\n\nindicator = next(ind for ind in indicators if ind.id == \"smos_ocean_salinity\") \n# Print basic metadata\nprint(f\"Title: {indicator.title}\")\nprint(f\"License: {indicator.license}\")\nprint(f\"Temporal Extent: {indicator.extent.temporal.to_dict()}\")\nprint(f\"Spatial Extent (bbox): {indicator.extent.spatial.bboxes}\")\nprint(\"-----------------------------------------------\")\nprint(f\"Description: {indicator.description}\")\n\n","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-3-checking-individual-metadata-fields","position":11},{"hierarchy":{"lvl1":"Step 4: Navigating the Indicator and Dataset Hierarchy"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-4-navigating-the-indicator-and-dataset-hierarchy","position":12},{"hierarchy":{"lvl1":"Step 4: Navigating the Indicator and Dataset Hierarchy"},"content":"So far, we‚Äôve explored the indicator STAC Collection smos_ocean_salinity as explained in the Step 1.\n\nTo access the actual data items on a subcollection STAC Collection we now need to look at its child collections, which contain the STAC Items and assets.\n\nIn this step, we identify and load those child collections so we can continue our exploration at the data level.\n\nIn our case, the indicator has just one collection - itself so it looks easy.\n\n# Get child links that are STAC collections\nchild_collections = []\nfor link in indicator.get_links(\"child\"):\n    if link.rel == \"child\":\n        child_collection = link.resolve_stac_object().target\n        child_collections.append(child_collection)\n\n# Show child collection IDs and titles\nprint(f\"{len(child_collections)} child collections found under 'smos_ocean_salinity':\")\nfor col in child_collections:\n    print(f\"- {col.id}: {col.title}\")\n\n","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-4-navigating-the-indicator-and-dataset-hierarchy","position":13},{"hierarchy":{"lvl1":"Step 5: Accessing and Browsing STAC Items via GeoParquet"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-5-accessing-and-browsing-stac-items-via-geoparquet","position":14},{"hierarchy":{"lvl1":"Step 5: Accessing and Browsing STAC Items via GeoParquet"},"content":"In eodashboard, each child collection under an indicator may reference a bulk listing of STAC Items using a GeoParquet file for performance reasons during the catalog creation.\nThis file acts as a storage for the STAC Items associated with that dataset and can be efficiently read and queried.\n\nWe identify this asset by checking for an Asset with a roles array containing \"collection-mirror\" which is eodash specific way of distinction of the GeoParquet.\n\nOnce found, we load it and use pyarrow.parquet to load the GeoParquet file and stac_geoparquet to convert it back to STAC Item structure and display their contents.\n\nThis enables fast, local-style exploration of all STAC items in the dataset, including geometry, timestamp, and links to assets like XYZ tiles or statistics endpoints.\n\nimport requests\nimport pyarrow.parquet as pq\nimport io\nimport stac_geoparquet\n\ngeoparquet_asset = None\nfor key, asset in child_collection.assets.items():\n    # specific way how eodash labels the asset with a geoparquet of items\n    if \"collection-mirror\" in asset.roles:\n        geoparquet_asset = asset\n        break\n\nif geoparquet_asset is None:\n    raise ValueError(\"No asset with role 'collection-mirror' found in the child collection.\")\n# eodash catalog links the asset href with relative path, we need to get absolute to retrieve it\nparquet_url = geoparquet_asset.get_absolute_href()\nprint(f\"Reading remote GeoParquet from: {parquet_url}\")\n\nresponse = requests.get(parquet_url)\nif response.status_code != 200:\n    print(f\"Failed to download parquet file from {parquet_url}\")\n# Read the table with pyarrow\ntable = pq.read_table(io.BytesIO(response.content))\n\n# Convert to a list of STAC dictionaries\nitems = list(stac_geoparquet.arrow.stac_table_to_items(table))\nprint(f\"In total {len(items)} items were retrieved.\")\nprint(f\"Submission {len(items)} items were retrieved.\")\n# show example of metadata of one item\nitem = items[0]\nprint(\"-------------------------------------\")\nprint(f\"Datetime: {item['properties'].get('datetime')}\")\nprint(f\"BBox: {item['bbox']}\")\nprint(f\"Number of service links: {len(item['links'])}\")\n\n\n","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-5-accessing-and-browsing-stac-items-via-geoparquet","position":15},{"hierarchy":{"lvl1":"Step 6. Visualize Linked XYZ Tile Layer"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-6-visualize-linked-xyz-tile-layer","position":16},{"hierarchy":{"lvl1":"Step 6. Visualize Linked XYZ Tile Layer"},"content":"For each item, eodash links the suggested rendering of the visualization layer, which we can display using folium on the map.\n\nWe selected the first Item containing data for 1.4.2023 and add the tile layer with a eox cloudless background..\n\nimport folium\n\n# Find the xyz tile link for 1.4.2023\nxyz_link = next((l for l in item[\"links\"] if l[\"rel\"] == \"xyz\"), None)\nprint(f\"Actual link is {xyz_link}\")\nm = folium.Map(location=[45, 10], zoom_start=4, tiles=None)\nif xyz_link:\n    folium.TileLayer(\n        tiles=xyz_link[\"href\"],\n        attr='Rendering of SMOS datacube provided by xcube-server operated by Brockmann Consult GmbH',\n        name=xyz_link.get(\"title\", \"Tile Layer\"),\n        overlay=True,\n        control=True\n    ).add_to(m)\n\n# Add EOxCloudless layer\nfolium.TileLayer(\n    tiles=\"https://tiles.maps.eox.at/wmts/1.0.0/s2cloudless-2024_3857/default/GoogleMapsCompatible/{z}/{y}/{x}.jpg\",\n    attr='<a href=\"https://maps.eox.at\">Overlay</a> { Data &copy; <a href=\"http://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors, Rendering &copy; <a href=\"https://eox.at\">EOX</a> and <a href=\"https://github.com/mapserver/basemaps\">MapServer</a> }',\n    name=\"EOxCloudless 2024\",\n    overlay=False,\n    control=True\n).add_to(m)\n\nfolium.LayerControl().add_to(m)\nm\n\n","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-6-visualize-linked-xyz-tile-layer","position":17},{"hierarchy":{"lvl1":"Step 7. Create the legend for the provided layer"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-7-create-the-legend-for-the-provided-layer","position":18},{"hierarchy":{"lvl1":"Step 7. Create the legend for the provided layer"},"content":"When viewing geospatial datasets, especially those using color mapped imagery such as the SMOS ocean salinity layer, the colors themselves have no meaning without a reference.\n\nIn our case, the SMOS layer visualization uses the jet colormap scaled from 0 to 50 as seen in the XYZ link from metadata, which corresponds to sea surface salinity in parts per 1000 (ppt).\n\nIncluding a legend ensures that viewers can correctly interpret the scientific meaning behind the visual patterns.\n\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(6, 1))\nfig.subplots_adjust(bottom=0.5)\n\n# Create a colorbar image from the \"jet\" colormap\ncmap = plt.get_cmap('jet')\nnorm = plt.Normalize(vmin=0, vmax=50)\n\ncb = plt.colorbar(\n    plt.cm.ScalarMappable(norm=norm, cmap=cmap),\n    cax=ax,\n    orientation='horizontal'\n)\n\ncb.set_label(\"Sea Surface Salinity (ppt)\")\nplt.show()\n\n","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-7-create-the-legend-for-the-provided-layer","position":19},{"hierarchy":{"lvl1":"Step 8. Fetching and Plotting Time Series Statistics"},"type":"lvl1","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-8-fetching-and-plotting-time-series-statistics","position":20},{"hierarchy":{"lvl1":"Step 8. Fetching and Plotting Time Series Statistics"},"content":"In this step, we access the statistics service linked from the indicator level STAC collection.\nWe sent a POST request with a specified geographic polygon to retrieve median values of the satellite data over time.\nThe response provides a time series which we then visualized using Matplotlib.\n\nTo ensure the date labels on the x-axis are readable and well-formatted, we converted the time strings to datetime objects and used Matplotlib‚Äôs date locators and formatters.\n\nimport requests\nimport json\nimport matplotlib.pyplot as plt\nfrom shapely.geometry import Polygon, mapping\nimport matplotlib.dates as mdates\nfrom datetime import datetime\n\n# Find the statistics link in the indicator-level STAC Collection\nstats_link = next(\n    link for link in indicator.links\n    if link.rel == \"service\" and link.media_type == \"application/json\"\n)\nprint(f\"Statistics link {stats_link.target}\")\n# Prepare the polygon geometry (example: small box in the Mediterranean sea south of France)\npolygon_geom = Polygon([\n    (4.35, 40.55),\n    (4.35, 42.35),\n    (7.2, 42.35),\n    (7.2, 40.55),\n    (4.35, 40.55)\n])\n\ngeometry_geojson = mapping(polygon_geom)\n\n# Load POST body template from linked JSON file and fill {{{geometry}}}\nbody_url = stats_link.extra_fields[\"body\"]\nbody_template_str = requests.get(body_url).text\n# Replace the placeholder with the actual JSON object text\nbody_filled_str = body_template_str.replace(\n    \"{{{polygon}}}\",\n    json.dumps(geometry_geojson)\n)\n\n# Now parse into a Python dict\nbody_filled = json.loads(body_filled_str)\n\n# Send the POST request\nresponse = requests.post(stats_link.target, json=body_filled)\nresponse.raise_for_status()\ndata = response.json()\n\n# Extract times and median values\ntimes = [entry[\"time\"] for entry in data[\"result\"]]\n# Convert to datetime\ntimes_dt = [datetime.fromisoformat(t.replace(\"Z\", \"+00:00\")) for t in times]\nmedians = [entry[\"median\"] for entry in data[\"result\"]]\n\n# Plot as a time series\nfig, ax = plt.subplots(figsize=(10, 5))\nax.plot(times_dt, medians, marker=\"o\")\n\nax.set_title(\"SMOS Ocean Salinity Median Values\")\nax.set_xlabel(\"Time\")\nax.set_ylabel(\"Median Value Salinity (ppt)\")\n\n# Format the x-axis dates\nax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))  # one tick per month\nax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n\nplt.xticks(rotation=45, ha=\"right\")\nplt.tight_layout()\nplt.show()","type":"content","url":"/notebooks/eodashboard-stac-access/eodashboard-stac-access#step-8-fetching-and-plotting-time-series-statistics","position":21},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps"},"type":"lvl1","url":"/notebooks/nightlights-notebook/night-lights-blending","position":0},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps"},"content":"","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending","position":1},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Case study: Creating nighttime light maps with color blending"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#case-study-creating-nighttime-light-maps-with-color-blending","position":2},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Case study: Creating nighttime light maps with color blending"},"content":"\n\nThis notebook demonstrates how to create nighttime light variation maps over a time interval (from 2019 to 2022) with additive color blending for studying the distribution of artificial lighting in urban and rural regions, offering insights into urbanization, infrastructure development, and socio-economic activity.\nThe Nighttime Light Levels indicator can be explored on the EO Dashboard by selecting the EXPLORE DATASETS mode and choosing \n\nNight lights indicators.\n\nThe study has been carried out by Bumpei Tojo PhD (Associate Professor), School of International and Area Studies, Tokyo University of Foreign Studies, Japan.\n\nThe PLES Engineering team (supporting ESA Green Solutions Division, EOP-SG) developed the blending algorithm with the current Notebook implementation and data ingestion on the dashboard (contacts: Federico Rondoni, \n\nf‚Äã.rondoni@stariongroup‚Äã.eu, Diego Moglioni, \n\nd‚Äã.moglioni@stariongroup‚Äã.eu).\n\n\nExample of a nighttime light map covering Northeastern United States during 2019-2022, representing areas where a decrease in nighttime light level occurred (indicating a presumed reduction in social activity) in red, and areas where an increase occurred (indicating a presumed increase in social activity) in blue.\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#case-study-creating-nighttime-light-maps-with-color-blending","position":3},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Input data:"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#input-data","position":4},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Input data:"},"content":"This product was developed by JAXA by aggregating the data from the Visible Infrared Imaging Radiometer Suite (VIIRS, onboard the Suomi NPP satellite) on a semi-annual basis (using median image generation) with 10-degree lat/lon (geographic) grid h-v tile as Geo Tiff files.\n\nThe tiles are 2400 x 2400 pixels, with pixel size of 0.004166 degrees (~464 m at the equator).\n\nMetric: nighttime radiance (measured in watts per square centimeter per steradian, [W/cm¬≤/sr]), which represents the brightness of artificial lighting.\n\nVIIRS 10-degree tile scheme\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#input-data","position":5},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Running environment:"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#running-environment","position":6},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Running environment:"},"content":"This notebook can be run by installing the provided Anaconda Python environment (data/Nightlights/nightlights-env.yml).\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#running-environment","position":7},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Importing Python libraries"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#importing-python-libraries","position":8},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Importing Python libraries"},"content":"\n\n#Import libraries\nimport os\nimport sys\nimport re\nimport numpy as np\nimport rasterio\nimport rioxarray as rxr\nimport subprocess\nfrom subprocess import Popen, PIPE\nimport tempfile\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom PIL import Image\nimport json\nfrom ipyleaflet import Map, ImageOverlay, basemaps\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#importing-python-libraries","position":9},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Defining working folders"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#defining-working-folders","position":10},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Defining working folders"},"content":"\n\ninput_dir = \"input\"\ninput_path = os.path.join(os.getcwd(), \"data\", \"Nightlights\", input_dir)\n\noutput_urban = \"output\"\nurban_path = os.path.join(os.getcwd(), \"data\", \"Nightlights\", output_urban)\n\n# Create output dir\nos.makedirs(urban_path, exist_ok=True)\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#defining-working-folders","position":11},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Visualizing input data"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#visualizing-input-data","position":12},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Visualizing input data"},"content":"\n\npattern = re.compile(r\"h(\\d+)v(\\d+)_(\\d{4})_(\\d)H_median\\.tif\")\n\nfor root, _, files in os.walk(input_path):\n    grouped_files = {}\n    \n    # Grouping files by h and v\n    for file in files:\n        match = pattern.match(file)\n        if match:\n            h, v, year, H = match.groups()\n            key = (h, v)\n            if key not in grouped_files:\n                grouped_files[key] = []\n            grouped_files[key].append((year, H, os.path.join(root, file))) \n    \n    # Process files for plotting\n    for (h, v), file_group in grouped_files.items():\n        file_group\n\ntuplelist2dict = {c:{'year':a,'half':b} for a,b,c in file_group}\nsorted_dict = {}\n\ngrid_tile = None\nfor item in sorted(tuplelist2dict, key = lambda k: (tuplelist2dict[k]['year'], tuplelist2dict[k]['half'])):\n    sorted_dict.update({item:tuplelist2dict[item]})\n    grid_tile = item.split('/')[-1].split('_')[0]\n\n\ndef plot_figures(figures, nrows = 1, ncols=1, factor = 1., clip_range = None, **kwargs):\n    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, figsize=(15, 15))\n    for idx,file_name in enumerate(figures):\n        title = file_name.split('/')[-1]\n        title = title.replace(\"_median.tif\", \"\")\n        axeslist.ravel()[idx].imshow(np.clip(mpimg.imread(file_name)*factor, *clip_range), **kwargs) # cmap=plt.gray(), cmap='Greys'\n        axeslist.ravel()[idx].set_title(title)\n        axeslist.ravel()[idx].set_axis_off()\n    fig.suptitle(r'Median nighttime light level [$Wcm^{-2}sr^{-1}$]', fontsize=20)\n    #plt.tight_layout() \n\n    \n\nplot_figures(sorted_dict, 4, 2, clip_range=(0,1), factor=100./255.)\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#visualizing-input-data","position":13},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Applying color blending"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#applying-color-blending","position":14},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Applying color blending"},"content":"\n\nAdditive color blending involves mixing the primary colors of light, red (R), green (G), and blue (B), while adjusting their luminance levels. By manipulating the luminance of these colors, a wide range of hues can be achieved, with the key characteristic being that combining all three colors results in white.\n\nTechnique\n\nmaximum pixel value of images for 2019 (brightest pixel values) is assigned to red (R)\n\nminimum pixel value of images for 2020-2021 (darkest pixel values) is assigned to green (G)\n\nmaximum pixel value of images for 2022 (brightest pixel values) is assigned to blue (B)\n\nOutput\n\nregions where a decrease in nighttime light level occurred are displayed in red\n\nareas that experienced an increase (presumed to indicate an increase in social activity) are shown in blue\n\nregions where there was no significant change throughout the pandemic are displayed in a gradient from gray to white.\n\npattern = re.compile(r\"h(\\d+)v(\\d+)_(\\d{4})_(\\d)H_median\\.tif\")\n\n\ndef read_and_preprocess(file):\n    with rasterio.open(file) as src:\n        img = src.read(1)\n        img = np.nan_to_num(img, nan=0)  # Replace NaNs with zeros\n        return img, src.profile\n\n    \ndef additive_blending(grouped_files):\n    # Process each group of files for blending\n    for (h, v), file_group in grouped_files.items():\n        # Initialize arrays to store the maximum and minimum values for each year\n        max_2019 = None\n        min_2020_2021 = None\n        max_2022 = None\n        \n        for year, H, file in file_group:\n            img, profile = read_and_preprocess(file)\n            \n            if year == '2019':\n                if max_2019 is None:\n                    max_2019 = img\n                else:\n                    max_2019 = np.maximum(max_2019, img)\n            elif year in ['2020', '2021']:\n                if min_2020_2021 is None:\n                    min_2020_2021 = img\n                else:\n                    min_2020_2021 = np.minimum(min_2020_2021, img)\n            elif year == '2022':\n                if max_2022 is None:\n                    max_2022 = img\n                else:\n                    max_2022 = np.maximum(max_2022, img)\n                                  \n    # Create the blended image using the specified blending technique\n    blended_img = np.zeros((max_2019.shape[0], max_2019.shape[1], 3), dtype=np.float32)\n    blended_img[:, :, 0] = max_2019.astype(np.float32)  # Red band: maximum of 2019\n    blended_img[:, :, 1] = min_2020_2021.astype(np.float32)  # Green band: minimum of 2020-2021 compared\n    blended_img[:, :, 2] = max_2022.astype(np.float32)  # Blue band: maximum of 2022\n    \n    return blended_img, profile        \n\n# Grouping files per (h,v) tiles and years span\ngrouped_files = {}\nfor root, _, files in os.walk(input_path):\n    \n    \n    # Group files by h and v\n    for file in files:\n        match = pattern.match(file)\n        if match:\n            h, v, year, H = match.groups()\n            key = (h, v)\n            if key not in grouped_files:\n                grouped_files[key] = []\n            grouped_files[key].append((year, H, os.path.join(root, file)))\n\n\n# blending           \nblended_img, profile = additive_blending(grouped_files)\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#applying-color-blending","position":15},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Employing ‚Äúurban‚Äù stretch processing"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#employing-urban-stretch-processing","position":16},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Employing ‚Äúurban‚Äù stretch processing"},"content":"\n\nThe purpose of the stretch processing is to emphasize the nighttime light level of each band (corresponding to 2019, 2020-21, and 2022), focusing on:\n\n‚Äúurban‚Äù nighttime light levels: the display range of each band is adjusted to 25-1000 [watts¬∑cm-2¬∑sr-1], emphasizing brighter areas\n\n# Urban stretch processing: Emphasize brighter areas\ndef urban_stretch_processing(band):\n    min_val = 25\n    max_val = 1000\n    band = np.clip(band, min_val, max_val)\n    band = (band - min_val) / (max_val - min_val) * 255\n    return band.astype(np.uint8)\n\n# Apply urban stretch processing to each band\nblended_img[:, :, 0] = urban_stretch_processing(blended_img[:, :, 0])\nblended_img[:, :, 1] = urban_stretch_processing(blended_img[:, :, 1])\nblended_img[:, :, 2] = urban_stretch_processing(blended_img[:, :, 2])\n        \n# Update the profile for a 3-band image and set nodata value to None\nprofile.update(count=3, dtype=rasterio.uint8, nodata=None)\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#employing-urban-stretch-processing","position":17},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Plotting blended image"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#plotting-blended-image","position":18},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Plotting blended image"},"content":"\n\ndef plot_image(image, factor=1.0, clip_range = None, **kwargs):\n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n    if clip_range is not None:\n        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n    else:\n        ax.imshow(image * factor, **kwargs)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n\nplot_image(blended_img, factor=1.5/255., clip_range=(0,1))\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#plotting-blended-image","position":19},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Overlaying with an interactive map"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#overlaying-with-an-interactive-map","position":20},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Overlaying with an interactive map"},"content":"\n\nSaving blended image as Cloud Optimized GeoTIFF\n\n# Exporting output as COG file \nres_name = f\"Nighttimelevel_Urban_{grid_tile}_2019-2022.tif\"\noutput_cog = os.path.join(urban_path, res_name)\n\n\n# Write the blended image directly to a temporary file\nwith tempfile.NamedTemporaryFile(suffix=\".tif\") as temp_file:\n    with rasterio.open(temp_file.name, \"w\", **profile) as dst:\n        dst.write(blended_img[:, :, 0], 1)\n        dst.write(blended_img[:, :, 1], 2)\n        dst.write(blended_img[:, :, 2], 3)\n\n    subprocess.run([\n        \"gdal_translate\", \"-of\", \"COG\",\n        \"-co\", \"COMPRESS=DEFLATE\",\n        \"-co\", \"BLOCKSIZE=512\",\n        \"-co\", \"RESAMPLING=NEAREST\",\n        \"-co\", \"OVERVIEWS=IGNORE_EXISTING\",\n        temp_file.name,\n        output_cog\n    ])\n\nprint(f\"COG file saved as {output_cog}\")\n\nExtracting bounding-box coordinates\n\np1 = Popen([\"gdalinfo\", \"-json\", output_cog, \"-mm\"], stdout=PIPE)\noutput = p1.communicate()[0]\ndec_out = output.decode('utf-8')\nj_str = json.loads(dec_out)\nbbox = j_str['cornerCoordinates']\nll = bbox['lowerLeft']  # SW coo\nur = bbox['upperRight'] # NE coo\ncenter = bbox['center']\n\nAdding alpha channel to the blended image\n\ndef almostEquals(a,b,thres=50):\n    return all(abs(a[i]-b[i])<thres for i in range(len(a)))\n\n\nimage = Image.open(output_cog).convert('RGBA')\npixeldata = list(image.getdata())\n\n\nfor i,pixel in enumerate(pixeldata):\n    if almostEquals(pixel[:3], (0,0,0)):\n        pixeldata[i] = (0,0,0,0)\n\n\nimage.putdata(pixeldata)\npng_path = os.path.join(urban_path, res_name.replace(\".tif\",\".png\"))\nres = image.save(png_path)\n#os.path.abspath(res)\nabs_path = os.path.abspath(png_path)\nwork_dir = os.getcwd()\nid_ = work_dir.split('/')[2]\nbase_url = os.path.join('https://hub-otc-sc.eox.at/user',id_,'files')\n#base_url\nabs_path = '/'.join(abs_path.split('/')[3:])\n#abs_path\n#os.path.join(base_url,abs_path)\n\nOverlay with OpenStreetMap\n\nm = Map(basemap=basemaps.CartoDB.DarkMatter, center=(center[1], center[0]), zoom=6)\nimage = ImageOverlay(\n        url=os.path.join(base_url,abs_path), #url=\"https://hub-otc-sc.eox.at/user/<id>/files/<path_to_png>\n        bounds=((ll[1], ll[0]), (ur[1], ur[0])) # SW and NE corners\n                    )\nm.add_layer(image);\nm\n\nUsing additive color blending images to focus on urban areas in the northeastern United States, particularly the southern part of the Boston-Washington Corridor comprising major cities like New York, Philadelphia, Baltimore, and Washington, D.C., revealed relatively little variation in nighttime lights before and after the COVID-19 pandemic, as indicated by the images appearing white. However, significant reductions in nighttime lights during the COVID-19 pandemic (subsequently recovering to pre-pandemic levels) were evident in other medium to large cities, including Boston and Toronto, among others, as indicated by the images appearing pink to reddish.\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#overlaying-with-an-interactive-map","position":21},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Alternative stretch processing approaches"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#alternative-stretch-processing-approaches","position":22},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Alternative stretch processing approaches"},"content":"\n\n‚ÄúRural‚Äù nighttime light levels: setting each band‚Äôs display range to 0-50 [Watts¬∑cm-2¬∑sr-1] to emphasize darker areas\n\nFor a broader focus (from rural to urban areas): applying a log10 transformation to the values of each band with a display range set to 0-3.6 (equivalent to 0-3981 [Watts¬∑cm-2¬∑sr-1])\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#alternative-stretch-processing-approaches","position":23},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Final remarks"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#final-remarks","position":24},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"Final remarks"},"content":"\n\nThis product has been specifically designed for utilization by researchers in applied scientific fields.\nPotential applications are being explored in environmental and social issue studies, such as disaster recovery, energy, urban land use changes, conflicts, migration, and monitoring of illegal, unreported activities.\n\n","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#final-remarks","position":25},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"To learn more"},"type":"lvl2","url":"/notebooks/nightlights-notebook/night-lights-blending#to-learn-more","position":26},{"hierarchy":{"lvl1":"Monitoring socio-economic activities with nighttime light maps","lvl2":"To learn more"},"content":"\n\nThe presented approach is often referenced in scientific and public health research. For example, Bunpei Tojo (2021) used Nightlights data in the study ‚ÄúApplication of Earth observation satellite data to public health: Comparison of night light (VIIRS) and solar radiation (SGLI) and domestic COVID-19 epidemic,‚Äù presented at the 12th Federation of Science and Technology conference, to analyze the relationship between nighttime light intensity and public health factors.\n\n\nÊù±Âüé (2021).","type":"content","url":"/notebooks/nightlights-notebook/night-lights-blending#to-learn-more","position":27},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI"},"type":"lvl1","url":"/notebooks/veda-api-bids-2023","position":0},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI"},"content":"This notebook is divided into two parts, each demonstrating the functionalities of the VEDA EOAPI.\n\nReading and visualizing one of the datasets from the VEDA data catalog.\n\nUsing the EOAPI to generate a time-series of OMI (Ozone Monitoring Instrument) NO‚ÇÇ and SO‚ÇÇ datasets\n\nAuthor: Slesa Adhikari\n\n","type":"content","url":"/notebooks/veda-api-bids-2023","position":1},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI","lvl2":"1. Reading and visualizing one of the datasets from the VEDA data catalog"},"type":"lvl2","url":"/notebooks/veda-api-bids-2023#id-1-reading-and-visualizing-one-of-the-datasets-from-the-veda-data-catalog","position":2},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI","lvl2":"1. Reading and visualizing one of the datasets from the VEDA data catalog"},"content":"\n\nImport all the necesssary libraries\n\nMake sure you install these first using:pip install pystac_client folium seaborn pandas\n\n# imports\nimport requests\nfrom pystac_client import Client\nimport folium\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nDefine the API endpoints\n\nThe EOAPI is a combination of two components.\n\nData catalog - the \n\nSpatioTemporal Asset Catalog (STAC) specification is used to catalog the available datasets\n\nDynamic tile server - \n\nTiTiler is used to dynamically serve cloud optimized geotiff (raster) data files\n\nSTAC_API_URL = \"https://staging-stac.delta-backend.com/\"\nRASTER_API_URL = \"https://staging-raster.delta-backend.com\"\n\nUse the pystac_client library to interact with the STAC data catalog\n\ncatalog = Client.open(STAC_API_URL)\n\nList all the datasets (collections) in the catalog\n\nfor collection in list(catalog.get_collections()):\n    print(f\"{collection.id} - {collection.title}\")\n\nChoose a collection to work with\n\nSearch all the items in the collection\n\ncollection_id = \"no2-monthly\"\nsearch = catalog.search(collections=[collection_id])\nitems = list(search.items())\nitems\n\nLoad and inspect one of the items\n\ns3_uri = items[0].assets[\"cog_default\"].href\n\nstats = requests.get(\n    f\"{RASTER_API_URL}/cog/statistics\",\n    params={\"url\": s3_uri}\n).json()\nstats\n\nDisplay the COG in a map\n\nGet the tiles endpoint for the file\n\nrescale = f\"{stats['b1']['min']},{stats['b1']['max']}\"\n\ntiles = requests.get(\n    f\"{RASTER_API_URL}/stac/tilejson.json?collection={collection_id}&item={items[0].id}&assets=cog_default&colormap_name=rdbu_r&rescale={rescale}\"\n).json()\n\ntiles\n\nUse the tiles to visualize the file in a map\n\nm = folium.Map(\n    zoom_start=6,\n    scroll_wheel_zoom=True, \n    tiles=tiles[\"tiles\"][0], \n    attr=\"VEDA\", \n    minzoom=0, \n    maxzoom=18,\n)\n\nm\n\nMake this map slightly more insightful\n\nUsing the minimum and maximum values for the colorscale may not be the most useful. Dynamic tiling to the rescue!\nTiTiler comes with a \n\nlarge amount of options to style the map. Here we‚Äôll do a quick a dirty adjustment of the max value.\n\nrescale_limited_max = f\"{stats['b1']['min']},{stats['b1']['max']/2}\"\n\ntiles_limited_max = requests.get(\n    f\"{RASTER_API_URL}/stac/tilejson.json?collection={collection_id}&item={items[0].id}&assets=cog_default&colormap_name=rdbu_r&rescale={rescale_limited_max}\"\n).json()\ntiles_limited_max\n\nm_limited_max = folium.Map(\n    zoom_start=6,\n    scroll_wheel_zoom=True, \n    tiles=tiles_limited_max[\"tiles\"][0], \n    attr=\"VEDA\", \n    minzoom=0, \n    maxzoom=18,\n)\nm_limited_max\n\n","type":"content","url":"/notebooks/veda-api-bids-2023#id-1-reading-and-visualizing-one-of-the-datasets-from-the-veda-data-catalog","position":3},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI","lvl2":"2. Using the EOAPI to generate a time-series of OMI (Ozone Monitoring Instrument) NO‚ÇÇ and SO‚ÇÇ datasets"},"type":"lvl2","url":"/notebooks/veda-api-bids-2023#id-2-using-the-eoapi-to-generate-a-time-series-of-omi-ozone-monitoring-instrument-no-and-so-datasets","position":4},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI","lvl2":"2. Using the EOAPI to generate a time-series of OMI (Ozone Monitoring Instrument) NO‚ÇÇ and SO‚ÇÇ datasets"},"content":"\n\nThere‚Äôs a story published in the EODashboard with the following title:\n\nAir pollution in India, China and the U.S. have changed significantly over the past two decades\n\nLink: \n\nhttps://‚Äãeodashboard‚Äã.org‚Äã/story‚Äã?id‚Äã=‚Äãair‚Äã-pollution‚Äã-us‚Äã-india‚Äã-china\n\nThe story talks about the trend of air pollution in India, China and the U.S. using the NO2 and SO2 readings grabbed from the OMI instrument\n\nHere, we‚Äôll recreate the analysis using the EOAPI\n\n# Here, we find the relevant collection ID for the dataset\ncollections = {\n    \"no2\": \"OMI_trno2-COG\",\n    \"so2\": \"OMSO2PCA-COG\",\n}\n\nDefine the roughly similar Area of Interest (AOI) for each of the country as seen in the story\n\naois = {\n    \"india\": {\n      \"type\": \"Feature\",\n      \"properties\": {},\n      \"geometry\": {\n        \"coordinates\": [\n          [\n            [\n              84.44227371801799,\n              25.276852788244952\n            ],\n            [\n              81.73331688510166,\n              25.379576397063317\n            ],\n            [\n              81.40290450746915,\n              20.640781701865322\n            ],\n            [\n              84.09079123546121,\n              20.59296261766137\n            ],\n            [\n              84.44227371801799,\n              25.276852788244952\n            ]\n          ]\n        ],\n        \"type\": \"Polygon\"\n      }\n    },\n    \"china\": {\n      \"type\": \"Feature\",\n      \"properties\": {},\n      \"geometry\": {\n        \"coordinates\": [\n          [\n            [\n              118.14487188674968,\n              40.38237805885373\n            ],\n            [\n              112.59679754686567,\n              40.39197699341523\n            ],\n            [\n              112.78712023622006,\n              32.015052150835814\n            ],\n            [\n              117.937454307721,\n              32.102440507249895\n            ],\n            [\n              118.14487188674968,\n              40.38237805885373\n            ]\n          ]\n        ],\n        \"type\": \"Polygon\"\n      }\n    },\n    \"usa\": {\n        \"type\": \"Feature\",\n        \"properties\": {},\n        \"geometry\": {\n            \"coordinates\": [\n            [\n                [\n                -80.16702521343733,\n                41.73420113945659\n                ],\n                [\n                -83.56446680395005,\n                38.599369254919566\n                ],\n                [\n                -82.00280661075571,\n                37.54658260550103\n                ],\n                [\n                -78.28140359718638,\n                40.450899619800595\n                ],\n                [\n                -80.16702521343733,\n                41.73420113945659\n                ]\n            ]\n            ],\n            \"type\": \"Polygon\"\n        }\n    },\n}\n\nDefine a function that takes the following params:\n\nitem: a STAC item\n\ngeojson: the geojson of the AOI\n\nUsing the /cog/statistics/ endpoint of the raster API, we get back the statistics of the item (which corresponds to one COG file) within the given geojson AOI.\n\nThe statistics includes min, max, mean, std, etc.\n\n# the bounding box should be passed to the geojson param as a geojson Feature or FeatureCollection\ndef generate_stats(item, geojson):\n    result = requests.post(\n        f\"{RASTER_API_URL}/cog/statistics\", \n        params={\n            \"url\": item.assets[\"cog_default\"].href\n        },\n        json=geojson\n    ).json()\n    return {\n        **result[\"properties\"],\n        \"start_datetime\": str(item.properties.get(\"datetime\", item.properties.get(\"start_datetime\")))[:4],\n        \"collection\": item.collection_id\n    }\n\nLet‚Äôs start out with the US üá∫üá∏ !\n\nWe‚Äôll get all the items in the NO2 and SO2 collections and generate the statistics from them for the Ohio River Valley region of the United States.\n\nusa_aoi = aois[\"usa\"]\nitems = list(catalog.search(collections=[collections[\"no2\"], collections[\"so2\"]]).items())\nusa_stats = [\n    generate_stats(item, usa_aoi)\n    for item in items\n]\n\nCreate a function that takes the statistics (which is a json) and converts it to a pandas dataframe in a format that‚Äôll make it easy to read and visualize.\n\nWe‚Äôre only concerned with the mean statistics for this example. Specifically the change from the year 2005 in percentage. We‚Äôll use pandas to calculate this change percentage and assign it to the change column.\n\ndef clean_stats(stats_json) -> pd.DataFrame:\n    # convert the stats_json as is to pandas dataframe\n    df = pd.json_normalize(stats_json)\n    # simple renaming for readability\n    df.columns = [col.replace(\"statistics.b1.\", \"\") for col in df.columns]\n    # create a date column from the start_datetime column\n    df[\"date\"] = pd.to_datetime(df[\"start_datetime\"], format=\"%Y\")\n    # sort the dataframe by the date column\n    df = df.sort_values(by=[\"date\"])\n    # create a change column that calculates the change of the mean values from the value in 2005\n    df[\"change\"] = df.groupby(\"collection\", group_keys=False)[\"mean\"].apply(lambda x: x.div(x.iloc[0]).subtract(1).mul(100))\n    return df\n\ncleaned_stats_df = clean_stats(usa_stats)\n\nWe‚Äôll now create a time-series of the change in mean values for NO2 and SO2 for the area in the US.\n\nplt.xticks([i for i in range(0, 21, 2)])\nsns.set_style(\"darkgrid\")\nax = sns.lineplot(\n    x=\"start_datetime\",\n    y=\"change\",\n    hue=\"collection\",\n    data=cleaned_stats_df,\n    palette=[\"#2196f3\", \"#ff5722\"],\n    style=\"collection\",\n    markers=[\"*\", \"d\"]\n)\nax.set_title(\"US - Ohio River Valley\")\nax.set_xlabel(\"Years\")\nax.set_ylabel(\"Change from 2005 (%)\")\nplt.legend(frameon=False, ncol=3)\nplt.show()\n\nNow, let‚Äôs create a function that creates this trend graph, given the country.\n\ndef create_chart(country):\n    stats = [generate_stats(item, aois[country]) for item in list(catalog.search(collections=[collections[\"no2\"], collections[\"so2\"]]).items())]\n    df = clean_stats(stats)\n\n    # Create a chart using Seaborn\n    plt.xticks([i for i in range(0, 21, 2)])\n    sns.set_style(\"darkgrid\")\n    ax = sns.lineplot(\n        x=\"start_datetime\",\n        y=\"change\",\n        hue=\"collection\",\n        data=df,\n        palette=[\"#2196f3\", \"#ff5722\"],\n        style=\"collection\",\n        markers=[\"*\", \"d\"]\n    )\n    ax.set_title(country.title())\n    ax.set_xlabel(\"Years\")\n    ax.set_ylabel(\"Change from 2005 (%)\")\n    plt.legend(frameon=False, ncol=3)\n    plt.show()\n\nWe can use this function to create charts for the rest of the AOIs.\n\nIndia üáÆüá≥\n\ncreate_chart(\"india\")\n\nChina üá®üá≥\n\ncreate_chart(\"china\")","type":"content","url":"/notebooks/veda-api-bids-2023#id-2-using-the-eoapi-to-generate-a-time-series-of-omi-ozone-monitoring-instrument-no-and-so-datasets","position":5}]}